{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Le gradient et le discret\n",
    "\n",
    "Les méthodes d'optimisation à base de gradient s'appuie sur une fonction d'erreur dérivable qu'on devrait appliquer de préférence sur des variables aléatoires réelles. Ce notebook explore quelques idées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un petit problème simple\n",
    "\n",
    "On utilise le jeu de données *iris* disponible dans [scikit-learn](http://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cale une régression logistique. On ne distingue pas apprentissage et test car ce n'est pas le propos de ce notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(multi_class=\"ovr\", solver=\"liblinear\")\n",
    "clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis on calcule la matrice de confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[49,  1,  0],\n",
       "       [ 2, 21, 27],\n",
       "       [ 1,  4, 45]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred = clf.predict(X)\n",
    "confusion_matrix(Y, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiplication des observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le paramètre ``multi_class='ovr'`` stipule que le modèle cache en fait l'estimation de 3 régressions logistiques binaire. Essayons de n'en faire qu'une seule en ajouter le label ``Y`` aux variables. Soit un couple $(X_i \\in \\mathbb{R^d}, Y_i \\in \\mathbb{N})$ qui correspond à une observation pour un problème multi-classe. Comme il y a $C$ classes, on multiplie cette ligne par le nombre de classes $C$ pour obtenir :\n",
    "\n",
    "$$\\forall c \\in \\mathbb{[}1, ..., C\\mathbb{]}, \\; \\left\\{ \\begin{array}{ll} X_i' = (X_{i,1}, ..., X_{i,d}, Y_{i,1}, ..., Y_{i,C}) \\\\ Y_i' = \\mathbb{1}_{Y_i = c} \\\\ Y_{i,k} = \\mathbb{1}_{c = k}\\end{array} \\right.$$\n",
    "\n",
    "Voyons ce que cela donne sur un exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>Y0</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y2</th>\n",
       "      <th>Y'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    X1   X2   Y0   Y1   Y2   Y'\n",
       "0  5.1  3.5  1.0  0.0  0.0  1.0\n",
       "1  5.1  3.5  0.0  1.0  0.0  0.0\n",
       "2  5.1  3.5  0.0  0.0  1.0  0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "\n",
    "\n",
    "def multiplie(X, Y, classes=None):\n",
    "    if classes is None:\n",
    "        classes = numpy.unique(Y)\n",
    "    XS = []\n",
    "    YS = []\n",
    "    for i in classes:\n",
    "        X2 = numpy.zeros((X.shape[0], 3))\n",
    "        X2[:, i] = 1\n",
    "        Yb = i == Y\n",
    "        XS.append(numpy.hstack([X, X2]))\n",
    "        Yb = Yb.reshape((len(Yb), 1))\n",
    "        YS.append(Yb)\n",
    "\n",
    "    Xext = numpy.vstack(XS)\n",
    "    Yext = numpy.vstack(YS)\n",
    "    return Xext, Yext\n",
    "\n",
    "\n",
    "x, y = multiplie(X[:1, :], Y[:1], [0, 1, 2])\n",
    "df = pandas.DataFrame(numpy.hstack([x, y]))\n",
    "df.columns = [\"X1\", \"X2\", \"Y0\", \"Y1\", \"Y2\", \"Y'\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trois colonnes ont été ajoutées côté $X$, la ligne a été multipliée 3 fois, la dernière colonne est $Y$ qui ne vaut 1 que lorsque le 1 est au bon endroit dans une des colonnes ajoutées. Le problème de classification qui été de prédire la bonne classe devient : est-ce la classe à prédire est $k$ ? On applique cela sur toutes les lignes de la base et cela donne :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>Y0</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y2</th>\n",
       "      <th>Y'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>7.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      X1   X2   Y0   Y1   Y2   Y'\n",
       "414  6.7  3.3  0.0  0.0  1.0  1.0\n",
       "125  5.5  2.5  0.0  0.0  1.0  0.0\n",
       "394  6.7  3.1  0.0  0.0  1.0  0.0\n",
       "411  6.0  2.2  1.0  0.0  0.0  0.0\n",
       "95   7.6  3.0  0.0  0.0  1.0  1.0\n",
       "64   5.8  2.6  0.0  0.0  1.0  0.0\n",
       "309  5.0  3.4  0.0  0.0  1.0  0.0\n",
       "7    6.7  3.0  0.0  1.0  0.0  0.0\n",
       "182  6.1  2.8  1.0  0.0  0.0  0.0\n",
       "49   4.7  3.2  0.0  1.0  0.0  0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xext, Yext = multiplie(X, Y)\n",
    "numpy.hstack([Xext, Yext])\n",
    "df = pandas.DataFrame(numpy.hstack([Xext, Yext]))\n",
    "df.columns = [\"X1\", \"X2\", \"Y0\", \"Y1\", \"Y2\", \"Y'\"]\n",
    "df.iloc[numpy.random.permutation(df.index), :].head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(Xext, Yext.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[278,  22],\n",
       "       [ 25, 125]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = clf.predict(Xext)\n",
    "confusion_matrix(Yext, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduire du bruit\n",
    "\n",
    "Un des problèmes de cette méthode est qu'on ajoute une variable binaire pour un problème résolu à l'aide d'une optimisation à base de gradient. C'est moyen. Pas de problème, changeons un peu la donne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>Y0</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y2</th>\n",
       "      <th>Y'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.107461</td>\n",
       "      <td>0.166893</td>\n",
       "      <td>0.018765</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.162464</td>\n",
       "      <td>1.187359</td>\n",
       "      <td>0.187721</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.086876</td>\n",
       "      <td>0.178472</td>\n",
       "      <td>1.179201</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    X1   X2        Y0        Y1        Y2   Y'\n",
       "0  5.1  3.5  1.107461  0.166893  0.018765  1.0\n",
       "1  5.1  3.5  0.162464  1.187359  0.187721  0.0\n",
       "2  5.1  3.5  0.086876  0.178472  1.179201  0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def multiplie_bruit(X, Y, classes=None):\n",
    "    if classes is None:\n",
    "        classes = numpy.unique(Y)\n",
    "    XS = []\n",
    "    YS = []\n",
    "    for i in classes:\n",
    "        # X2 = numpy.random.randn((X.shape[0]* 3)).reshape(X.shape[0], 3) * 0.1\n",
    "        X2 = numpy.random.random((X.shape[0], 3)) * 0.2\n",
    "        X2[:, i] += 1\n",
    "        Yb = i == Y\n",
    "        XS.append(numpy.hstack([X, X2]))\n",
    "        Yb = Yb.reshape((len(Yb), 1))\n",
    "        YS.append(Yb)\n",
    "\n",
    "    Xext = numpy.vstack(XS)\n",
    "    Yext = numpy.vstack(YS)\n",
    "    return Xext, Yext\n",
    "\n",
    "\n",
    "x, y = multiplie_bruit(X[:1, :], Y[:1], [0, 1, 2])\n",
    "df = pandas.DataFrame(numpy.hstack([x, y]))\n",
    "df.columns = [\"X1\", \"X2\", \"Y0\", \"Y1\", \"Y2\", \"Y'\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le problème est le même qu'avant excepté les variables $Y_i$ qui sont maintenant réel. Au lieu d'être nul, on prend une valeur  $Y_i < 0.4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>Y0</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y2</th>\n",
       "      <th>Y'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.197643</td>\n",
       "      <td>1.199976</td>\n",
       "      <td>0.180766</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.178395</td>\n",
       "      <td>0.190600</td>\n",
       "      <td>1.159765</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.188947</td>\n",
       "      <td>1.093288</td>\n",
       "      <td>0.139723</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.095428</td>\n",
       "      <td>0.182643</td>\n",
       "      <td>1.037533</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.131419</td>\n",
       "      <td>0.077241</td>\n",
       "      <td>0.177483</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.099738</td>\n",
       "      <td>0.197291</td>\n",
       "      <td>1.035431</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.069061</td>\n",
       "      <td>0.045325</td>\n",
       "      <td>1.061221</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.093164</td>\n",
       "      <td>1.177413</td>\n",
       "      <td>0.095890</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.094184</td>\n",
       "      <td>0.196944</td>\n",
       "      <td>0.083975</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.197558</td>\n",
       "      <td>0.080273</td>\n",
       "      <td>1.009379</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      X1   X2        Y0        Y1        Y2   Y'\n",
       "295  5.5  2.6  0.197643  1.199976  0.180766  1.0\n",
       "46   5.2  3.4  0.178395  0.190600  1.159765  0.0\n",
       "187  6.7  3.1  0.188947  1.093288  0.139723  1.0\n",
       "210  6.9  3.1  0.095428  0.182643  1.037533  1.0\n",
       "29   5.5  3.5  1.131419  0.077241  0.177483  1.0\n",
       "315  6.4  3.2  0.099738  0.197291  1.035431  1.0\n",
       "152  5.8  2.7  0.069061  0.045325  1.061221  0.0\n",
       "168  6.5  2.8  0.093164  1.177413  0.095890  1.0\n",
       "348  6.9  3.1  1.094184  0.196944  0.083975  0.0\n",
       "261  6.3  2.8  0.197558  0.080273  1.009379  1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xextb, Yextb = multiplie_bruit(X, Y)\n",
    "df = pandas.DataFrame(numpy.hstack([Xextb, Yextb]))\n",
    "df.columns = [\"X1\", \"X2\", \"Y0\", \"Y1\", \"Y2\", \"Y'\"]\n",
    "df.iloc[numpy.random.permutation(df.index), :].head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clfb = GradientBoostingClassifier()\n",
    "clfb.fit(Xextb, Yextb.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[299,   1],\n",
       "       [ 10, 140]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predb = clfb.predict(Xextb)\n",
    "confusion_matrix(Yextb, predb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est un petit peu mieux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaisons de plusieurs modèles\n",
    "\n",
    "On cherche maintenant à comparer le gain en introduisant du bruit pour différents modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>err1</th>\n",
       "      <th>err2</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.048889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.048889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.048889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>GaussianNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.104444</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.104444</td>\n",
       "      <td>0.091111</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>MLPClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>XGBClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        err1      err2                       model\n",
       "10  0.333333  0.333333          AdaBoostClassifier\n",
       "3   0.048889  0.000000      DecisionTreeClassifier\n",
       "4   0.048889  0.000000         ExtraTreeClassifier\n",
       "6   0.048889  0.000000        ExtraTreesClassifier\n",
       "8   0.333333  0.333333                  GaussianNB\n",
       "1   0.104444  0.044444  GradientBoostingClassifier\n",
       "9   0.104444  0.091111        KNeighborsClassifier\n",
       "0   0.333333  0.333333          LogisticRegression\n",
       "7   0.333333  0.333333               MLPClassifier\n",
       "2   0.053333  0.002222      RandomForestClassifier\n",
       "5   0.333333  0.053333               XGBClassifier"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def error(model, x, y):\n",
    "    p = model.predict(x)\n",
    "    cm = confusion_matrix(y, p)\n",
    "    return (cm[1, 0] + cm[0, 1]) / cm.sum()\n",
    "\n",
    "\n",
    "def comparaison(model, X, Y):\n",
    "    if isinstance(model, tuple):\n",
    "        clf = model[0](**model[1])\n",
    "        clfb = model[0](**model[1])\n",
    "        model = model[0]\n",
    "    else:\n",
    "        clf = model()\n",
    "        clfb = model()\n",
    "\n",
    "    Xext, Yext = multiplie(X, Y)\n",
    "    clf.fit(Xext, Yext.ravel())\n",
    "    err = error(clf, Xext, Yext)\n",
    "\n",
    "    Xextb, Yextb = multiplie_bruit(X, Y)\n",
    "    clfb.fit(Xextb, Yextb.ravel())\n",
    "    errb = error(clfb, Xextb, Yextb)\n",
    "    return dict(model=model.__name__, err1=err, err2=errb)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    AdaBoostClassifier,\n",
    ")\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "models = [\n",
    "    (LogisticRegression, dict(multi_class=\"ovr\", solver=\"liblinear\")),\n",
    "    GradientBoostingClassifier,\n",
    "    (RandomForestClassifier, dict(n_estimators=20)),\n",
    "    DecisionTreeClassifier,\n",
    "    ExtraTreeClassifier,\n",
    "    XGBClassifier,\n",
    "    (ExtraTreesClassifier, dict(n_estimators=20)),\n",
    "    (MLPClassifier, dict(activation=\"logistic\")),\n",
    "    GaussianNB,\n",
    "    KNeighborsClassifier,\n",
    "    (\n",
    "        AdaBoostClassifier,\n",
    "        dict(\n",
    "            base_estimator=LogisticRegression(multi_class=\"ovr\", solver=\"liblinear\"),\n",
    "            algorithm=\"SAMME\",\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "res = [comparaison(model, X, Y) for model in models]\n",
    "df = pandas.DataFrame(res)\n",
    "df.sort_values(\"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*err1* correspond à $Y_0, Y_1, Y_2$ binaire, *err2* aux mêmes variables mais avec un peu de bruit. L'ajout ne semble pas faire décroître la performance et l'améliore dans certains cas. C'est une piste à suivre. Reste à savoir si les modèles n'apprennent pas le bruit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avec une ACP\n",
    "\n",
    "On peut faire varier le nombre de composantes, j'en ai gardé qu'une. L'ACP est appliquée après avoir ajouté les variables binaires ou binaires bruitées. Le résultat est sans équivoque. Aucun modèle ne parvient à apprendre sans l'ajout de bruit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>err1</th>\n",
       "      <th>err2</th>\n",
       "      <th>model</th>\n",
       "      <th>errACP1</th>\n",
       "      <th>errACP2</th>\n",
       "      <th>modelACP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.048889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.048889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.048889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>GaussianNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.104444</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.224444</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.104444</td>\n",
       "      <td>0.091111</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.335556</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>MLPClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.024444</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.315556</td>\n",
       "      <td>XGBClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        err1      err2                       model   errACP1   errACP2  \\\n",
       "10  0.333333  0.333333          AdaBoostClassifier  0.333333  0.333333   \n",
       "3   0.048889  0.000000      DecisionTreeClassifier  0.333333  0.000000   \n",
       "4   0.048889  0.000000         ExtraTreeClassifier  0.333333  0.000000   \n",
       "6   0.048889  0.000000        ExtraTreesClassifier  0.333333  0.000000   \n",
       "8   0.333333  0.333333                  GaussianNB  0.333333  0.333333   \n",
       "1   0.104444  0.044444  GradientBoostingClassifier  0.333333  0.224444   \n",
       "9   0.104444  0.091111        KNeighborsClassifier  0.335556  0.340000   \n",
       "0   0.333333  0.333333          LogisticRegression  0.333333  0.333333   \n",
       "7   0.333333  0.333333               MLPClassifier  0.333333  0.333333   \n",
       "2   0.053333  0.002222      RandomForestClassifier  0.333333  0.024444   \n",
       "5   0.333333  0.053333               XGBClassifier  0.333333  0.315556   \n",
       "\n",
       "                      modelACP  \n",
       "10          AdaBoostClassifier  \n",
       "3       DecisionTreeClassifier  \n",
       "4          ExtraTreeClassifier  \n",
       "6         ExtraTreesClassifier  \n",
       "8                   GaussianNB  \n",
       "1   GradientBoostingClassifier  \n",
       "9         KNeighborsClassifier  \n",
       "0           LogisticRegression  \n",
       "7                MLPClassifier  \n",
       "2       RandomForestClassifier  \n",
       "5                XGBClassifier  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def comparaison_ACP(model, X, Y):\n",
    "    if isinstance(model, tuple):\n",
    "        clf = model[0](**model[1])\n",
    "        clfb = model[0](**model[1])\n",
    "        model = model[0]\n",
    "    else:\n",
    "        clf = model()\n",
    "        clfb = model()\n",
    "\n",
    "    axes = 1\n",
    "    solver = \"full\"\n",
    "    Xext, Yext = multiplie(X, Y)\n",
    "    Xext = PCA(n_components=axes, svd_solver=solver).fit_transform(Xext)\n",
    "    clf.fit(Xext, Yext.ravel())\n",
    "    err = error(clf, Xext, Yext)\n",
    "\n",
    "    Xextb, Yextb = multiplie_bruit(X, Y)\n",
    "    Xextb = PCA(n_components=axes, svd_solver=solver).fit_transform(Xextb)\n",
    "    clfb.fit(Xextb, Yextb.ravel())\n",
    "    errb = error(clfb, Xextb, Yextb)\n",
    "    return dict(modelACP=model.__name__, errACP1=err, errACP2=errb)\n",
    "\n",
    "\n",
    "res = [comparaison_ACP(model, X, Y) for model in models]\n",
    "dfb = pandas.DataFrame(res)\n",
    "pandas.concat([df.sort_values(\"model\"), dfb.sort_values(\"modelACP\")], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base d'apprentissage et de test\n",
    "\n",
    "Cette fois-ci, on s'intéresse à la qualité des frontières que les modèles trouvent en vérifiant sur une base de test que l'apprentissage s'est bien passé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelTT</th>\n",
       "      <th>err_train</th>\n",
       "      <th>err2_train</th>\n",
       "      <th>err2b_train_clean</th>\n",
       "      <th>err_test</th>\n",
       "      <th>err2_test</th>\n",
       "      <th>err2b_test_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>0.206667</td>\n",
       "      <td>0.273333</td>\n",
       "      <td>0.313333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.273333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.176667</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>0.246667</td>\n",
       "      <td>0.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.076667</td>\n",
       "      <td>0.073333</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156667</td>\n",
       "      <td>0.206667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.213333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.036667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.193333</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.346667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       modelTT  err_train  err2_train  err2b_train_clean  \\\n",
       "10          AdaBoostClassifier   0.333333    0.333333           0.333333   \n",
       "3       DecisionTreeClassifier   0.026667    0.000000           0.226667   \n",
       "4          ExtraTreeClassifier   0.026667    0.000000           0.253333   \n",
       "6         ExtraTreesClassifier   0.026667    0.000000           0.140000   \n",
       "8                   GaussianNB   0.333333    0.333333           0.333333   \n",
       "1   GradientBoostingClassifier   0.080000    0.013333           0.176667   \n",
       "9         KNeighborsClassifier   0.070000    0.076667           0.073333   \n",
       "0           LogisticRegression   0.333333    0.333333           0.333333   \n",
       "7                MLPClassifier   0.333333    0.333333           0.333333   \n",
       "2       RandomForestClassifier   0.026667    0.000000           0.156667   \n",
       "5                XGBClassifier   0.106667    0.036667           0.333333   \n",
       "\n",
       "    err_test  err2_test  err2b_test_clean  \n",
       "10  0.333333   0.333333          0.333333  \n",
       "3   0.206667   0.273333          0.313333  \n",
       "4   0.213333   0.253333          0.273333  \n",
       "6   0.200000   0.213333          0.220000  \n",
       "8   0.333333   0.333333          0.333333  \n",
       "1   0.186667   0.246667          0.240000  \n",
       "9   0.160000   0.160000          0.166667  \n",
       "0   0.333333   0.333333          0.333333  \n",
       "7   0.333333   0.333333          0.333333  \n",
       "2   0.206667   0.266667          0.213333  \n",
       "5   0.193333   0.280000          0.346667  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def comparaison_train_test(models, X, Y, mbruit=multiplie_bruit, acp=None):\n",
    "    axes = acp\n",
    "    solver = \"full\"\n",
    "\n",
    "    ind = numpy.random.permutation(numpy.arange(X.shape[0]))\n",
    "    X = X[ind, :]\n",
    "    Y = Y[ind]\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=1.0 / 3)\n",
    "\n",
    "    res = []\n",
    "    for model in models:\n",
    "        if isinstance(model, tuple):\n",
    "            clf = model[0](**model[1])\n",
    "            clfb = model[0](**model[1])\n",
    "            model = model[0]\n",
    "        else:\n",
    "            clf = model()\n",
    "            clfb = model()\n",
    "\n",
    "        Xext_train, Yext_train = multiplie(X_train, Y_train)\n",
    "        Xext_test, Yext_test = multiplie(X_test, Y_test)\n",
    "        if acp:\n",
    "            Xext_train_ = Xext_train\n",
    "            Xext_test_ = Xext_test\n",
    "            acp_model = PCA(n_components=axes, svd_solver=solver).fit(Xext_train)\n",
    "            Xext_train = acp_model.transform(Xext_train)\n",
    "            Xext_test = acp_model.transform(Xext_test)\n",
    "        clf.fit(Xext_train, Yext_train.ravel())\n",
    "\n",
    "        err_train = error(clf, Xext_train, Yext_train)\n",
    "        err_test = error(clf, Xext_test, Yext_test)\n",
    "\n",
    "        Xextb_train, Yextb_train = mbruit(X_train, Y_train)\n",
    "        Xextb_test, Yextb_test = mbruit(X_test, Y_test)\n",
    "        if acp:\n",
    "            acp_model = PCA(n_components=axes, svd_solver=solver).fit(Xextb_train)\n",
    "            Xextb_train = acp_model.transform(Xextb_train)\n",
    "            Xextb_test = acp_model.transform(Xextb_test)\n",
    "            Xext_train = acp_model.transform(Xext_train_)\n",
    "            Xext_test = acp_model.transform(Xext_test_)\n",
    "        clfb.fit(Xextb_train, Yextb_train.ravel())\n",
    "\n",
    "        errb_train = error(clfb, Xextb_train, Yextb_train)\n",
    "        errb_train_clean = error(clfb, Xext_train, Yext_train)\n",
    "        errb_test = error(clfb, Xextb_test, Yextb_test)\n",
    "        errb_test_clean = error(clfb, Xext_test, Yext_test)\n",
    "\n",
    "        res.append(\n",
    "            dict(\n",
    "                modelTT=model.__name__,\n",
    "                err_train=err_train,\n",
    "                err2_train=errb_train,\n",
    "                err_test=err_test,\n",
    "                err2_test=errb_test,\n",
    "                err2b_test_clean=errb_test_clean,\n",
    "                err2b_train_clean=errb_train_clean,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    dfb = pandas.DataFrame(res)\n",
    "    dfb = dfb[\n",
    "        [\n",
    "            \"modelTT\",\n",
    "            \"err_train\",\n",
    "            \"err2_train\",\n",
    "            \"err2b_train_clean\",\n",
    "            \"err_test\",\n",
    "            \"err2_test\",\n",
    "            \"err2b_test_clean\",\n",
    "        ]\n",
    "    ]\n",
    "    dfb = dfb.sort_values(\"modelTT\")\n",
    "    return dfb\n",
    "\n",
    "\n",
    "dfb = comparaison_train_test(models, X, Y)\n",
    "dfb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les colonnes *err2b_train_clean* et *err2b_test_clean* sont les erreurs obtenues par des modèles appris sur des colonnes bruitées et testées sur des colonnes non bruitées ce qui est le véritable test. On s'aperçoit que les performances sont très dégradées sur la base d'test. Une raison est que le bruit choisi ajouté n'est pas centré. Corrigeons cela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelTT</th>\n",
       "      <th>err_train</th>\n",
       "      <th>err2_train</th>\n",
       "      <th>err2b_train_clean</th>\n",
       "      <th>err_test</th>\n",
       "      <th>err2_test</th>\n",
       "      <th>err2b_test_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143333</td>\n",
       "      <td>0.193333</td>\n",
       "      <td>0.273333</td>\n",
       "      <td>0.206667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143333</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.193333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.203333</td>\n",
       "      <td>0.193333</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>0.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.193333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176667</td>\n",
       "      <td>0.206667</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.253333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.063333</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.240000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       modelTT  err_train  err2_train  err2b_train_clean  \\\n",
       "10          AdaBoostClassifier   0.333333    0.333333           0.333333   \n",
       "3       DecisionTreeClassifier   0.033333    0.000000           0.143333   \n",
       "4          ExtraTreeClassifier   0.033333    0.000000           0.143333   \n",
       "6         ExtraTreesClassifier   0.033333    0.000000           0.123333   \n",
       "8                   GaussianNB   0.333333    0.333333           0.333333   \n",
       "1   GradientBoostingClassifier   0.083333    0.013333           0.203333   \n",
       "9         KNeighborsClassifier   0.106667    0.106667           0.100000   \n",
       "0           LogisticRegression   0.333333    0.333333           0.333333   \n",
       "7                MLPClassifier   0.333333    0.333333           0.333333   \n",
       "2       RandomForestClassifier   0.040000    0.000000           0.176667   \n",
       "5                XGBClassifier   0.080000    0.063333           0.170000   \n",
       "\n",
       "    err_test  err2_test  err2b_test_clean  \n",
       "10  0.333333   0.333333          0.333333  \n",
       "3   0.193333   0.273333          0.206667  \n",
       "4   0.226667   0.233333          0.180000  \n",
       "6   0.200000   0.213333          0.193333  \n",
       "8   0.333333   0.333333          0.333333  \n",
       "1   0.193333   0.226667          0.280000  \n",
       "9   0.180000   0.180000          0.193333  \n",
       "0   0.333333   0.333333          0.333333  \n",
       "7   0.333333   0.333333          0.333333  \n",
       "2   0.206667   0.240000          0.253333  \n",
       "5   0.186667   0.220000          0.240000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def multiplie_bruit_centree(X, Y, classes=None):\n",
    "    if classes is None:\n",
    "        classes = numpy.unique(Y)\n",
    "    XS = []\n",
    "    YS = []\n",
    "    for i in classes:\n",
    "        # X2 = numpy.random.randn((X.shape[0]* 3)).reshape(X.shape[0], 3) * 0.1\n",
    "        X2 = numpy.random.random((X.shape[0], 3)) * 0.2 - 0.1\n",
    "        X2[:, i] += 1\n",
    "        Yb = i == Y\n",
    "        XS.append(numpy.hstack([X, X2]))\n",
    "        Yb = Yb.reshape((len(Yb), 1))\n",
    "        YS.append(Yb)\n",
    "\n",
    "    Xext = numpy.vstack(XS)\n",
    "    Yext = numpy.vstack(YS)\n",
    "    return Xext, Yext\n",
    "\n",
    "\n",
    "dfb = comparaison_train_test(models, X, Y, mbruit=multiplie_bruit_centree, acp=None)\n",
    "dfb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est mieux mais on en conclut que dans la plupart des cas, la meilleure performance sur la base d'apprentissage avec le bruit ajouté est due au fait que les modèles apprennent par coeur. Sur la base de test, les performances ne sont pas meilleures. Une erreur de 33% signifie que la réponse du classifieur est constante. On multiplie les exemples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelTT</th>\n",
       "      <th>err_train</th>\n",
       "      <th>err2_train</th>\n",
       "      <th>err2b_train_clean</th>\n",
       "      <th>err_test</th>\n",
       "      <th>err2_test</th>\n",
       "      <th>err2b_test_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.209333</td>\n",
       "      <td>0.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073333</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.232000</td>\n",
       "      <td>0.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>0.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.086667</td>\n",
       "      <td>0.087333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>0.186667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.094667</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.113333</td>\n",
       "      <td>0.158667</td>\n",
       "      <td>0.153333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.226667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.123333</td>\n",
       "      <td>0.108667</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.153333</td>\n",
       "      <td>0.204000</td>\n",
       "      <td>0.193333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       modelTT  err_train  err2_train  err2b_train_clean  \\\n",
       "10          AdaBoostClassifier   0.333333    0.333333           0.333333   \n",
       "3       DecisionTreeClassifier   0.040000    0.000000           0.120000   \n",
       "4          ExtraTreeClassifier   0.040000    0.000000           0.073333   \n",
       "6         ExtraTreesClassifier   0.040000    0.000000           0.066667   \n",
       "8                   GaussianNB   0.333333    0.333333           0.333333   \n",
       "1   GradientBoostingClassifier   0.086667    0.087333           0.166667   \n",
       "9         KNeighborsClassifier   0.110000    0.094667           0.106667   \n",
       "0           LogisticRegression   0.333333    0.333333           0.333333   \n",
       "7                MLPClassifier   0.333333    0.333333           0.333333   \n",
       "2       RandomForestClassifier   0.046667    0.000667           0.090000   \n",
       "5                XGBClassifier   0.123333    0.108667           0.173333   \n",
       "\n",
       "    err_test  err2_test  err2b_test_clean  \n",
       "10  0.333333   0.333333          0.333333  \n",
       "3   0.180000   0.209333          0.240000  \n",
       "4   0.213333   0.232000          0.220000  \n",
       "6   0.213333   0.168000          0.160000  \n",
       "8   0.333333   0.333333          0.333333  \n",
       "1   0.173333   0.192000          0.186667  \n",
       "9   0.113333   0.158667          0.153333  \n",
       "0   0.333333   0.333333          0.333333  \n",
       "7   0.333333   0.333333          0.333333  \n",
       "2   0.160000   0.188000          0.226667  \n",
       "5   0.153333   0.204000          0.193333  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def multiplie_bruit_centree_duplique(X, Y, classes=None):\n",
    "    if classes is None:\n",
    "        classes = numpy.unique(Y)\n",
    "    XS = []\n",
    "    YS = []\n",
    "    for i in classes:\n",
    "        for k in range(5):\n",
    "            # X2 = numpy.random.randn((X.shape[0]* 3)).reshape(X.shape[0], 3) * 0.3\n",
    "            X2 = numpy.random.random((X.shape[0], 3)) * 0.8 - 0.4\n",
    "            X2[:, i] += 1\n",
    "            Yb = i == Y\n",
    "            XS.append(numpy.hstack([X, X2]))\n",
    "            Yb = Yb.reshape((len(Yb), 1))\n",
    "            YS.append(Yb)\n",
    "\n",
    "    Xext = numpy.vstack(XS)\n",
    "    Yext = numpy.vstack(YS)\n",
    "    return Xext, Yext\n",
    "\n",
    "\n",
    "dfb = comparaison_train_test(\n",
    "    models, X, Y, mbruit=multiplie_bruit_centree_duplique, acp=None\n",
    ")\n",
    "dfb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cela fonctionne un peu mieux le fait d'ajouter du hasard ne permet pas d'obtenir des gains significatifs à part pour le modèle [SVC](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelTT</th>\n",
       "      <th>err_train</th>\n",
       "      <th>err2_train</th>\n",
       "      <th>err2b_train_clean</th>\n",
       "      <th>err_test</th>\n",
       "      <th>err2_test</th>\n",
       "      <th>err2b_test_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.193333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.246667</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143333</td>\n",
       "      <td>0.206667</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.206667</td>\n",
       "      <td>0.186667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.103333</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.123333</td>\n",
       "      <td>0.206667</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.186667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.173333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.206667</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.246667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       modelTT  err_train  err2_train  err2b_train_clean  \\\n",
       "10          AdaBoostClassifier   0.333333    0.333333           0.333333   \n",
       "3       DecisionTreeClassifier   0.033333    0.000000           0.143333   \n",
       "4          ExtraTreeClassifier   0.033333    0.000000           0.246667   \n",
       "6         ExtraTreesClassifier   0.033333    0.000000           0.143333   \n",
       "8                   GaussianNB   0.333333    0.333333           0.333333   \n",
       "1   GradientBoostingClassifier   0.090000    0.013333           0.133333   \n",
       "9         KNeighborsClassifier   0.103333    0.110000           0.123333   \n",
       "0           LogisticRegression   0.333333    0.333333           0.333333   \n",
       "7                MLPClassifier   0.333333    0.333333           0.333333   \n",
       "2       RandomForestClassifier   0.040000    0.000000           0.146667   \n",
       "5                XGBClassifier   0.100000    0.033333           0.210000   \n",
       "\n",
       "    err_test  err2_test  err2b_test_clean  \n",
       "10  0.333333   0.333333          0.333333  \n",
       "3   0.200000   0.233333          0.193333  \n",
       "4   0.233333   0.320000          0.300000  \n",
       "6   0.206667   0.220000          0.180000  \n",
       "8   0.333333   0.333333          0.333333  \n",
       "1   0.220000   0.206667          0.186667  \n",
       "9   0.206667   0.180000          0.186667  \n",
       "0   0.333333   0.333333          0.333333  \n",
       "7   0.333333   0.333333          0.333333  \n",
       "2   0.180000   0.266667          0.173333  \n",
       "5   0.206667   0.240000          0.246667  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def multiplie_bruit_centree_duplique_rebalance(X, Y, classes=None):\n",
    "    if classes is None:\n",
    "        classes = numpy.unique(Y)\n",
    "    XS = []\n",
    "    YS = []\n",
    "    for i in classes:\n",
    "        X2 = numpy.random.random((X.shape[0], 3)) * 0.8 - 0.4\n",
    "        X2[:, i] += 1  # * ((i % 2) * 2 - 1)\n",
    "        Yb = i == Y\n",
    "        XS.append(numpy.hstack([X, X2]))\n",
    "        Yb = Yb.reshape((len(Yb), 1))\n",
    "        YS.append(Yb)\n",
    "\n",
    "    Xext = numpy.vstack(XS)\n",
    "    Yext = numpy.vstack(YS)\n",
    "    return Xext, Yext\n",
    "\n",
    "\n",
    "dfb = comparaison_train_test(\n",
    "    models, X, Y, mbruit=multiplie_bruit_centree_duplique_rebalance\n",
    ")\n",
    "dfb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Petite explication\n",
    "\n",
    "Dans tout le notebook, le score de la régression logistique est nul. Elle ne parvient pas à apprendre tout simplement parce que le problème choisi n'est pas linéaire séparable. S'il l'était, cela voudrait dire que le problème suivant l'est aussi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0., 0., 1.],\n",
       "        [0., 1., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0., 0., 1.],\n",
       "        [0., 0., 1., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0., 1.]]), array([[1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = numpy.zeros((9, 6))\n",
    "Y = numpy.zeros((9, 1))\n",
    "for i in range(9):\n",
    "    M[i, i // 3] = 1\n",
    "    M[i, i % 3 + 3] = 1\n",
    "    Y[i] = 1 if i // 3 == i % 3 else 0\n",
    "M, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(multi_class=\"ovr\", solver=\"liblinear\")\n",
    "clf.fit(M, Y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A revisiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}