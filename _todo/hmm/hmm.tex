\input{../../common/livre_begin.tex}
\firstpassagedo{\input{hmm_titre.tex}}
\input{../../common/livre_table_begin.tex}
\firstpassagedo{\input{hmm_chapter.tex}}




\indexsee{mod�le de Markov cach�}{MMC}
\indexfr{MMC}
\indexsee{cha�ne de Markov cach�e}{MMC}
\indexsee{Hidden Markov Model}{MMC}
\indexfr{HMM}



\label{annexe_hmm_def}




Cette annexe d�taille les concepts et les propri�t�s des mod�les de Markov cach�s en �vitant aussi souvent que possible les r�f�rences � la reconnaissance de l'�criture manuscrite.





%------------------------------------------------------------------------------------------------------------------
\section{Cha�ne de Markov}
%------------------------------------------------------------------------------------------------------------------
\indexfr{cha�ne de Markov}

\subsection{D�finition}

\indexfr{s�quence}
\indexfr{�tat}

Une cha�ne de Markov est un mod�le probabiliste mod�lisant des s�quences de symboles appartenant � un ensemble fini. Ces s�quences peuvent �tre consid�r�es �galement comme des suites enti�res finies.

        \begin{xdefinition}{cha�ne de Markov}
        \label{markov_chaine_definition}%
        Soit $M$ une cha�ne de Markov.\newline
        Soit $Q = \intervalle{1}{N}$ l'ensemble des �tats.\newline
        Soit $S=\underset{T=1} {\overset{+\infty}{\cup}} Q^T$ l'espace des s�quences.\newline
        On note $s = \pa{q_1,\dots,q_{T_s}} \in S$ une s�quence de longueur $T_s$.\newline
        \indexfrr{mod�le}{probabiliste}
        Une cha�ne de Markov est un mod�le probabiliste sur $S$ v�rifiant les deux hypoth�ses suivantes~:
                \begin{enumerate}
                \item L'�tat � l'instant $t$ ne d�pend que de l'�tat � l'instant $t-1$~:
                    $$
                    \forall s \in S, \; \forall t \in \intervalle{2}{T_s}, \; 
                                \pr{q_t \sachant \vecteurno{q_1}{q_{t-1}},M} = \pr{q_t \sachant q_{t-1},M}
                    $$
                    On appelle $\pr{q_t \sachant q_{t-1},M}$ la \emph{probabilit� de transition}
                    \indexfrr{probabilit�}{transition}
                    de l'�tat $q_{t-1}$ � l'�tat $q_t$ � l'instant $t$.
                \item Les probabilit�s de transition ne d�pendent pas du temps~:
                    $$
                    \forall s \in S, \; \forall \pa{t,t'} \in \intervalle{2}{T_s}, \; 
                                \pr{q_t \sachant q_{t-1},M} = \pr{q_{t'} \sachant q_{t'-1},M}
                    $$
                \end{enumerate}
        \end{xdefinition}



Afin de simplifier les notations ult�rieurement, on d�finit pour la cha�ne de Markov $M$, la matrice des probabilit�s de transition $A_M \in M_N\pa{\R}$~: \indexfrr{notation}{probabilit� de transition}

        \begin{eqnarray}
        A_{M}=  \pa {  a_{M,ij} }                              _{\substack{1\leqslant i\leqslant N\\1\leqslant j\leqslant N}} =
                \pa{  \pr{  q_{t}=j \sachant q_{t-1} =i,M } }  _{\substack{1\leqslant i\leqslant N\\1\leqslant j\leqslant N}}
        \label{hmm_eq_1}
        \end{eqnarray}

On d�finit �galement le vecteur des probabilit�s d'entr�es $\pi_M \in \R^N$ :

        \begin{eqnarray}
        \forall i\in \ensemble{1}{N} ,\, \pi_{M,i}=\pa { q_{1}=i \sachant  M }
        \label{hmm_eq_2}
        \end{eqnarray}

            \begin{xproperty}{contrainte}
            \label{propriete_mmc_contrainte_1}%
            La d�finition~\ref{markov_chaine_definition} d'une cha�ne de Markov et ses param�tres d�finis en 
            (\ref{hmm_eq_1}) et (\ref{hmm_eq_2}) implique que~:
                    \begin{eqnarray*}
                    \forall i \in \ensemble{1}{N} , \,\summy{j=1}{N}a_{M,ij}&=&1 \text{ et } \summy{j=1}{N} \,\pi_{M,j} = 1
                    \end{eqnarray*}
            Par abus de notation, on �crira $a_{ij}=a_{M,ij}$, et $\pi_{i}=\pi_{M,i}$
            \end{xproperty}


La d�finition d'une cha�ne de Markov simplifie l'�criture de la probabilit� d'une s�quence~:

        \begin{xproperty}{probabilit� d'une s�quence}
        La d�finition~\ref{markov_chaine_definition} d'une cha�ne de Markov et ses param�tres d�finis en (\ref{hmm_eq_1}) et
             (\ref{hmm_eq_2}) implique que~:
                \begin{eqnarray*}
                \pr{s|M}        &=& \pr{q_1,\dots,q_T \sachant M} = \pr{q_1 \sachant M}\prody{t=2}{T}
                                                                 \pr{q_t \sachant \overline{q_{t-1}},M} 
                                = \pi_{q_1} \prody{t=2}{T_s} a_{q_{t-1},q_t}
                \end{eqnarray*}
        \end{xproperty}









\subsection{Exemple : pi�ce de monnaie truqu�e} \label{chaine_markov_exemple}

\indexfrr{cha�ne de Markov}{exemple}%
\indexfrr{exemple}{pi�ce de monnaie}

\para{Enonc�}

On consid�re une pi�ce truqu�e qui a $7$ chances sur $10$ de retomber sur pile (�tat $1$), et $3$ chances sur $10$ de retomber sur face (�tat $2$), et une vraie pi�ce. Si la face pile tombe, c'est la vraie pi�ce qui sera jou�e, sinon, ce sera la pi�ce truqu�e. La premi�re jou�e est tir�e au hasard. La cha�ne de Markov correspondant � ce probl�me est d�finie par les probabilit�s suivantes~:

        $$
        \begin{array}
        [c]{ccccc}%
        \pr{  q_{1}=1 }  =0,5 &  & \pr{  q_{t}=1 \sac  q_{t-1}=1 }  =0,5 &  & \pr{ q_{t}=1 \sac q_{t-1}=2 }  =0,7\\
        \pr{  q_{1}=2 }  =0,5 &  & \pr{  q_{t}=2 \sac  q_{t-1}=1 }  =0,5 &  & \pr{ q_{t}=2 \sac q_{t-1}=2 }  =0,3
        \end{array}
        $$

Par cons�quent :

        $$
        \begin{array}{ccc}
                A=\pa{
                    \begin{array}{cc}%
                    0,5 & 0,5\\
                    0,7 & 0,3
                    \end{array}
                }
            &
            \text{ et }
            &
                \pi=\pa{
                    \begin{array}{c}
                    0,5\\
                    0,5
                    \end{array}
                }
        \end{array}
        $$

Ce mod�le peut �tre repr�sent� graphiquement par un sch�ma utilisant des graphes o� chaque n\oe ud est un �tat du mod�le et chaque probabilit� de transition positive un arc du graphe (voir figure~\ref{figure_chaine_markov_exemple-fig}). Plus de d�tails sont donn�s dans le paragraphe~\ref{hmm_representation_graphe}.


        \begin{figure}[ht]
        $$
        \frame{
        \filefig{../hmm/fig_markov}
        }
        $$
        \caption{Repr�sentation d'une cha�ne de Markov sous forme de graphe.}
        \label{figure_chaine_markov_exemple-fig}
        \indexfrr{cha�ne de Markov}{graphe}%
        \end{figure}


\para{R�sultats int�ressants}

Cette mod�lisation simple permet d'obtenir la probabilit� que la face pile apparaisse � un instant donn�, et de d�finir le gain que peut esp�rer un tricheur en utilisant sa pi�ce truqu�e. On s'int�resse d'abord �~:

        $$
        \pr{  q_{t}=j \sac  q_{t-2}=i,M  }  = \summy{k=1}{N} \pr{ q_{t}=j \sac  q_{t-1}=k,M }
        \pr{  q_{t-1}=k \sac  q_{t-2}=i,M }   = \pa {  A_{M} ^{2} }  _{i,j}
        $$

Par r�currence, on en d�duit que :

        $$
        \pr{  q_{t}=j \sac q_{t-d}=i,M } = \pa {  A_{M}^{d} }  _{i,j}
        $$

On note $\pi'_M$ la transpos�e de la matrice $\pi_M$, on obtient alors que :

        $$
        \pi'_M \pa {  A_{M}^{t} } = \pa {  \pr {   q_{t}=i \sac   M } } _{1\leqslant i\leqslant N}
        $$

Finalement, cette formule appliqu�e � l'exemple pr�c�dent donne :

        $$
        \underset{t\rightarrow+\infty}{\lim}    \pr{   q_{t}=1 }  =\frac{7}{12} \text{ et }
        \underset{t\rightarrow+\infty}{\lim}    \pr{   q_{t}=2 }  =\frac{5}{12}%
        $$

Les lois limites des �tats sont utiles pour calculer une esp�rence de gain. Si le joueur gagne un franc lorsque la face pile sort et perd un franc dans l'autre cas, sur une suite de douze coups, il gagne en moyenne deux francs. On peut �galement calculer la probabilit� d'une s�quence de quatre gain cons�cutifs~:

        $$
        \pr {  1111 \sac M }  =0,5\ast0,3\ast0,3\ast0,3=0,0135
        $$












%----------------------------------------------------------------------------------------------------------------------
\section{Cha�ne de Markov cach�e}
%----------------------------------------------------------------------------------------------------------------------
\label{interdoc_mmc}

Il n'est pas �vident qu'un processus (ou s�quence de variables al�atoires) suive la loi d'une cha�ne de Markov, n�anmoins, ce processus peut parfois �tre expliqu� par un autre cach� qui suit la loi d'une cha�ne de Markov. Ce second processus est dit cach� car le premier, celui qu'il explique, est le seul observ�. Afin de comprendre ce concept, l'exemple pr�c�dent (paragraphe~\ref{chaine_markov_exemple}) sera l�g�rement modifi� de mani�re � pr�senter les cha�nes de Markov cach�es.

\subsection{Exemple : pi�ce de monnaie truqu�e}

\indexfrr{exemple}{pi�ce de monnaie}
\label{chaine_markov_cachee_exemple}

Dans l'exemple des deux pi�ces truqu�e et non truqu�e (paragraphe~\ref{chaine_markov_exemple}), les �tats de la cha�ne de Markov et faces des pi�ces �taient identiques. Les �tats correspondent maintenant aux pi�ces (information cach�e) et les observations correspondent aux faces (information observ�e). L'�tat $1$ sera la pi�ce non truqu�e et l'�tat $2$ sera la pi�ce truqu�e. On suppose que la d�cision du joueur concernant le choix de la pi�ce ne d�pend plus de la face qui appara�t apr�s le lancer mais d�pend du choix de la pi�ce au lancer pr�c�dent. Les probabilit�s de transition sont d�finies ainsi~:

        $$
        \begin{array}[c]{ccccc}%
        \pr {  q_{1}=1 }  =0,5 &  & \pr {  q_{t}=1 \sac  q_{t-1}=1 }  =0,5 &  & \pr{  q_{t}=1 \sac  q_{t-1}=2 }=0,7\\
        \pr {  q_{1}=2 }  =0,5 &  & \pr {  q_{t}=2 \sac  q_{t-1}=1 }  =0,5 &  & \pr{  q_{t}=2 \sac  q_{t-1}=2 }=0,3
        \end{array}
        $$

De chaque �tat d�pendent les probabilit�s de voir appara�tre pile ou face. On note $O_t$ la face qui appara�t � l'instant $t$,
les probabilit�s qui suivent sont appel�es \emph{probabilit�s d'�mission}.\indexfrr{probabilit�}{�mission}

        $$
        \begin{array}[c]{ccc}%
        \pr {  O_{t}=1 \sac  q_{t}=1 }  =0,5 &  & \pr {O_{t}=1 \sac  q_{t}=2 }  =0,7\\
        \pr {  O_{t}=2 \sac  q_{t}=1 }  =0,5 &  & \pr {O_{t}=2 \sac  q_{t}=2 }  =0,3
        \end{array}
        $$

\indexfrr{MMC}{graphe}

Ce mod�le peut toujours �tre repr�sent� graphiquement par un sch�ma utilisant des graphes (figure~\ref{figure_chaine_markov_cachee_exemple-fig}). Plus de d�tails seront donn�s au paragraphe~\ref{hmm_representation_graphe}.


        \begin{figure}[ht]
        $$
        \frame{
        \filefig{../hmm/fig_hmarkov}
        }
        $$
        \caption{Repr�sentation d'une cha�ne de Markov sous forme de graphe.}
        \label{figure_chaine_markov_cachee_exemple-fig}
        \indexfrr{cha�ne de Markov}{graphe}%
        \end{figure}


On cherche alors � calculer probabilit� de la s�quence $1111$ qui correspond � une s�rie de quatre "face". Si la s�quence d'observations est connue, il n'en est pas de m�me pour la s�quence d'�tats (ou pi�ces) : il faut les envisager toutes et conna�tre la probabilit� d'�mettre une s�rie de quatre "face" pour chacune d'elles. La r�ponse n�cessite d'abord de d�finir ce qu'est math�matiquement une cha�ne de Markov cach�e car le calcul n'est plus aussi �vident que pour celui des cha�nes de Markov non cach�es.








\subsection{D�finition d'une cha�ne de Markov cach�e}

Une cha�ne de Markov cach�e part de l'id�e que le processus stochatisque observ� (la s�quence d'observations) est expliqu� par un autre processus (la s�quence d'�tats) qui est inconnu.



        \begin{xdefinition} {cha�ne de Markov cach�e}
        \label{markov_chaine_cachee_definition}%
        Soit $M$ une cha�ne de Markov cach�e,\newline%
        Soit $Q = \intervalle{1}{N}$ l'ensemble des �tats,\newline%
        Soit $S=\underset{T=1} {\overset{+\infty}{\cup}} Q^T$ l'espace des s�quences d'�tats,\newline%
        Soit $\mathcal{O} = \intervalle{1}{D}$ l'ensemble des observations,\newline%
        Soit $\mathbf{O}=\underset{T=1} {\overset{+\infty}{\cup}} \mathcal{O}^T$ l'espace des s�quences d'observations,\newline%
        On note $s = \pa{q_1,\dots,q_{T_s}} \in S$ une s�quence de longueur $T_s$,\newline%
        Soit $O = \pa{O_1,\dots,O_{T_O}} \in \mathbf{O}$ une s�quence de longueur $T_O$,\newline%
        Alors une cha�ne de Markov cach�e est un mod�le probabiliste v�rifiant les quatre conditions suivantes~:
        
                \begin{enumerate}
                \item L'observation � l'instant $t$ ne d�pend que de l'�tat � l'instant $t$~:
                
                \indexfrr{probabilit�}{transition}
                        \indexfrr{probabilit�}{�mission}
                        \indexfrr{probabilit�}{entr�e}
                        
                    $$
                    \forall s \in S \text{ telle que } T_s = T_O, \; \forall t \in \intervalle{1}{T_O}, \;
                    \pr{O_t|\overline{q_t},\overline{O_{t-1}},M} = \pr{O_t|q_t,M}
                    $$
                    On appelle $\pr{O_t|q_t,M}$ la \emph{probabilit� d'�mission} de l'observation $O_t$ 
                                sachant l'�tat $q_t$ � l'instant $t$.
                \item Les probabilit�s d'�missions ne d�pendent pas du temps :
                    $$
                    \forall s \in S \text{ telle que } T_s = T_O, \; 
                            \forall \pa{t,t'} \in \intervalle{2}{T_s}, \; \pr{O_t|q_t,M} = \pr{O_{t'}|q_{t'},M}
                    $$
                \item L'�tat � l'instant $t$ ne d�pend que de l'�tat � l'instant $t-1$~:
                    $$
                    \forall s \in S \text{ telle que } T_s = T_O, \; \forall t \in \intervalle{2}{T_s}, \;
                    \pr{q_t| \overline{q_{t-1}},\overline{O_{t-1}},M} = \pr{q_t|q_{t-1},M}
                    $$
                    On appelle $\pr{q_t|q_{t-1},M}$ la \emph{probabilit� de transition} de l'�tat $q_{t-1}$ � l'�tat $q_t$ � l'instant $t$.
                \item Les probabilit�s de transition ne d�pendent pas du temps~:
                    $$
                    \forall s \in S \text{ telle que } T_s = T_O, \; \forall \pa{t,t'} 
                            \in \intervalle{2}{T_s}, \; \pr{q_t|q_{t-1},M} = \pr{q_{t'}|q_{t'-1},M}
                    $$
                \end{enumerate}
        \end{xdefinition}



Etant donn� que ni les probabilit�s de transitions ni les probabilit�s d'�missions ne d�pendent du temps, on d�finit pour le mod�le $M$ � $N$ �tats, les matrices $A_M$, $B_M$ et le vecteur $\Pi_M$ par ~:

\indexfrr{probabilit�}{transition}
\indexfrr{probabilit�}{�mission}
\indexfrr{probabilit�}{entr�e}

        \begin{eqnarray*}
        A_M    &=& \pa {  a_{M,ij} } _ {\substack{ 1\leqslant i\leqslant N\\1\leqslant j\leqslant N}} =
                   \pa{ \pr {  q_{t}=j \sac  q_{t-1} =i,M } } _{\substack{1\leqslant i\leqslant N\\1\leqslant j\leqslant N}}
                    \label{hmm_contrainte_1}\\
        B_M    &=& \pa{   b_{M,ij} } _ {\substack{1\leqslant i\leqslant N\\1\leqslant j\leqslant D}}=
                   \pa { \pr{ O_{t}=j \sac  q_{t}=i,M } }     _ {\substack{1\leqslant i\leqslant N\\1\leqslant j\leqslant D}}
                    \label{hmm_contrainte_2}\\
        \Pi_M  &=& \pa { \pi_{M,i} } _ { 1 \infegal i \infegal N } = \pa { \pr {  q_1 = i \sac M} } _ { 1 \infegal i \infegal N }
                             \label{hmm_contrainte_3}
        \end{eqnarray*}


La d�finition d'une cha�ne de Markov cach�e implique les contraintes suivantes sur les param�tres $A_M$, $B_M$, $\Pi_M$
r�sum�es par la propri�t� suivante~:


        \begin{xproperty}{contrainte}
        \label{propriete_mmc_contrainte}%
        La d�finition~\ref{markov_chaine_cachee_definition} et les notations d�finies en (\ref{hmm_contrainte_1}),
        (\ref{hmm_contrainte_2}) et (\ref{hmm_contrainte_3}) impliquent que~:
        
                \begin{eqnarray*}
                \forall i\in \ensemble{1}{N}, \; &&\summy{j=1}{N} \; a_{M,ij}=1 \text{ et }
                                                                                    \summy{j=1}{N} \; b_{M,ij}=1 \\
                                                 &&\summy{i=1}{N} \; \Pi_{M,i} = 1
                \end{eqnarray*}
        \end{xproperty}


Par abus de notation, lorsqu'il n'y a aucune ambigu�t�, on note $A=A_M$, $B=B_M$, $\Pi=\Pi_M$. On cherche maintenant � exprimer la probabilit� d'une s�quence d'observations, soit $O \in \mathbf{O}$, on peut dor�navant d�finir~:

\indexfrr{probabilit�}{s�quence}
\indexfrr{s�quence}{observation}

        \begin{eqnarray*}
        \pr{O \sac M} &=&   \summyone{\begin{subarray}{c}s \in S \\ T_s = T_O \end{subarray}}
                            \pr{O,s|M} \\
        \pr{O \sac M} &=&   \summyone{\begin{subarray}{c}s \in S \\ T_s = T_O \end{subarray}}
                            \pr{\vecteurno{O_1}{O_{T_O}},\vecteurno{s_1}{s_{T_s}}|M}
        \end{eqnarray*}

En utilisant les hypoth�ses de la d�finition~\ref{markov_chaine_cachee_definition}, on cherche � exprimer cette probabilit�
� l'aide des param�tres $A$, $B$, $\Pi$ du mod�le $M$~:

        \begin{eqnarray}
        \pr{O|M} &=&   \summyone{\begin{subarray}{c}s \in S \\ T_s = T_O \end{subarray}}
                        \pr{O,s|M} \nonumber\\
        \pr{O|M} &=&   \summyone{\begin{subarray}{c}s \in S \\ T_s = T_O \end{subarray}}
                        \pr{O_{T_O}|s_{T_s},M}
                        \pr{s_{T_s}|s_{T_s-1},M}
                        \pr{\vecteurno{O_1}{O_{T_O-1}},\vecteurno{s_1}{s_{T_s-1}}|M} \nonumber\\
        \pr{O|M} &=&   \summyone{\begin{subarray}{c}s \in S \\ T_s = T_O \end{subarray}}
                        \crochet{ \pr{s_1|M} \prody{t=2}{T_O}\pr{s_t|s_{t-1},M} \prody{t=1}{T_O} \pr{O_t|s_t,M} } \nonumber\\
        \pr{O|M} &=&   \summyone{\begin{subarray}{c}s \in S \\ T_s = T_O \end{subarray}}
                        \crochet{ \pi_{s_1} \prody{t=2}{T_O}a_{s_{t-1},s_t} \prody{t=1}{T_O} b_{q_t}\pa{O_t} }
                         \label{mmc_expression_proba_seq}
        \end{eqnarray}

N�anmoins, cette expression (\ref{mmc_expression_proba_seq}) suppose un calcul co�teux en temps,
il est n�cessaire de factoriser certaines op�rations.

\indexfr{factoriser}







\subsection{Calcul factoris� de la probabilit� d'une s�quence}

\label{hmm_alpha_definition_forward}

Soit $O=\vecteur{O_1}{O_T}$ une s�quence d'observations, les s�quences d'�tats seront not�es $s=\vecteur{q_1}{q_T}$. On pose pour $1\leqslant i\leqslant N$ et $1\leqslant t\leqslant T$ :

        \begin{eqnarray}
        \alpha_{t} \pa{i}  = \alpha_{M,t} \pa{i}  = \pr{  q_{t}=i,O_{1},...,O_{t} \sac  M } \label{hmm_eq_alpha_1}
        \end{eqnarray}

Pour $t=1$, on obtient pour tout $i \in \ensemble{1}{N}$~:

        \begin{eqnarray}
        \alpha_{1} \pa{i} &=& \pr{ q_{1}=i,O_{1} \sac M }  = \pr{   O_{1} \sac  q_{1}=i,M}
                              \pr{ q_{1}=i       \sac M } \nonumber \\
                          &=& \pi_{i}b_{i,O_{1}} \label{mmc_alpha_forward_1} \label{hmm_eq_alpha_2}
        \end{eqnarray}

\indexfr{forward}
\indexfr{$\alpha_t\pa{.}$}

On �tablit la r�currence suivante sur $t$ et pour tout $j \in \ensemble{1}{N}$~:

        \begin{eqnarray}
        \alpha_{t+1}\pa{j}  &=& \pr{ q_{t+1}=j,O_{1},...,O_{t+1} \sac M } \nonumber\\
        \alpha_{t+1}\pa{j}  &=& \pr{ O_{t+1} \sac  q_{t+1}=j,O_{1},...,O_{t},M }
                                \pr{ q_{t+1}=j,O_{1},...,O_{t} \sac M } \nonumber\\
        \alpha_{t+1}\pa{j}  &=& \pr{ O_{t+1} \sac  q_{t+1}=j,M } \;
                                \summy{i=1}{N} \; \pr{ q_{t+1}=j,q_{t}=i,O_{1},...,O_{t} \sac  M} \nonumber\\
        \alpha_{t+1}\pa{j}  &=& b_{j}\pa{O_{t+1}} \; \summy{i=1}{N} \; \pr {  q_{t+1}=j \sac  q_{t}=i,O_{1},...,O_{t},M }
                                                                       \pr {  q_{t}=i,O_{1},...,O_{t} \sac  M } \nonumber\\
        \alpha_{t+1}\pa{j}  &=& b_{j}\pa{O_{t+1}} \; \summy{i=1}{N} \; a_{ij} \, \alpha_{t} \pa{i}
             \label{mmc_alpha_forward_2}\label{hmm_eq_alpha_3}
        \end{eqnarray}

Finalement, la probabilit� de la s�quence est obtenue gr�ce � la suite $\alpha_t\pa{.}$ par un calcul appel� \emph{forward}~:

\indexfr{forward}
        
        \begin{eqnarray}
        \pr {O_{1},...,O_{T} \sac M}  = \summy{i=1}{N} \alpha_{T}\pa{i}\label{hmm_eq_alpha_4}
        \end{eqnarray}

De ces formules, on tire l'algorithme suivant permettant de calculer la probabilit� d'une s�quence d'observations.

        \begin{xalgorithm}{forward} \label{hmm_algo_forward}
        Les notations utilis�es sont celles des formules (\ref{hmm_eq_alpha_1}), (\ref{hmm_eq_alpha_2}),
        (\ref{hmm_eq_alpha_3}), (\ref{hmm_eq_alpha_4}).
        
        \begin{xalgostep}{initialisation}
                \begin{xfor}{i}{1}{N}
                $\alpha_1\pa{i} \longleftarrow \pi_{i}b_{i,O_{1}}$
                \end{xfor}
        \end{xalgostep}
        
        \begin{xalgostep}{r�currence}
                \begin{xfor}{t}{2}{T}
                        \begin{xfor}{j}{1}{N}
                                $\alpha_{t}\pa{j} \longleftarrow 0$ \\
                                \begin{xfor}{i}{1}{N}
                                        $\alpha_{t}\pa{j} \longleftarrow \alpha_{t}\pa{j} + a_{ij} \, \alpha_{t-1} \pa{i}$
                                \end{xfor} \\
                                $\alpha_{t}\pa{j} \longleftarrow \alpha_{t}\pa{j} \; b_{j}\pa{O_{t+1}}$
                        \end{xfor}
                \end{xfor}
        \end{xalgostep}
        
        \begin{xalgostep}{terminaison}
                $p \longleftarrow 0$ \\
                \begin{xfor}{i}{1}{N}
                        $p \longleftarrow p + \alpha_{T}\pa{i}$
                \end{xfor}
        \end{xalgostep}
        
        La probabilit� de la s�quence $\vecteur{O_1}{O_T}$ est $p$ obtenue � la derni�re �tape.
        
        \end{xalgorithm}
        
        






De la m�me mani�re, on d�finit pour $1\leqslant i\leqslant N$ et $1\leqslant t\leqslant T$ la suite~:

\indexfr{$\beta_t\pa{.}$}
\indexfr{backward}

        \begin{eqnarray}
        \beta_{t}\pa{i}  = \beta_{M,t}\pa{i}  = \pr{   O_{t+1} ,...,O_{T} \sac q_{t}=i,M} \label{hmm_eq_beta_1}
        \end{eqnarray}

Par un calcul analogue � (\ref{mmc_alpha_forward_1}) et (\ref{mmc_alpha_forward_2}), on obtient pour tout $i \in \ensemble{1}{N}$~:

        \begin{eqnarray}
        \beta_{T}\pa{i}  &=& \pr{   \emptyset \sac q_{T}=i,M } = 1 \label{hmm_eq_beta_2}\\
        \beta_{t}\pa{i}  &=& \summy{j=1}{N} b_{j} \pa{O_{t+1}}\,a_{ij}\,\beta_{t+1}\pa{j} \label{hmm_eq_beta_3}
        \end{eqnarray}

Finalement, la probabilit� de la s�quence est �galement obtenue gr�ce � la suite $\beta_t\pa{.}$ par un calcul appel� \emph{backward}~:

\indexfr{backward}

        \begin{eqnarray}
        \pr { O_{1},...,O_{T} \sac  M }  = \summy{i=1}{N} \pi_{i}\,\beta_{1} \pa{i} \,b_{i}\pa{O_{1}} \label{hmm_eq_beta_4}
        \end{eqnarray}

\indexfr{backward}
\indexfr{forward}
\indexfr{$\beta_t\pa{.}$}
\indexfr{$\alpha_t\pa{.}$}
\indexfr{co�t}

Les fonctions $\alpha_t\pa{.}$ et $\beta_t\pa{.}$ permettent de calculer la probabilit� d'une s�quence avec un co�t en $O\pa{TN^2}$ op�rations. Ces calculs sont semblables � des algorithmes de programmation dynamique et parfois appel�s algorithmes \emph{forward} ($\alpha_t\pa{.}$) et \emph{backward} ($\beta_t\pa{.}$) (\citeindex{Rabiner1986}). De ces formules, on tire l'algorithme suivant permettant de calculer la probabilit� d'une s�quence d'observations.


            \begin{xalgorithm}{backward} \label{hmm_algo_backward}
            Les notations utilis�es sont celles des formules (\ref{hmm_eq_beta_1}), (\ref{hmm_eq_beta_2}), (\ref{hmm_eq_beta_3}),
            (\ref{hmm_eq_beta_4}).
            
            \begin{xalgostep}{initialisation}
                    \begin{xfor}{i}{1}{N}
                    $\beta_T\pa{i} \longleftarrow 1$
                    \end{xfor}
            \end{xalgostep}
            
            \begin{xalgostep}{r�currence}
                    \begin{xfor}{t}{T-1}{1}
                            \begin{xfor}{i}{1}{N}
                                    $\beta_{t}\pa{j} \longleftarrow 0$ \\
                                    \begin{xfor}{j}{1}{N}
                                            $\beta_{t}\pa{i} \longleftarrow \beta_{t}\pa{i} + a_{ij}
                                             \, b_{j}\pa{O_{t+1}} \, \beta_{t+1} \pa{j}$
                                    \end{xfor} \\
                            \end{xfor}
                    \end{xfor}
            \end{xalgostep}
            
            \begin{xalgostep}{terminaison}
                    $p \longleftarrow 0$ \\
                    \begin{xfor}{i}{1}{N}
                            $p \longleftarrow p + \beta_{1}\pa{i} \, b_i\pa{O_1} \, \pi_i$
                    \end{xfor}
            \end{xalgostep}
            
            La probabilit� de la s�quence $\vecteur{O_1}{O_T}$ est $p$ obtenue � la derni�re �tape.
            
            \end{xalgorithm}
            
            










\subsection{Autres r�sultats int�ressants}


Trois autres r�sultats int�ressants utilis�s lors de l'apprentissage (paragraphe~\ref{par_apprentissage_hmm})
peuvent �tre obtenus de mani�re similaire~:

\label{hmm_probabilite_etat_transition_posteriori}%

        \begin{eqnarray}
        \pr{ O_1,...,O_T,q_t=i \sac  M }  &=& \alpha_t\pa {i}  \beta_t\pa{i} \label{hmm_proba_state}\\
        \forall t\in \ensemble{1}{T}, \; \pr{  O_{1},...,O_{T} \sac M }  &=& \summy{i=1}{N} \alpha_{t}\pa{i} \beta_{t} \pa{i}\\
        \pr{O_{1},...,O_{T},q_{t}=i,q_{t+1}=j \sac M} &=& \alpha_{t}\pa{i} \, a_{ij} \, b_{j}\pa{O_{t+1}}\beta_{t+1}\pa{j}
         \label{hmm_proba_transition}
        \end{eqnarray}









\subsection{Retour � l'exemple}
\indexfrr{exemple}{pi�ce de monnaie}

Rappel des probabilit�s de transitions et d'�mission~:%

        $$
        \begin{array}[c]{ccccc}%
        \pr{q_{1}=1}  =0,5 &  & \pr{q_{t}=1 \sac q_{t-1}=1}  =0,5 &  & \pa{q_{t}=1 \sac  q_{t-1}=2}  =0,7\\
        \pr{q_{1}=2}  =0,5 &  & \pr{q_{t}=2 \sac q_{t-1}=1}  =0,5 &  & \pr{q_{t}=2 \sac  q_{t-1}=2}  =0,3
        \end{array}
        $$
        
        $$
        \begin{array}[c]{ccc}%
        \pr{O_{t}=1 \sac q_{t}=1 }  =0,7 &  & \pr{O_{t}=1 \sac q_{t}=2 }  =0,5\\
        \pr{O_{t}=2 \sac q_{t}=1 }  =0,3 &  & \pr{O_{t}=2 \sac q_{t}=2 }  =0,5
        \end{array}
        $$

On cherche � calculer la probabilit�e de la s�quence 1111 :%

        $$
        \begin{array}[c]{c}%
            \frame{$
            \begin{array}[c]{ccccc}%
            & \alpha_{1}\left(  .\right)  & \alpha_{2}\left(  .\right)  & \alpha_{3}\left(  .\right)  & \alpha_{4}\left(  .\right) \\
            \text{�tat}\,1 & 0,15 & 0,094 & 0,04099 & 0,0174454\\
            \text{�tat}\,2 & 0,25 & 0,085 & 0,03535 & 0,014986
            \end{array}
            $}
            \\
            \\
            \begin{array}[c]{c}%
            P\left(  1111\right)  =0,0174454+0,014986=0,0324314
            \end{array}
        \end{array}
        $$

Les lois limites des observations peuvent �galement �tre obtenus :

        \begin{eqnarray*}
        \pr{O=k|t} &=& \pr{O=k|q=1,t}\pr{q=1|t} + \pr{O=k|q=2,t}\pr{q=2|t} \\
        \underset{t \rightarrow \infty}{\lim} \pr{O=k|t} &=& \underset{t \rightarrow \infty}{\lim} \crochet{\pr{O=k|q=1,t}\pr{q=1|t} +
        \pr{O=k|q=2,t}\pr{q=2|t}}\\
        \underset{t \rightarrow \infty}{\lim} \pr{O=k|t} &=& \pr{O=k|q=1,t}\underset{t \rightarrow \infty}{\lim}\pr{q=1|t} +
        \pr{O=k|q=2,t}\underset{t \rightarrow \infty}{\lim}\pr{q=2|t}\\
        \end{eqnarray*}

Comme :

        $$
        \begin{array}[c]{c}%
        \underset{t\rightarrow+\infty}{\lim}P\left(  q_{t}=1\right)  =\frac{7}{12}\\
        \underset{t\rightarrow+\infty}{\lim}P\left(  q_{t}=2\right)  =\frac{5}{12}%
        \end{array}
        $$

On en d�duit que :

        $$
        \begin{array}[c]{c}%
        \underset{t\rightarrow+\infty}{\lim}P\left(  O_{t}=1\right)  = 0,7 * \frac{7}{12} + 0,5 * \frac{5}{12} = \frac{37}{60}\\
        \underset{t\rightarrow+\infty}{\lim}P\left(  O_{t}=2\right)  = 0,3 * \frac{7}{12} + 0,5 * \frac{5}{12} = \frac{23}{60}
        \end{array}
        $$







\subsection{Introduction d'un �tat d'entr�e et d'un �tat de sortie}

\label{hmm_intro_entree_sortie}

En reconnaissance de l'�criture, les s�quences d'observations ne d�passent pas quelques graph�mes par lettres~: toutes les s�quences d'observations sont finies, or cette information suppl�mentaire n'est pas prise en compte dans les cha�nes de Markov cach�es pr�sent�es jusqu'� pr�sent. L'introduction d'un �tat d'entr�e et d'un �tat de sortie va y rem�dier afin de signifier la fin de la s�quence (voir \citeindex{Chen1994}). La figure~\ref{figure_model_optimaux_M-fig} montre les deux mod�les optimaux (avec ou sans �tat de sortie) pour la lettre "M". Le dessin de cette lettre fait intervenir trois graph�mes identiques. Le premier mod�le (1) sans �tat de sortie ne peut prendre en compte la "dur�e" de la lettre "M", des s�quences de deux, trois, cent graph�mes auront toutes la m�me probabilit�. Le second mod�le (2) ne permet qu'une seule �criture de la lettre "M" en trois graph�mes. Tous les �tats de la cha�ne de Markov sont des �tats \emph{�metteurs} (voir d�finition~\ref{definition_etat_emetteur}) car chaque observation est associ� un �tat, les �tats d'entr�es et de sortie sont \emph{non �metteurs} (voir d�finition~\ref{definition_etat_non_emetteur}).

        \begin{figure}[t]
    $$\frame{$\begin{array}[c|c]{c}\includegraphics[height=9cm, width=15cm] 
    {\filext{../dessin2/chaine_markov_etat_sortie}}\end{array}$}$$
    \caption{Mod�les optimaux pour la lettre "M" avec et sans �tat de sortie}
    \label{figure_model_optimaux_M-fig}
        \end{figure}

\indexfrr{�tat}{�metteur}
\indexfrr{�tat}{non �metteur}
\indexfrr{�tat}{muet}
\indexfrr{�tat}{entr�e}
\indexfrr{�tat}{sortie}



        \begin{xdefinition}{�tat �metteur}
        \label{definition_etat_emetteur}%
        \indexfrr{�tat}{�metteur}%
        Un �tat d'une cha�ne de Markov cach�e est dit \emph{�metteur} si le passage par cet �tat implique 
        l'�mission d'une observation. Par d�finition, pour une s�quence d'observations $O$ de longueur $T$, 
        toutes les s�quences d'�tats cach�s permises pour cette s�quence $O$ contiennent exactement $T$ �tats �metteurs.
        \end{xdefinition}


        \begin{xdefinition}{�tat non �metteur}
        \label{definition_etat_non_emetteur}%
        \indexfrr{�tat}{non �metteur}
        \indexsee{�tat}{muet}
        Un �tat d'une cha�ne de Markov cach�e est dit \emph{non �metteur} (ou \emph{muet}) 
        si le passage par cet �tat n'implique 
        aucune �mission d'observation. Par d�finition, pour toute s�quence d'observations, 
        une s�quence d'�tats cach�s peut 
        contenir une infinit� d'�tats non �metteurs.
        \end{xdefinition}



        \begin{xdefinition}{cha�ne de Markov cach�e, entr�e et sortie (ES)}
        \label{markov_chaine_cachee_definition_es}%
        Soit $M$ une cha�ne de Markov cach�e (ES),\newline%
        Soit $Q = \intervalle{1}{N}$ l'ensemble des �tats,\newline%
        Soit $S=\underset{T=1} {\overset{+\infty}{\cup}} Q^T$ l'espace des s�quences d'�tats,\newline%
        Soit $\mathcal{O} = \intervalle{1}{D}$ l'ensemble des observations,\newline%
        Soit $\mathbf{O}=\underset{T=1} {\overset{+\infty}{\cup}} \mathcal{O}^T$ l'espace des s�quences d'observations,\newline%
        On note $s = \pa{q_1,\dots,q_{T_s}} \in S$ une s�quence de longueur $T_s$,\newline%
        Soit $O = \pa{O_1,\dots,O_{T_O}} \in \mathbf{O}$ une s�quence de longueur $T_O$,\newline%
        Alors une cha�ne de Markov cach�e est un mod�le probabiliste v�rifiant les quatre conditions suivantes~:
                \begin{enumerate}
                \indexfrr{probabilit�}{transition}
            \indexfrr{probabilit�}{�mission}
            \indexfrr{probabilit�}{entr�e}
            \indexfrr{probabilit�}{sortie}
                \item L'observation � l'instant $t$ ne d�pend que de l'�tat � l'instant $t$~:
                    $$
                    \forall s \in S \text{ telle que } T_s = T_O, \; \forall t \in \intervalle{1}{T_O}, \;
                    \pr{O_t|\overline{q_t},\overline{O_{t-1}},M} = \pr{O_t|q_t,M}
                    $$
                    On appelle $\pr{O_t|q_t,M}$ la \emph{probabilit� d'�mission} de l'observation $O_t$ 
                    sachant l'�tat $q_t$ � l'instant $t$.
                    
                \item Les probabilit�s d'�missions ne d�pendent pas du temps :
                    $$
                    \forall s \in S \text{ telle que } T_s = T_O, \; 
                    \forall \pa{t,t'} \in \intervalle{2}{T_s}, \; \pr{O_t|q_t,M} = \pr{O_{t'}|q_{t'},M}
                    $$
                    
                \item L'�tat � l'instant $t$ ou la sortie ne d�pend que de l'�tat � l'instant $t-1$~:
                    \begin{eqnarray*}
                    \forall s \in S \text{ telle que } T_s = T_O, \; \forall t \in \intervalle{2}{T_s}, \; &&
                                \pr{q_t| \overline{q_{t-1}},\overline{O_{t-1}},M} = \pr{q_t|q_{t-1},M} \\
                    \forall s \in S \text{ telle que } T_s = T_O, \forall t \in \intervalle{2}{T_s}, \; &&
                                \pr{ sortie | \overline{q_{t-1}},\overline{O_{t-1}},M} = \pr{sortie |q_{t-1},M}
                    \end{eqnarray*}
                    
                    On appelle $\pr{q_t|q_{t-1},M}$ la probabilit� de transition de l'�tat $q_{t-1}$ � l'�tat $q_t$ � l'instant $t$ et
                    $\pr{sortie|q_{t-1},M} = \pr{s|q_{t-1},M}$ la \emph{probabilit� de sortie} � l'instant $t-1$.
                    
                \item Les probabilit�s de transition et de sortie ne d�pendent pas du temps~:
                    \begin{eqnarray*}
                    \forall s \in S \text{ telle que } T_s = T_O, \; \forall \pa{t,t'} \in \intervalle{2}{T_s}, && 
                                        \pr{q_t|q_{t-1},M} = \pr{q_{t'}|q_{t'-1},M} \\
                    \forall s \in S \text{ telle que } T_s = T_O, \; \forall \pa{t,t'} \in \intervalle{2}{T_s}, && 
                                        \pr{sortie|q_{t-1},M} = \pr{sortie|q_{t'-1},M}
                    \end{eqnarray*}
                    
                \end{enumerate}
        
        \end{xdefinition}



La cha�ne de Markov cach�e (ES) $M$ � $N$ �tats est d�finie par les param�tres $A_M$, $B_M$, $\Pi_M$, $\Theta_M$~:

        \begin{eqnarray}
        A_M    &=& \pa {  a_{M,ij} } _ {\substack{ 1\leqslant i\leqslant N\\1\leqslant j\leqslant N}} =
                   \pa{ \pr {  q_{t}=j \sac  q_{t-1} =i,M } } _{\substack{1\leqslant i\leqslant N\\
                                                                               1\leqslant j\leqslant N}} \label{hmm_contrainte_es_1}\\
        B_M    &=& \pa{   b_{M,ij} } _ {\substack{1\leqslant i\leqslant N\\1\leqslant j\leqslant D}}=
                   \pa { \pr{ O_{t}=j \sac  q_{t}=i,M } }     _ {\substack{1\leqslant i\leqslant N
                                                                               \\1\leqslant j\leqslant D}} \label{hmm_contrainte_es_2}\\
        \Pi_M  &=& \pa { \pi_{M,i} } _ { 1 \infegal i \infegal N } = \pa { \pr {  q_1 = i \sac M} } _ 
                                                                        { 1 \infegal i \infegal N } \label{hmm_contrainte_es_3} \\
        \Theta_M  &=& \pa { \theta_{M,i} } _ { 1 \infegal i \infegal N } = \pa { \pr {  s \sac q_{t}, M} } _ 
                                                                                { 1 \infegal i \infegal N } \label{hmm_contrainte_es_4}
        \end{eqnarray}


La d�finition d'une cha�ne de Markov cach�e (ES) implique les contraintes suivantes sur les param�tres $A_M$, $B_M$, $\Pi_M$, $\Theta_M$
r�sum�es par la propri�t� suivante~:


        \begin{xproperty}{contrainte}
        \label{propriete_mmc_contrainte_es}%
        La d�fintion~\ref{markov_chaine_cachee_definition_es} et les notations d�finies en (\ref{hmm_contrainte_es_1}),
        (\ref{hmm_contrainte_es_2}), (\ref{hmm_contrainte_es_3}) et (\ref{hmm_contrainte_es_4}) impliquent que~:
        
                \begin{eqnarray}
                \forall i\in \ensemble{1}{N}, \; && \summy{j=1}{N} \; a_{M,ij} + \theta_{M,i} =1 \\
                \forall i\in \ensemble{1}{N}, \; &&\summy{j=1}{N} \; b_{M,ij}=1 \\
                                                 &&\summy{i=1}{N} \; \Pi_{M,i} = 1
                \end{eqnarray}
        \end{xproperty}
        
        

En utilisant les hypoth�ses de la d�finition~\ref{markov_chaine_cachee_definition}, on cherche � exprimer la probabilit� d'une s�quence
d'observations � l'aide des param�tres $A=A_M$, $B=B_M$, $\Pi=\pi_M$, $\Theta=\Theta_M$ du mod�le $M$~:

        \begin{eqnarray}
        \pr{O|M} &=&   \summyone{\begin{subarray}{c}s \in S \\ T_s = T_O \end{subarray}}
                        \pr{O,s|M} \nonumber\\
        \pr{O|M} &=&   \summyone{\begin{subarray}{c}s \in S \\ T_s = T_O \end{subarray}}
                        \crochet{ \pi_{s_1} \theta_{s_T} \prody{t=2}{T_O}a_{s_{t-1},s_t}
                             \prody{t=1}{T_O} b_{q_t}\pa{O_t} } \label{mmc_expression_proba_seq_es}
        \end{eqnarray}




Le calcul factoris� de cette probabilit� est aussi modifi�, les suites $\alpha_t\pa{.}$ et $\beta_t\pa{.}$ deviennent~:

\indexfr{factoriser}
\indexfr{$\alpha_t\pa{.}$}
\indexfr{$\beta_t\pa{.}$}
\indexfr{forward}
\indexfr{backward}



\para{Calcul de la suite }$\alpha_{t}\left(  .\right)  $

\label{hmm_calcul_alpha}
\indexfr{$\alpha_t\pa{.}$}%
\label{hmm_calcul_alpha}%

Pour $1\leqslant i\leqslant N$ et $1\leqslant t\leqslant T$,

        \begin{eqnarray}
        \alpha _{t} \pa{i}  = \pr{ q_{t}=i,O_{1},...,O_{t} \sac  M} \label{hmm_eq_alpha_es_1}
        \end{eqnarray}

L'initialisation ne change pas :

        \begin{eqnarray}
        \alpha_{1}\pa{i}  = \pr{   q_{1}=i,O_{1} \sac  M } = \pr { O_{1} \sac q_{1}=i,M} \pr { q_{1}=i \sac M}  = \pi_{i}b_{i}\pa{O_{1}}
        \label{hmm_eq_alpha_es_2}
        \end{eqnarray}

Par r�currence :

        \begin{eqnarray}
        \alpha_{t+1} \pa{j}  = b_{j,O_{t+1}} \summy{i=1}{N} a_{ij}\alpha_{t}\pa{i} \label{hmm_eq_alpha_es_3}
        \end{eqnarray}

Seule change la probabilit� de la s�quence~:

        \begin{eqnarray}
        \pr{  O_{1},...,O_{T} \sac  M}  = \summy{i=1}{N} \; \alpha_{T} \pa{i} \,\theta_{i} \label{hmm_eq_alpha_es_4}
        \end{eqnarray}


L'algorithme~\ref{hmm_algo_forward} devient le suivant~:

        \begin{xalgorithm}{forward} \label{hmm_algo_forward_es}
        Les notations utilis�es sont celles des formules (\ref{hmm_eq_alpha_es_1}), (\ref{hmm_eq_alpha_es_2}),
        (\ref{hmm_eq_alpha_es_3}), (\ref{hmm_eq_alpha_es_4}).
        
        \begin{xalgostep}{initialisation}
                \begin{xfor}{i}{1}{N}
                $\alpha_1\pa{i} \longleftarrow \pi_{i}b_{i,O_{1}}$
                \end{xfor}
        \end{xalgostep}
        
        \begin{xalgostep}{r�currence}
                \begin{xfor}{t}{2}{T}
                        \begin{xfor}{j}{1}{N}
                                $\alpha_{t}\pa{j} \longleftarrow 0$ \\
                                \begin{xfor}{i}{1}{N}
                                        $\alpha_{t}\pa{j} \longleftarrow \alpha_{t}\pa{j} + a_{ij} \, \alpha_{t-1} \pa{i}$
                                \end{xfor} \\
                                $\alpha_{t}\pa{j} \longleftarrow \alpha_{t}\pa{j} \; b_{j}\pa{O_{t+1}}$
                        \end{xfor}
                \end{xfor}
        \end{xalgostep}
        
        \begin{xalgostep}{terminaison}
                $p \longleftarrow 0$ \\
                \begin{xfor}{i}{1}{N}
                        $p \longleftarrow p + \alpha_{T}\pa{i} \; \theta_i$
                \end{xfor}
        \end{xalgostep}
        
        La probabilit� de la s�quence $\vecteur{O_1}{O_T}$ est $p$ obtenue � la derni�re �tape.
        
        \end{xalgorithm}
        
        
        







\para{Calcul de la suite }$\beta_{t}\left(  .\right)  $
\label{hmm_calcul_beta}%

\indexfr{$\beta_t\pa{.}$}%

Pour $1\leqslant i\leqslant N$ et $1\leqslant t\leqslant T$,

        \begin{eqnarray}
        \beta _{t}\pa{i}  = \pr{ O_{t+1},...,O_{T} \sac  q_{t}=i,M} \label{hmm_eq_beta_es_1}
        \end{eqnarray}

L'initialisation change :

        \begin{eqnarray}
        \begin{array}{l}
        \beta_{T}\pa{i}  = \pr{  \emptyset \sac  q_{T}=i,M}  = \theta_{i} \\
        \qquad(=\text{probabilit� que la s�quence soit finie sachant que }q_{T}=i)
        \end{array} \label{hmm_eq_beta_es_2}
        \end{eqnarray}

Par r�currence :

        \begin{eqnarray}
        \beta_{t} \pa{i}  = \summy{j=1}{N} \, b_{j}\pa{O_{t+1}} \, a_{ij} \, \beta_{t+1}\pa{j} \label{hmm_eq_beta_es_3}
        \end{eqnarray}

Finalement :

        \begin{eqnarray}
        \pr{  O_{1},...,O_{T} \sac  M }  = \summy{i=1}{N} \pi_{i}\,\beta_{1}\pa{i}\,b_{i,O_{1}} \label{hmm_eq_beta_es_4}
        \end{eqnarray}

L'algorithme~\ref{hmm_algo_backward} devient le suivant~:


        \begin{xalgorithm}{backward} \label{hmm_algo_backward_es}
        Les notations utilis�es sont celles des formules (\ref{hmm_eq_beta_es_1}), (\ref{hmm_eq_beta_es_2}), (\ref{hmm_eq_beta_es_3}),
        (\ref{hmm_eq_beta_es_4}).
        
        \begin{xalgostep}{initialisation}
                \begin{xfor}{i}{1}{N}
                $\beta_T\pa{i} \longleftarrow \theta_i$
                \end{xfor}
        \end{xalgostep}
        
        \begin{xalgostep}{r�currence}
                \begin{xfor}{t}{T-1}{1}
                        \begin{xfor}{i}{1}{N}
                                $\beta_{t}\pa{j} \longleftarrow 0$ \\
                                \begin{xfor}{j}{1}{N}
                                        $\beta_{t}\pa{i} \longleftarrow \beta_{t}\pa{i} + a_{ij} \, b_{j}\pa{O_{t+1}} \, \beta_{t+1} \pa{j}$
                                \end{xfor} \\
                        \end{xfor}
                \end{xfor}
        \end{xalgostep}
        
        \begin{xalgostep}{terminaison}
                $p \longleftarrow 0$ \\
                \begin{xfor}{i}{1}{N}
                        $p \longleftarrow p + \beta_{1}\pa{i} \, b_i\pa{O_1} \, \pi_i $
                \end{xfor}
        \end{xalgostep}
        
        La probabilit� de la s�quence $\vecteur{O_1}{O_T}$ est $p$ obtenue � la derni�re �tape.
        
        \end{xalgorithm}
        

        
Par la suite, toutes les cha�nes de Markov seront suppos�es poss�der un �tat d'entr�e et un �tat de sortie.











\subsection{Repr�sentation d'une cha�ne de Markov sous forme de graphe}

\indexfr{graphe}%
\indexfrr{transition}{nulles}%
\indexfrr{connexion}{transition}
\label{hmm_representation_graphe}%

Les paragraphes pr�c�dents ont d�j� montr� qu'il �tait possible de mod�liser une cha�ne de Markov sous forme de graphe o� les noeuds sont les �tats et les transitions les arcs. Une probabilit� non nulle de passer d'un �tat $i$ � un autre �tat $j$ peut �tre envisag�e comme un lien unidirectionnel entre ces deux �tats dont le poids est la probabilit� de transition de l'�tat $i$ vers l'�tat $j$. L'ensemble des probabilit�s non nulles d'un mod�le d�finit un ensemble de liens entre les �tats qui peut �tre d�crit par un graphe. Un mod�le enti�rement connect� de $N$ �tats contient $N^{2}+2N$ connexions. Une structure de graphe permet de diminuer ce nombre de connexions en ne tenant compte que des connexions non nulles (les mod�les utilis�s pour la reconnaissance de l'�criture contiennent en g�n�ral une grande part de connexions nulles.), voir figures~\ref{figure_rn_graphe_trans_un-fig}, \ref{figure_rn_graphe_trans_deux-fig}.


                \begin{figure}[ht]
                    $$
                    \begin{tabular}[c]{|ccc|} \hline
                        \begin{tabular}{c} \; \\
                        \begin{tabular}{|c|c|c|} \hline
                        A & 0   & 1   \\ \hline
                        0 & 0,7 & 0,3 \\ \hline
                        1 & 0,5 & 0,5 \\ \hline
                        \end{tabular} \\ \;
                        \end{tabular}
                    & $\longleftrightarrow$ &
                    %
                    \filefig{../hmm/fig_grmat}
                    %
                        \\ \hline
                    \small Matrice de transition & $\longleftrightarrow$ & Graphe de transition \\ \hline
                    \end{tabular}
                    $$
                    \caption{Equivalence entre matrice de transition et graphe de transition pour une cha�ne de Markov.}
                    \label{figure_rn_graphe_trans_un-fig}
                \end{figure}


                \begin{figure}[ht]
                    $$
                    \begin{tabular}[c]{|ccc|} \hline
                        \begin{tabular}{c} \; \\
                        \begin{tabular}{|c|c|c|c|c|} \hline
                        A & E   & 0   & 1   & S \\ \hline
                        E &     & 0,5 & 0,5 &   \\ \hline
                        0 &     & 0,6 & 0,3 & 0,1  \\ \hline
                        1 &     & 0,4 & 0,4 & 0,2  \\ \hline
                        S &     &     &     &      \\ \hline
                        \end{tabular} \\ \;
                        \end{tabular}
                    & $\longleftrightarrow$ &
                    %
                    \filefig{../hmm/fig_grmat2}
                    %
                        \\ \hline
                    \small Matrice de transition & $\longleftrightarrow$ & Graphe de transition \\ \hline
                    \end{tabular}
                    $$
                    \caption{Equivalence entre matrice de transition et graphe de transition 
                                        pour une cha�ne de Markov ES.}
                    \indexfrr{graphe}{transition}
                    \indexfrr{matrice}{transition}
                    \label{figure_rn_graphe_trans_deux-fig}
                \end{figure}




La reconnaissance de l'�criture utilise peu de mod�les ergodiques (ou enti�rement connect�s) car le sens de la lecture interdit de revenir � un �tat d�j� visit�. Par cons�quent, les matrices de connexions sont triangulaires sup�rieures avec des z�ros sur la diagonale. En d�finitive, il existe peu de connexions non nulles par rapport � toutes celles qui sont possibles. Le tableau~\ref{table_connexion_nulle-tab} (page~\pageref{table_connexion_nulle-tab}) montre que, en g�n�ral, seules 10\% des connexions possibles sont non nulles~: la description sous forme de graphe de ces cha�nes de Markov cach�e est plus avantagueuse qu'une description matricielle. Ce r�sultat est bien s�r propre � la reconnaissance de l'�criture manuscrite.

        \begin{table}[t]
    $$\fbox{$\small
    \begin{array}{ccccc}
    \textbf{lettre} & \begin{array}{c} \textbf{nombre} \\ \textbf{d'�tats} \end{array}
                    & \begin{array}{c} \textbf{connexions} \\ \textbf{possibles} \end{array}
                    & \begin{array}{c} \textbf{connexions} \\ \textbf{non nulles} \end{array}
                    &  \textbf{rapport}\\
    A  & 42 & 1848  &  150 &8,1\%\\
    B  & 36 & 1368  &  112 &8,2\%\\
    C  & 27 & 783   &  76  &9,7\%\\
    D  & 30 & 960   &  97  &10,1\%\\
    E  & 23 & 575   &  73  &12,7\%\\
    F  & 34 & 1224  &  96  &7,8\%\\
    G  & 38 & 1520  &  126 &8,3\%\\
    H  & 36 & 1368  &  97  &7,1\%\\
    I  & 24 & 624   &  70  &11,2\%\\
    J  & 10 & 120   &  21  &17,5\%\\
    K  & 32 & 1088  &  80  &7,4\%\\
    L  & 30 & 960   &  36  &3,8\%\\
    M  & 42 & 1848  &  126 &6,8\%\\
    N  & 36 & 1368  &  103 &7,5\%\\
    O  & 27 & 783   &  71  &9,1\%\\
    P  & 35 & 1295  &  100 &7,7\%\\
    Q  & 34 & 1224  &  85  &6,9\%\\
    R  & 33 & 1155  &  108 &9,4\%\\
    S  & 29 & 899   &  92  &10,2\%\\
    T  & 31 & 1023  &  80  &7,8\%\\
    U  & 27 & 783   &  62  &7,9\%\\
    V  & 29 & 899   &  77  &8,6\%\\
    W  & 36 & 1368  &  78  &5,7\%\\
    X  & 36 & 1368  &  97  &7,1\%\\
    Y  & 40 & 1680  &  114 &6,8\%\\
    Z  & 38 & 1520  &  90  &5,9\%
    \end{array}
    $}$$
    \caption{Connexions non nulles dans les mod�les de reconnaissance de lettres.}
    \label{table_connexion_nulle-tab}
        \end{table}













%----------------------------------------------------------------------------------------------------------------------
\section{Algorithme du meilleur chemin : algorithme de Viterbi}
%----------------------------------------------------------------------------------------------------------------------
\label{paragraphe_viterbi_principe}


\indexfr{Viterbi}%
\indexfrr{meilleur(e)}{chemin}%
\indexfrr{s�quence}{�tat}
\indexfrr{s�quence}{observation}

Nous avons vu que le calcul des suites $\alpha_{t}\pa{.}$ et $\beta _{t}\pa{.}$ permet de calculer la probabilit� d'une s�quence d'observations, qui est une somme de probabilit�s sur l'ensemble des s�quences d'�tats possibles. L'algorithme de Viterbi permet de trouver parmi toutes ces s�quences d'�tats, celle dont la probabilit� d'�mettre la s�quence d'observations est la plus forte. On appelle aussi cette s�quence d'�tats ou meilleur chemin la s�quence d'�tats la plus probable ayant �mis la s�quence d'observations. Soit une s�quence d'observations $O=\left(  O_{1},...,O_{T}\right)$, et le mod�le $M$, cet algorithme permet de trouver la s�quence $s^{\ast }\left(  O_{1},...,O_{T},M\right)$~:%

        \begin{eqnarray}
        s^* \pa{ O_{1},...,O_{T},M }    =\underset{s}{\arg\max} \, \pr{  s \sac O_{1},...,O_{T},M }
                                        =\underset{s}{\arg\max} \, \pr{ s,O_{1},...,O_{T} \sac M }
                                        \label{hmm_viterbi_eq_1}
        \end{eqnarray}

On note $\pa{ \delta_{t} \pa{i}} _{\substack{1\leqslant t\leqslant T\\1\leqslant i\leqslant N}}$ la probabilit� de la s�quence d'�tats $\left(  q_{1},...,q_{t}\right)  $ la plus probable telle que $q_{t}=i$ ayant �mis la s�quence $\left( O_{1},...,O_{t}\right)$~:

        \begin{eqnarray}
        \delta_t\pa{i} = \underset{\vecteur{q_1}{q_{t-1}}}{\arg \max} \, \pr{ \vecteurno{O_1}{O_t}, \vecteurno{q_1}{q_{t-1}},q_t=i | M}
        \label{hmm_viterbi_eq_2}
        \end{eqnarray}

alors $\delta_t\pa{i}$ v�rifie :

        \begin{eqnarray}
        \begin{array}{rl}
        \text{pour }t=1 \text{ et } 1\leqslant i\leqslant N, & \delta_{1}\left(  i\right) =\pi_{1}b_{i}\left(  O_{1}\right)\\
        \text{pour }2\leqslant t\leqslant T \text{ et } 1\leqslant j\leqslant N, &
                    \delta _{t}\left(  j\right)  =\underset{1\leqslant i\leqslant N}{\max}\left\{ \delta_{t-1}\left(  i\right)  a_{ij}
                    \; b_{i}\left(  O_{t}\right)  \right\}  \\
        \end{array}
        \label{hmm_viterbi_eq_3}
        \end{eqnarray}

On d�finit �galement la suite $\pa{ \lambda_{t}}_{1\leqslant t\leqslant T}$ par :

        \begin{eqnarray}
        \begin{array}{rl}
        \text{pour }1\leqslant t\leqslant T-1, \; & \lambda _{t} =\underset{1\leqslant i\leqslant
            N}{\arg\max} \left\{ \delta_{t}\left(  \lambda_{t+1}\right)  \right\} \\
        \text{pour }t=T, \; & \lambda_{T} =\underset{1\leqslant i\leqslant N}{\arg\max}\left\{ \delta_{T}\left( i\right)\theta_i \right\}
        \end{array}
        \label{hmm_viterbi_eq_4}
        \end{eqnarray}

Par cons�quent, le meilleur chemin est la s�quence d'�tats $\left(  \lambda_{1},...,\lambda_{T}\right)  $ et a pour probabilit�
$\delta_T\pa{\lambda_T}\theta_{\lambda_T}$.

On en d�duit l'algorithme suivant~:

        \begin{xalgorithm}{Viterbi}\label{hmm_algo_viterbi_etat}
        \indexfr{Viterbi}
        Les notations utilis�es sont celles des �quations (\ref{hmm_viterbi_eq_1}), (\ref{hmm_viterbi_eq_2}),
        (\ref{hmm_viterbi_eq_3}), (\ref{hmm_viterbi_eq_4}).
        
        \begin{xalgostep}{initialisation}\label{hmm_viterbi_step_a}
                \begin{xfor}{i}{1}{N}
                $
                \begin{array}{lll}
                \delta_1\pa{i}  &\longleftarrow& \pi_i \, b_i\pa{O_1} \\
                \lambda_1\pa{i} &\longleftarrow& -1
                \end{array}
                $
                \end{xfor}
        \end{xalgostep}
        
        \begin{xalgostep}{r�currence}\label{hmm_viterbi_step_b}
                \begin{xfor}{t}{2}{T}
                        \begin{xfor}{j}{1}{N}
                                $
                                \begin{array}{lll}
                                \delta_t\pa{j}  &\longleftarrow& \delta_{t-1}\pa{1} \; a_{1j} \, b_j\pa{O_t} \\
                                \lambda_t\pa{j} &\longleftarrow& 1
                                \end{array}
                                $ \\
                                \begin{xfor}{i}{2}{N}
                                        $x \longleftarrow \delta_{t-1}\pa{i} \, a_{ij} \, b_j\pa{O_t}$ \\
                                        \begin{xif}{$x < \delta_t\pa{j}$}
                                                $
                                                \begin{array}{lll}
                                                \delta_t\pa{j}  &\longleftarrow& x \\
                                                \lambda_t\pa{j} &\longleftarrow& i
                                                \end{array}
                                                $
                                        \end{xif}
                                \end{xfor}
                        \end{xfor}
                \end{xfor}
        \end{xalgostep}
        
        \begin{xalgostep}{terminaison}\label{hmm_viterbi_step_c}
                $
                \begin{array}{lll}
                \delta_{T+1}        &\longleftarrow& \delta_{T}\pa{1} \, \theta_{1} \\
                \lambda_{T+1}       &\longleftarrow& 1
                \end{array}
                $ \\
                \begin{xfor}{i}{2}{N}
                        $x \longleftarrow \delta_{T}\pa{i} \, \theta_i$ \\
                        \begin{xif}{$x < \delta_{T+1}$}
                                $
                                \begin{array}{lll}
                                \delta_{T+1}  &\longleftarrow& x \\
                                \lambda_{T+1} &\longleftarrow& i
                                \end{array}
                                $
                        \end{xif}
                \end{xfor}
        \end{xalgostep}
        
        \begin{xalgostep}{s�quence d'�tats la plus probable}\label{hmm_viterbi_step_d}
                $q^*_T  \longleftarrow \lambda_{T+1}$ \\
                \begin{xfor}{t}{T-1}{1}
                        $q^*_t  \longleftarrow \lambda_{t+1}\pa{ q^*_{t+1}}$
                \end{xfor}
        \end{xalgostep}
        
        La s�quence d'�tats la plus probable est $\vecteur{q^*_1}{q^*_T}$ et a pour probabilit� $\delta_{T+1}$.
        
        \end{xalgorithm}
        




\begin{xremark}{forward et backward}
L'obtention du meilleur chemin n�cessite deux passages, le premier pour le calcul des matrices $\delta_t\pa{i}$ et $\lambda_t\pa{i}$ \indexfr{forward} \indexfr{backward} lors des �tapes~\ref{hmm_viterbi_step_a}, \ref{hmm_viterbi_step_b}, \ref{hmm_viterbi_step_c}. Ce calcul est semblable � celui de l'algorithme forward~\ref{hmm_algo_forward_es}. Le second passage de l'�tape~\ref{hmm_viterbi_step_d} dans l'autre sens (indice d�croissant) permet de retrouver le meilleur chemin. Cette �tape n'est pas n�cessaire pour obtenir seulement la probabilit� de la meilleur s�quence d'�tats.
\end{xremark}




\begin{xremark}{meilleure s�quence, plus court chemin}
Cet algorithme est � rapprocher d'un algorithme de recherche du plus court chemin dans un graphe. En effet, la probabilit� d'un chemin s'exprime comme un produit de probabilit�s :%

\indexfrr{meilleur(e)}{s�quence}
\indexfrr{meilleur(e)}{chemin}
\indexfr{graphe}


        $$
        \pr {  q_{1},...,q_{T},O_{1},...,O_{T} \sac  M}  =\pi_{q_{1}}b_{q_{1}}
                \left(  O_{1}\right)  \underset{t=2}{\overset{T}{\prod}
        }a_{q_{t-1},q_{t}}b_{q_{t}}\left(  O_{t}\right)
        $$

En passant au logarithme, on obtient une somme de termes qui peuvent �tre consid�r�s comme des distances entre deux �tats. L'algorithme de Viterbi n'est autre qu'un algorithme de recherche du meilleur chemin de type Dijkstra (\citeindex{Dijkstra1971}).
\end{xremark}















%----------------------------------------------------------------------------------------------------------------------
\section{Apprentissage d'une cha�ne de Markov cach�e}
%----------------------------------------------------------------------------------------------------------------------
\label{hmm_apprentissage_chapter}

\subsection{Principe}

\indexfr{apprentissage}%
\label{par_apprentissage_hmm}

Dans l'exemple paragraphe~\ref{chaine_markov_cachee_exemple}, la cha�ne de Markov cach�e adapt�e au probl�me se d�duisait de l'�nonc� : les probabilit�s de transitions et d'�missions �taient fix�es par la d�finition des deux pi�ces truqu�e et non truqu�e. Les questions que l'on cherche � r�soudre dans ces probl�mes sont en g�n�ral des esp�rances de gain, des dur�es, des informations sur le comportement du jeu sur une longue p�riode, sur de longues s�quences d'observations. A partir du mod�le, on cherche donc � d�duire des propri�t�s sur les observations. 

L'apprentissage d'une cha�ne de Markov cach�e est exactement la t�che inverse. On dispose de s�quences d'observations dont il faut d�duire le mod�le qui les a g�n�r�es. Une fois la topologie du mod�le choisie, l'apprentissage revient donc � estimer les probabilit�s d'entr�es, de transitions, d'�missions qui mod�lisent au mieux la base d'�chantillons.



        \begin{figure}[ht]
      $$\frame{$\begin{array}[c]{c}\includegraphics[height=1cm, width=3cm] 
      {\filext{../dessin2/imagemg}}\end{array}$}$$
    \caption{Un mot segment� en graph�mes.}
    \label{figure_exemple_grapheme}
        \end{figure}

La figure~\ref{figure_exemple_grapheme} est un exemple de mot � reconna�tre, la reconnaissance avec dictionnaire (deux mots pour cet exemple) consiste � reconna�tre que c'est le mot "CHARLES" plut�t que "JEROME" qui est �crit sur cette image.

\indexfrr{reconnaissance}{dictionnaire}

Pour r�pondre � cette question, deux mod�les de Markov cach�s sont construits, l'un pour le mot "CHARLES", $M_{CHARLES}$, et l'autre pour le mot "JEROME", $M_{JEROME}$. Le pr�traitement de l'image aboutit � la s�quence d'observations $O = \vecteur{O_1}{O_T}$. On dit que~:

        $$
        \text{si } \pr{O|M_{CHARLES}} > \pr{O|M_{JEROME}} \text{ alors l'image contient le mot "CHARLES"}
        $$

Il reste � construire les mod�les $M_{CHARLES}$ et $M_{JEROME}$ et pour cela on dispose d'une base d'images annot�es\indexfr{annotation} qui contiennent des images des mots "CHARLES" et "JEROME". Le mot $M_{CHARLES}$ va apprendre toutes les s�quences issues des images annot�es "CHARLES", il en sera de m�me pour le mot "JEROME". Si on note $\vecteur{O_1^C}{O_K^C}$ les s�quences d'observations annot�es "CHARLES" et $\vecteur{O_1^J}{O_L^J}$ celles annot�es "JEROME", l'apprentissage consiste � maximiser la vraisemblance~:

\indexfr{vraisemblance}

        \begin{eqnarray}
        L\pa{\theta_C, \theta_J, \vecteurno{O_1^C}{O_K^C},\vecteurno{O_1^J}{O_K^J}} &=&
                                \prody{n=1}{K} \pr{O_n^C | M_{CHARLES}} \; \prody{n=1}{L} \pr{O_n^L | M_{JEROME}}
                                         \nonumber \\
                &=& \prody{n=1}{K} \pr{O_n^C | \theta_C} \; \prody{n=1}{L} \pr{O_n^L | \theta_J} \nonumber \\
                &=& L\pa{\theta_C, \vecteurno{O_1^C}{O_K^C}} L\pa{\theta_J, \vecteurno{O_1^J}{O_K^J}}
                             \label{hmm_eq_vraisemblance} \\
                && \text{o� } \theta_C \text{ et } \theta_J \text{ sont les param�tres} \nonumber  \\
                && \text{des mod�les } M_{CHARLES} \text{ et } M_{JEROME} \nonumber
        \end{eqnarray}

L'apprentissage soul�ve deux questions :

\begin{enumerate}
\item Le choix des mod�les pour les mots "CHARLES" et "JEROME", ce point sera �tudi� dans la partie~\ref{selection_architecture_chaine_MMC}. \item L'apprentissage de ces mod�les, ce point est d�taill� dans les paragraphes qui suivent (algorithme, convergence, d�monstration).
\end{enumerate}


L'�quation (\ref{hmm_eq_vraisemblance}) sugg�re que l'apprentissage des mod�les "CHARLES" et "JEROME" peut s'effectuer de mani�re ind�pendante � condition que les vraisemblances associ�es � ces deux mod�les d�pendent de param�tres diff�rents. Dans le cas contraire, la r�solution du probl�me se d�duit du cas o� on suppose qu'un seul mod�le $M$ doit apprendre les s�quences d'observations~:

        $$
        \left( O^{k}=\left( O_{1}^{k},..., O_{T_{k}}^{k} \right) \right) _{1\leqslant k\leqslant K}
        $$

        \begin{xproblem}{apprentissage d'une cha�ne de Markov cach�e}
        \label{hmm_problem_apprentissage_hmm}
        \indexfr{apprentissage}
        Les notations utilis�es sont celles de la d�finition~\ref{markov_chaine_cachee_definition}, l'�quation
         (\ref{hmm_eq_vraisemblance})
        permet de d�finir l'apprentissage d'une cha�ne de Markov cach�e comme �tant la solution du probl�me 
        d'optimisation suivant~:
        
        \indexfr{vraisemblance}
        \indexfr{optimisation}%
        
                $$
                \begin{array}{l}
                \left(  A_{M},\pi_{M},\theta_{M},B_{M}\right)  =\underset{A,\pi,\theta,B } {\arg\max} \; 
                                \underset{\text{vraisemblance du mod�le}} {\underbrace
                {\prody{k=1}{K}  \pr{  O_{1}^{k},...,O_{T_{k}}^{k}\left| M\right. }}} \\ \\
                \begin{array}{rcl}
                \text{ avec les contraintes } & &
                        \left\{
                        \begin{subarray}{l}
                        \summyone{i}\pi_i=1 \\
                        \forall j, \; \summyone{i}a_{ij} = 1 \\
                        \forall j, \; \summyone{o}b_j\pa{o} = 1 \\
                        \forall i, \; \pi_i \supegal 0 \\
                        \forall i, \; \theta_i \supegal 0 \\
                        \forall \pa{i,j} \; a_{ij} \supegal 0 \\
                        \forall \pa{i,o} \; b_j\pa{o} \supegal 0
                        \end{subarray}
                        \right.
                \end{array}
                \end{array}
                $$
        \end{xproblem}
        
        

\indexfr{Baum-Welch}

L'algorithme d'optimisation ou apprentissage des mod�les de Markov cach�s est bas� sur les formules de Baum-Welch qui prennent en compte les contraintes du probl�me (voir \citeindex{Baum1972} ou \citeindex{Rabiner1986}), utilis�es comme un cas particulier de l'algorithme EM
(Expectation-Maximisation, voir \citeindex{Dempster1977}). Trois �tapes composent cet algorithme it�ratif~:




        \begin{xalgorithm} {apprentissage d'une cha�ne de Markov cach�e}
        \indexfr{r�estimation}
        \indexfr{optimisation}\label{hmm_algorithme_baumwelch}
        Cet algorithme permet d'obtenir une solution au probl�me~\ref{hmm_problem_apprentissage_hmm} 
        correspondant � un minimum local
        \indexfr{minimum local} de la vraisemblance\indexfr{vraisemblance} (\ref{hmm_eq_vraisemblance}) comme le
        montre le th�or�me~\ref{theoreme_hmm_baum_welch_1})~:
        
        \begin{xalgostep}{initialisation}
                Les param�tres $A_0, \Pi_0, \Theta_0, B_0$ re�oivent des valeurs al�atoires.\\
                $t \longleftarrow 0$ \\
                calcul de la vraisemblance du mod�le $L_0$
        \end{xalgostep}
        
        \begin{xalgostep}{r�currence} \label{hmm_algo_apprentissage_step_recurrence}
                \begin{xwhile}{$L_{t} > L_{t-1}$}
                        $t \longleftarrow t+1$ \\
                        Les param�tres $\overline{A_{t}}, \overline{\Pi_{t}}, \overline{\Theta_{t}},
                         \overline{B_{t}}$ sont estim�s en fonction des formules de Baum-Welch
                        (voir table~\ref{figure_formule_baumwelch-fig}).\\
                        $
                        \begin{array}{lll}
                        A_t             & \longleftarrow & \overline{A_{t}} \\
                        \Pi_t           & \longleftarrow & \overline{\Pi_{t}} \\
                        \Theta_t        & \longleftarrow & \overline{\Theta_{t}} \\
                        B_t             & \longleftarrow & \overline{B_{t}}
                        \end{array}
                        $ \\
                        calcul de la vraisemblance du mod�le $L_t$
                \end{xwhile}
        \end{xalgostep}
        
        \end{xalgorithm}
        

                \begin{table}[t]
                    \[
                    \fbox{$%
                    \begin{array}[c]{rclcrcl}%
                    \overline{a_{i,j}}& = & \dfrac{\underset{k=1}{\overset{K}{{\displaystyle\sum}}}
                    \dfrac{1}{P_{k}}\left[  \underset{t=1}{\overset{T_{k}-1}
                    {{\displaystyle\sum}}}\alpha_{t}^{k}\left(  i\right)  \,a_{i,j}\,b_{j}\pa{O^k_{t+1}}
                    \,\beta_{t+1}^{k}\left(  j\right)  \right]  }
                    {\underset{k=1}{\overset{K}{{\displaystyle\sum}}}\dfrac{1}{P_{k}}\left[ 
                     \underset{t=1}{\overset{T_{k}}{{\displaystyle\sum}
                    }}\alpha_{t}^{k}\left(  i\right)  \beta_{t}^{k}\left(  i\right)  \right]  }
                    &
                    &
                    \overline{b_{i}\pa{o}}
                    &
                    =
                    &
                    \dfrac{\underset{k=1}{\overset{K}{{\displaystyle\sum}}}\dfrac{1}{P_{k}}\left[ 
                     \underset{t=1}{\overset{T_{k}}{{\displaystyle\sum}
                    }}\alpha_{t}^{k}\left(  i\right)  \beta_{t}^{k}\left(  i\right) 
                            \,\indicatrice{O_{t}^{k}=o}\right]  }
                    {\underset {k=1}{\overset{K}{
                    {\displaystyle\sum}}}\dfrac{1}{P_{k}}\left[  \underset{t=1}{\overset{T_{k}}{{\displaystyle\sum}
                    }}\alpha_{t}^{k}\left(  i\right)  \beta_{t}^{k}\left(  i\right)  \right]  }
                    \\%
                    & & & & & & \\%
                    \overline{\theta_{i}} & = & \dfrac{\underset{k=1}{\overset{K}{ {\displaystyle\sum}
                     }}\dfrac{1}{P_{k}}\alpha_{T_{k}}^{k}
                    \left(  i\right)  \,\overset{=\theta_{i} }{\overbrace{\beta_{T_{k}}^{k}\left(  i\right) 
                     }}}{\underset{k=1}{\overset{K}{
                    {\displaystyle\sum}}}\dfrac{1}{P_{k}}\left[  \underset{t=1}{\overset{T_{k}}{ {\displaystyle\sum}
                     }}\alpha_{t}^{k}\left(  i\right)
                    \beta_{t}^{k}\left(  i\right)  \right]  }
                    &
                    &
                    \overline{\pi_{i}}
                    &
                    =
                    &
                    \dfrac{1}{K}\underset{k=1}{\overset{K}{ {\displaystyle\sum}
                     }}\dfrac{1}{P_{k}}\overset{=\pi_{i}}{\overbrace{\alpha_{1}^{k}
                    \left( i\right)  }}\beta_{1}^{k}\left(  i\right)
                    \\ & & & & & &  \\
                    & & \text{avec } P_k = P\vecteur{O_1^k}{O_{T_k}^k} & & \text{et} & &
                                \alpha_t^k\pa{i} = \pr{\vecteurno{O_1^k}{O_t^k}, q_t = i | M} \\
                    & & & & & & \beta_t^k\pa{i} =  \pr{\vecteurno{O_{t+1}^k}{O_{T_k}^k} | q_t = i, M}
                    \end{array}
                    $}
                    \]
                    \caption{Formules de r�estimation de Baum-Welch.}
                    \label{figure_formule_baumwelch-fig}
                    \indexfr{Baum-Welch}
                    \indexfr{r�estimation}
                        \label{formule_baumwelch}
                \end{table}



            \begin{xtheorem} {convergence de l'algorithme~\ref{hmm_algorithme_baumwelch}}
            \label{theoreme_hmm_baum_welch_1}%
            \indexfr{Baum-Welch}
            Soit $M =\pa{A,B,\Theta,\Pi}$ une cha�ne de Markov et $\left( O^{k}=\left( O_{1}^{k},..., O_{T_{k}}^{k} \right) 
            \right) _{1\leqslant k\leqslant K}$
            une suite de s�quences d'observations, l'algorithme~\ref{hmm_algorithme_baumwelch} 
            implique la convergence croissante de la vraisemblance~:
            \indexfrr{s�quence}{observation}
                    \begin{eqnarray}
                    \underset{k=1}{\overset{K}{\prod}} \pr{ O_{1}^{k},...,O_{T_{k}}^{k}\left|  M\right.  }
                     \label{hmm_eq_vraisemblance_theo}
                    \end{eqnarray}
            \end{xtheorem}


\begin{xremark}{convergence vers un minimum local}
Le th�or�me~\ref{theoreme_hmm_baum_welch_1} d�montre de la suite $\pa{L_t}_{t \infegal 0}$ construite par l'algorithme~\ref{hmm_algorithme_baumwelch}, la valeur atteinte correspond � un minimum local et non global de la vraisemblance (\ref{hmm_eq_vraisemblance_theo}).
\indexfr{minimum local}
\end{xremark}




Les paragraphes qui suivent (\ref{hmm_apprentissage_chapter}...) donnent diff�rentes d�monstrations de ce th�or�me. 








\subsection{D�monstration intuitive}
\label{baumwelch_sens}


\begin{xdemo}{th�or�me}{\ref{theoreme_hmm_baum_welch_1}}

L'�tape~\ref{hmm_algo_apprentissage_step_recurrence} de l'algorithme d'apprentissage~\ref{hmm_algorithme_baumwelch} consiste � r�estimer les param�tres $A,\pi,\theta,B$ de mani�re � accro�tre la vraisemblance $L\pa{A,\pi,\theta,B}$ :%

        \begin{eqnarray*}
        L\pa{A,\pi,\theta,B} &=& \underset{k=1}{\overset{K}{\prod}}
                \pr{   O_{1}^{k},...,O_{T_{k}}^{k}\left| M\right.  }\\
        L\pa{A,\pi,\theta,B} &=& \underset{k=1}{\overset{K}{\prod}} \crochet 
                    {\summyone{s \in S} _pr{   O_{1}^{k},...,O_{T_{k}}^{k},s\left| M\right.  } }\\
        && \text{o� } s \text { est l'ensemble des s�quences d'�tats} \\
        && \text{de la cha�ne de Markov cach�e } M
        \end{eqnarray*}

Le principe des formules de Baum-Welch consiste � augmenter la valeur des param�tres tr�s probables et � diminuer celle de ceux peu probables. On note~:

\begin{itemize}
\item $l_{i,t}$ le nombre de chemins (ou s�quences) partant de l'�tat $i$ � l'instant $t$ (voir figure ~\ref{figure_baumwelch_idee-fig})
\item $l_{i,j,t}$ le nombre de chemins partant de l'�tat $i$ � l'instant $t$ et passant � l'�tat $j$ � l'instant $t+1$
        (voir figure~\ref{figure_baumwelch_idee-fig})
\end{itemize}

                        \begin{figure}[t]
                            $$\frame{$\begin{array}[c|c]{c}\includegraphics[height=6cm, width=15cm] 
                            {\filext{../dessin2/hmm_baumwelch_idee}}\end{array}$}$$
                            \caption{    Id�e des formules de Baum-Welch~: donner une nouvelle valeur
                                                � un coefficient tenant compte du nombre de chemins
                                                qui l'empruntent.}
                            \label{figure_baumwelch_idee-fig}
                        \end{figure}

La nouvelle valeur $\overline{a_{ij}}$ sera : $\overline{a_{ij}} = \dfrac{\summyone{t}l_{i,j,t}}{\summyone{t}l_{i,t}}$. Il reste � exprimer cette expression en termes de probabilit�s~:

        $$
        \begin{array}{l}
        \overline{a_{i,j}} = \dfrac{\overset{K}{\underset{k=1}{\sum}}\dfrac{1}{P_{k} }
                        \overset{T_{k}-1}{\underset{t=1}{\sum}}
                                \pr{  q_{t+1}=j,q_{t} =i,O^{k}}  }
                                {\overset{K}{\underset{k=1}{\sum}}\dfrac{1}{P_{k}} 
                        \overset{T_{k}}{\underset{t=1}{\sum}}
                    \pr{   q_{t}=i,O^{k}}  }%
        =\dfrac{\underset{k=1}{\overset{K}{\sum}}\dfrac{1}{P_{k}}\left[ \underset{t=1}
                        {\overset{T_{k}-1}{\sum}}\alpha_{t}^{k}\left(  i\right)
        \,a_{i,j}\,b_{j,O_{t+1}\,}\beta_{t+1}^{k}\left(  j\right)  \right] }
                    {\underset{k=1}{\overset{K}{\sum}}\dfrac{1}{P_{k}}\left[  \underset
        {t=1}{\overset{T_{k}}{\sum}}\alpha_{t}^{k}\left(  i\right)  \beta_{t}^{k}\left(  i\right)  \right]  } \\
        \text{d'apr�s l'expression (\ref{hmm_proba_transition}), page~\pageref{hmm_proba_transition}}
        \end{array}
        $$

La r�estimation des probabilit�s d'�mission suit le m�me raisonnement, pour all�ger les notations, on note $O=O^{k}$ et $C_{o}^{t}=\indicatrice{O_{t}=o}$ :

        \begin{eqnarray*}
        \pr{  O_{t}=o,q_{t},O}  &=& \pr{  C_{o}^{t},q_{t},O} = \pr{  O_{t+1},..,O_{T}\left| 
                         C_{o}^{t},q_{t},O_{1},...,O_{t}\right.
                }  \pr{  C_{o}^{t},q_{t},O_{1},...,O_{t}}\\
        \pr{C_o^t,q_t,O} &=& \pr{\vecteurno{O_1}{O_T} |q_t} \pr{C_o^t | q_t, \vecteurno{O_1}{O_t}}
                         \pr{q_t, \vecteurno{O_1}{O_t}} \\
        \pr{C_o^t,q_t,O} &=& \beta_t \pa{q_t} \indicatrice{O_t=o} \alpha_t \pa{q_t}
        \end{eqnarray*}

D'o� :%

        $$
        \overline{b_i\pa{o}}=\dfrac{\underset{k=1}{\overset{K}{\sum}}\dfrac{1}{P_{k} }
                        \left[  P\left(  O_{t}=o,q_{t}=i,O\right)  \right]  }{\underset{k=1}
        {\overset{K}{\sum}}\dfrac{1}{P_{k}}\left[  \underset{t=1}
                        {\overset{T_{k}}{\sum}}P\left(  q_{t}=i,O\right)  \right]}=\dfrac{\underset{k=1}{\overset
        {K}{\sum}}\dfrac{1}{P_{k}}\underset{t=1}{\overset{T_{k}}{\sum}}
                        \alpha_{t} ^{k}\left(  i\right)  \beta_{t}^{k}\left(  i\right)  \,\indicatrice{
        O_{t}^{k}=o}}{\underset{k=1}{\overset{K}{\sum}}\dfrac{1}{P_{k} }
                \underset{t=1}{\overset{T_{k}}{\sum}}\alpha_{t}^{k}\left(  i\right)
        \beta_{t}^{k}\left(  i\right)  }
        $$

On peut calculer de m�me~:

        $$
        \overline{\theta_{i}}=\dfrac{\underset {k=1}{\overset{K}{\sum}}\dfrac{1}{P_{k}} \pr{  q_{T_{k}}=i,O}
        }{\underset{k=1}{\overset{K}{\sum}}\dfrac{1}{P_{k}}\underset{t=1}
         {\overset{T_{k}}{\sum}} \pr{  q_{t}=i,O^{k}}  } \text{ et }\overline{\pi
        _{i}}=\underset{k=1}{\overset{K}{ {\displaystyle\sum} }}\dfrac{1}{P_{k}} \pr{  q_{1}=i,O^{k}}
        $$

\end{xdemo}












\subsection{Lemmes et th�or�mes interm�diaires}

Ces lemmes servent des d�monstrations plus rigoureuses expos�es au paragraphe suivant (\ref{hmm_demo_gradient_par}).


            \begin{xlemma}{Levinson1983 (1)}\label{hmm_lemme_baumwelch_1_un} (voir \citeindex{Levinson1983})
            
            Soit $\left(  u_{1},...,u_{N}\right)  \in\left( \R_{+}^{\ast}\right)  ^{N}$ et
             $\left(  v_{1},...,v_{N}\right) \in\left( \R_{+}\right) ^{N}$ tels que $\overset{N}{\underset {i=1}{\sum}}v_{i}>0$ alors :
            
                    $$
                    \ln\left[  \frac{\overset{N}{\underset{i=1}{\sum}}v_{i}}{\overset{N}{\underset{i=1}{\sum}}
                                u_{i}}\right]  \geqslant\dfrac{\overset
                    {N}{\underset{i=1}{\sum}}u_{i}\ln v_{i}-u_{i}\ln u_{i}}{\overset{N} {\underset{i=1}{\sum}}u_{i}}
                    $$
                    
            \end{xlemma}

\begin{xdemo}{lemme}{\ref{hmm_lemme_baumwelch_1_un}}
On utilise la concavit� de la fonction logarithme :
        $$
        \ln\left[  \frac{\overset{N}{\underset{i=1}{\sum}}v_{i}}{\overset
        {N}{\underset{i=1}{\sum}}u_{i}}\right]  =\ln\left[  \overset{\text{moyenne
        pond�r�e}}{\overbrace{\overset{N}{\underset{i=1}{\sum}}\frac{u_{i}%
        }{\overset{N}{\underset{k=1}{\sum}}u_{k}}\dfrac{v_{i}}{u_{i}}}}\right]
        \geqslant\overset{N}{\underset{i=1}{\sum}}\frac{u_{i}}{\overset{N}%
        {\underset{k=1}{\sum}}u_{k}}\ln\dfrac{v_{i}}{u_{i}}=\frac{1}{\overset
         {N}{\underset{k=1}{\sum}}u_{k}}\overset{N}{\underset{i=1}{\sum}}u_{i}\ln
        v_{i}-u_{i}\ln u_{i}
        $$
\end{xdemo}









        \begin{xlemma}{Levinson1983 (2)}\label{hmm_lemme_baumwelch_2_deux} (voir \citeindex{Levinson1983})
        Soit $\left(  u_{1},...,u_{N}\right)  \in\left( \R_{+}^{\ast}\right)  ^{N}$, 
        la solution unique de la maximisation sous contrainte suivante~:
                $$
                \left|
                \begin{array}{l}%
                \underset{\left(  x_{1},...,x_{N}\right)  }{\max}\,\overset{N}{\underset
                {i=1}{\sum}}u_{i}\ln x_{i}\\
                \overset{N}{\underset{i=1}{\sum}}x_{i}=1
                \end{array}
                \right.
                $$
        est obtenue pour $\forall i\in\left\{  1,...,N\right\}  ,\; x_{i}=\dfrac{u_{i}}{\overset{N}{\underset{i=1}{\sum}}u_{i}}$
        \end{xlemma}



\begin{xdemo}{lemme}{\ref{hmm_lemme_baumwelch_2_deux}}
On utilise les multiplicateurs de Lagrange, on pose : $F\left(  x_{1} ,...,x_{N},\lambda\right)
=\overset{N}{\underset{i=1}{\sum}}u_{i}\ln x_{i}+\lambda\left(  \overset{N}{\underset{i=1}{\sum}}x_{i}-1\right)  $

Lorsque $F$ est maximum, ses d�riv�es partielles v�rifient :
        \begin{eqnarray*}
        \dfrac{\partial F\left(  x_{1},...,x_{N},\lambda\right)  }{\partial x_{k} }=\dfrac{u_{k}}{x_{k}}+\lambda=0 &\Longleftrightarrow&
            x_{k}=-\dfrac{u_{k} }{\lambda}\\
        &\Longrightarrow& -\overset{N}{\underset{k=1}{\sum}}\dfrac{u_{k}
         }{\lambda}=-1\Longrightarrow\lambda=-\overset{N}{\underset{k=1}{\sum}}
        u_{k}\Longrightarrow x_{k}=\dfrac{u_{k}}{\overset{N}{\underset{k=1}{\sum} }u_{k}}
        \end{eqnarray*}
\end{xdemo}










            \begin{xlemma}{multiplicateurs de Lagrange}\label{hmm_lemme_baumwelch_3_trois}
            La solution du probl�me de maximisation suivant :
                    $$
                    \left|\begin{array}{l}%
                    \underset{\left(  x_{1},...,x_{N}\right)  }{\max}f\left(  x_{1},...,x_{N}%
                    \right) \\
                    \overset{N}{\underset{i=1}{\sum}}x_{i}=1
                    \end{array}
                    \right.
                    $$
                    $$
                    \text{ v�rifie }\quad \underset{k=1}{\overset{N}{%
                    {\displaystyle\sum} }}x_{k}\dfrac{\partial f}{\partial x_{k}}
                    \left(  x_{1},...,x_{N}\right) \neq0\Longrightarrow\forall i \in \intervalle{1}{N},
                    \; x_{i}=\dfrac{x_{i}\dfrac{\partial f}{\partial x_{i}}\left(  x_{1},...,x_{N}\right)  }{\underset{k=1}{\overset
                    {N}{%
                    {\displaystyle\sum} }}x_{k}\dfrac{\partial f}{\partial x_{k}}\left(  x_{1},...,x_{N}\right)  }
                    $$
            \end{xlemma}



\begin{xdemo}{lemme}{\ref{hmm_lemme_baumwelch_3_trois}}
On utilise les multiplicateurs de Lagrange, on pose : $F\left(  x_{1},...,x_{N},\lambda\right)  =f\left(  x_{1},...,x_{N}\right)  +\lambda\left( \overset{N}{\underset{i=1}{\sum}}x_{i}-1\right)  $ Lorsque $F$ est
maximum, ses d�riv�es partielles v�rifient (on pose $X=\vecteur{x_1}{x_N}$~:

        \begin{eqnarray*}
        \dfrac{\partial F\left( X,\lambda\right)  }{\partial x_{k} }=\dfrac{\partial f}{\partial x_{k}}\left(X\right)
            +\lambda=0 &\Longrightarrow&  x_{k}\dfrac{\partial f}{\partial x_{k}}\left(X\right)  +\lambda x_{k}=0 \\
        &\Longrightarrow& \underset{k=1}{\overset{N}{{\displaystyle\sum} }}\left[  x_{k}\dfrac{\partial f}{\partial x_{k}}\left(X\right)
            +\lambda x_{k}\right]  =0\\
        &\Longrightarrow& \underset{k=1}{\overset{N}{{\displaystyle\sum}}}x_{k}
                \dfrac{\partial f}{\partial x_{k}}\left(X\right)  =-\lambda
        \end{eqnarray*}

En rempla�ant $\lambda$ par $-\underset{k=1}{\overset{N}{ {\displaystyle\sum} }}x_{k}\dfrac{\partial f}{\partial x_{k}}\left(  ...\right)  $ dans chacune des �quations aux d�riv�es partielles, on d�montre le lemme ~\ref{hmm_lemme_baumwelch_3_trois}. Cette optimisation revient � chercher le maximum de la fonction $f$ sur l'hyperplan d'�quation $\overset{N}{\underset{i=1}{\sum}}x_{i}=1$.
\end{xdemo}


C'est ce lemme qui est � la source du th�or�me~\ref{theorem_loglogconvexe} mais au pr�alable suivent une d�finition et un lemme.








            \begin{xdefinition}{fonction log-log-convexe}
            \label{definition_log_log_convexe}
            \indexfr{log-log-convexe}%
            Soit une fonction :
                    $$
                    \begin{array}{rccl}
                    f : & \pa{\R^*_+}^n &\longrightarrow& \R+^* \\
                    & \vecteur{x_1}{x_n} &\longrightarrow& f \vecteur{x_1}{x_n}
                    \end{array}
                    $$
            $f$ est une fonction \emph{log-log-convexe} si et seulement si la fonction :
                    $$
                    \begin{array}{rccl}
                    g : & \pa{\R}^n &\longrightarrow& \R+^* \\
                    & \vecteur{u_1}{u_n} &\longrightarrow& g\vecteur{u_1}{u_n} = \ln \crochet{ f \vecteur{e^{u_1}}{e^{u_n}}}
                    \end{array}
                    $$
            est une fonction convexe.
            \end{xdefinition}







            \begin{xlemma}{distance de Kullback-Leiber}
            \label{lemme_loglogconvexe}%
            \indexfrr{distance}{Kullback-Leiber}%
            On pose $D = \accolade{x=\vecteur{x_1}{x_n} \in \R^n \left| \summy{i=1}{n} x_i = 1 \text{ et } 
                            \forall i \in \intervalle{1}{n}, x_i > 0 \right.} $.\newline%
            Soit $\pa{x,y} \in D^2$ alors :
                    $$
                    \summy{i=1}{n} y_i \ln \crochet{\dfrac{x_i}{y_i}} \infegal 0
                    $$
            \end{xlemma}


\begin{xdemo}{lemme}{\ref{lemme_loglogconvexe}}
La fonction $x \longrightarrow \ln x$ est concave, donc :
        \begin{eqnarray*}
        \summy{i=1}{n} y_i \ln \crochet{\dfrac{x_i}{y_i}} &=&  \summy{i=1}{n} \;  \dfrac{y_i}{\summy{k=0}{n}y_k} \; 
                    \ln \crochet{\dfrac{x_i}{y_i}} \text{ car } y \in D\\
        &\infegal&  \ln \crochet { \summy{i=1}{n} \dfrac{y_i}{\summy{k=0}{n}y_k}  \dfrac{x_i}{y_i} } \\
        &\infegal&  \ln \crochet {  \dfrac{\summy{i=1}{n}x_i}{\summy{i=0}{n}y_i}  }  = 
        \ln \dfrac{1}{1} \text{ car } \pa{x,y} \in D^2 \\
        &\infegal& 0
        \end{eqnarray*}
\end{xdemo}











            \begin{xtheorem}{fonction log-log-convexe}
            \label{theorem_loglogconvexe}%
            \indexfr{log-log-convexe}%
            On pose $D = \accolade{x=\vecteur{x_1}{x_n} \in \R^n \left| \summy{i=1}{n} x_i = 1 \text{ et } \forall i 
            \in \intervalle{1}{n}, x_i > 0 \right.} $.\newline%
            Soit $f : \pa{\R^*_+}^n \longrightarrow \R+^*$ une fonction log-log-convexe d�rivable.\newline%
            Soit $x \in D$, on d�finit $y \pa{x} = \vecteur{y_1\pa{x}}{y_n\pa{x}} \in D$ tel que :
                    $$
                    \forall i \in \intervalle{1}{n}, \; y_i \pa{x} = \frac{x_i \partialfrac{f}{x_i}\pa{x}}
                                {\summy{k=1}{n}x_k \partialfrac{f}{x_k}\pa{x}}
                    $$
            alors $f$ v�rifie :
                    $$
                    \forall x \in D, \; f\pa{ y \pa{x}} \supegal f\pa{x}
                    $$
            \end{xtheorem}
            
            
            
            
\begin{xdemo}{th�or�me}{\ref{theorem_loglogconvexe}}

Soit $\pa{x,x'} \in D^2$, on d�finit $\pa{u,u'} \in \pa{\R^n}^2$ tel que :

        $$
        \forall i \in \intervalle{1}{n}, \; u_i = \ln x_i \text{ et } u'_i = \ln x'_i
        $$
        
$u$ et $u'$ v�rifient :

        $$
        \summy{i=1}{n} e^{u_i} = 1  \text{ et } \summy{i=1}{n} e^{u'_i} = 1
        $$
        
On pose $h\pa{u} = \ln f\vecteur{e^{u_1}}{e^{u_n}}$, $f$ est log-log-convexe, donc :

        \begin{eqnarray*}
        h \pa{u'}  - h \pa{u} &\supegal& \summy{i=1}{n}  \partialfrac{h}{u_i}\pa{u} \pa{u'_i - u_i} \\
        \ln f \pa{x'}  - \ln f \pa{x} &\supegal& \summy{i=1}{n}  \dfrac{e^{u_i}}{f\pa{x}} \partialfrac{f}{x_i} 
                    \pa{x}\pa{\ln x'_i - \ln x_i} \\
        \ln \crochet{\dfrac{f \pa{x'}}{f \pa{x}}} &\supegal& \summy{i=1}{n} \dfrac{x_i}{f\pa{x}} \partialfrac{f}{x_i} 
                \pa{x}\ln \crochet {
            \dfrac{x'_i}{x_i}}
        \end{eqnarray*}

Si $x' = y\pa{x} = \pa{y_i \pa{x} = \frac{x_i \partialfrac{f}{x_i}\pa{x}}{\summy{k=1}{n}x_k \partialfrac{f}{x_k}\pa{x}}}_{1 \infegal i \infegal n}$, alors~:

        $$
        \begin{array}{rrcl}
        & - \ln \crochet{\dfrac{f \pa{y\pa{x}}}{f \pa{x}}} &\infegal&
                        \summy{i=1}{n} \dfrac{x_i}{f\pa{x}} \partialfrac{f}{x_i} \pa{x}\ln \crochet {\dfrac{x_i}{y_i\pa{x}}} \\
        \Longrightarrow & - \ln \crochet{\dfrac{f \pa{y\pa{x}}}{f \pa{x}}} &\infegal&
                        \crochet{\summy{i=1}{n}  \dfrac{ x_i\partialfrac{f}{x_i} \pa{x} } {f\pa{x}}}
                        \underset{\infegal 0 \text{ d'apr�s le lemme ~\ref{lemme_loglogconvexe}}}{\underbrace{\crochet{\summy{i=1}{n}
                                          y_i\pa{x} \ln \crochet {\dfrac{x_i}{y_i\pa{x}}}}}} \\
        \Longrightarrow & \ln \crochet{\dfrac{f \pa{y\pa{x}}}{f \pa{x}}} &\supegal& 0 \\ \\
        \Longrightarrow &  f \pa{y\pa{x}} &\supegal& f \pa{x}
        \end{array}
        $$
        
\end{xdemo}








        \begin{xcorollary}{polyn�me � coefficients positifs (Baum1968)} \label{hmm_theorem_baumwelch_un} (voir \citeindex{Baum1968})
        \indexfr{log-log-convexe}%
        \indexfr{polyn�me}%
        
        Soit $P : \R^N \dans \R$ un polyn�me dont les coefficients sont tous positifs, 
        soit $x = \vecteur{x_1}{x_N} \in \R^N$ tels que $\summy{i=1}{N}x_i = 1$ et $\forall i \in \intervalle{1}{N}, 
                \; x_i \supegal 0$, 
        soit $y = \vecteur{y_1}{y_N} \in \R^N$ d�fini par~:
                $$
                \forall i \in \intervalle{1}{N}, \; y_i = \frac{x_i \partialfrac{P}{x_i}\pa{x}}{\summy{k=1}{N}x_k \partialfrac{P}{x_k}\pa{x}}
                $$
        alors~:
                $$
                P\pa{y} \supegal P\pa{x}
                $$
        \end{xcorollary}



\begin{xdemomine}{corollaire}{\ref{hmm_theorem_baumwelch_un}}

Soit $D$ l'ensemble d�fini dans le th�or�me~\ref{theorem_loglogconvexe}, si $f$ est une fonction log-log-convexe d�fini sur $\overline{D}$, si $f$ est continue alors les �galit�s d�montr�es sur $D$ le sont aussi sur $\overline{D}$. Il ne reste plus qu'� d�montrer qu'un polyn�me � coefficients positifs est log-log-convexe.

Soit $x=\vecteur{x_1}{x_n} \in D$, on note $e^u = \vecteur{e_{u_1}}{e_{u_n}}$, on peut �crire le polyn�me $P$ sous la forme :
        \begin{eqnarray*}
        P\pa{x} &=& \summyone{ 0 \infegal \vecteurno{i_1}{i_n} \infegal \deg P} \; 
                    a_{\vecteurno{i_1}{i_n}} \prody{k=1}{n} x_k^{i_k} \\
        P\pa{e^u} &=& \summyone{ 0 \infegal \vecteurno{i_1}{i_n} \infegal \deg P} \; 
                    a_{\vecteurno{i_1}{i_n}} \prody{k=1}{n} \pa{e^{u_k}}^{i_k} \\
        P\pa{e^u} &=& \summyone{ 0 \infegal \vecteurno{i_1}{i_n} \infegal \deg P} \; 
                    a_{\vecteurno{i_1}{i_n}} e^{ \summy{k=1}{n} i_k u_k} \\
        \partialfrac{P\pa{e^u}}{u_l} &=& \summyone{ 0 \infegal \vecteurno{i_1}{i_n}
                 \infegal \deg P} \; a_{\vecteurno{i_1}{i_n}} \,  i_l \, e^{ \summy{k=1}{n} i_k
            u_k}
        \end{eqnarray*}
        
On pose $i = \vecteur{i_1}{i_n}$. On en d�duit pour $m \in \intervalle{1}{n}$ que :

        \begin{eqnarray*}
        \dfrac{\partial \pa{\ln P\pa{e^u}}}{\partial u_l \partial u_m} &=& \dfrac{1}{P^2\pa{e_u}} \crochet {%
            \begin{array}{cl}
                & \pa{\summyone{i} \; a_i \,  i_l i_m \, e^{\scal{i,u}}} \pa{\summyone{i} \; a_i \,  e^{\scal{i,u}}} \\%
            -   & \pa{\summyone{i} \; a_i \,  i_l \, e^{\scal{i,u}}}      \pa{\summyone{i} \; a_i \, 
                    i_m \, e^{\scal{i,u}}}%
            \end{array}}
         \\
        \dfrac{\partial \pa{\ln P\pa{e^u}}}{\partial u_l \partial u_m} &=& \dfrac{1}{P^2\pa{e_u}} \crochet {%
            \summyone{i} \summyone{j} \; a_i \, a_j \, i_l \pa{i_m -j_m} \, e^{\scal{i,u}} \, e^{\scal{j,u}}}
        \end{eqnarray*}

Il faut montrer que la matrice $\pa{\dfrac{\partial \pa{\ln P\pa{e^u}}}{\partial u_l \partial u_m}}_{u_l u_m}$ est d�finie positive. On cherche donc � montrer que pour tout $y \in \R^n$, $\summyone{l,m} y_l y_m \dfrac{\partial \pa{\ln P\pa{e^u}}}{\partial u_l \partial u_m} \supegal 0$. On note $b_{\vecteurno{i_1}{i_n}} = a_{\vecteurno{i_1}{i_n}} e^{ \summy{k=1}{n} i_k u_k} \supegal 0 $.

        \begin{eqnarray*}
        \summyone{l,m} y_l y_m \dfrac{\partial \pa{\ln P\pa{e^u}}}{\partial u_l \partial u_m} & = &
            \summyone{l,m} y_l y_m  \summyone{i} \summyone{j} \; a_i \, a_j \, i_l \pa{i_m -j_m} \,
                             e^{\scal{i,u}} \, e^{\scal{j,u}} \\ \\
        & = & \summyone{i} \summyone{j} \; \summyone{l,m}  \; y_l y_m  \; b_i b_j i_l \pa{i_m -j_m} \\
        & = & \summyone{i} \summyone{j} \; b_i b_j \pa{ \summyone{l,m}  \; y_l y_m   i_l \pa{i_m -j_m}} \\
        & = & \summyone{i} \summyone{j} \; b_i b_j \pa{
                                        \crochet { \summyone{l}  y_l i_l }   \crochet{ \summyone{m}  y_m  i_m }
                                    -   \crochet { \summyone{l}  y_l i_l }   \crochet{ \summyone{m}  y_m  j_m } }
        \end{eqnarray*}

On pose $I_i = \summyone{l}  y_l i_l $, comme $\dfrac{\partial \pa{\ln P\pa{e^u}}}{\partial u_l \partial u_m} =\dfrac{\partial \pa{\ln P\pa{e^u}}}{\partial u_m \partial u_l}$, on peut �crire que~:

        \begin{eqnarray*}
        \summyone{l,m} y_l y_m \dfrac{\partial \pa{\ln P\pa{e^u}}}{\partial u_l \partial u_m} & = &
          \dfrac{1}{2} \summyone{l,m} y_l y_m \crochet{ \dfrac{\partial \pa{\ln P\pa{e^u}}}{\partial u_l \partial u_m} +
                                         \dfrac{\partial \pa{\ln \pr{e^u}}}{\partial u_m \partial u_l} } \\
        & = & \dfrac{1}{2} \summyone{i} \summyone{j} \; b_i b_j \pa{ I_i^2 - I_i I_j + I_j^2 -  I_j I_i } \\
        & = & \dfrac{1}{2} \summyone{i} \summyone{j} \; b_i b_j \pa{ I_i - I_j}^2 \\
        & \supegal & 0
        \end{eqnarray*}

Un polyn�me � coefficients positifs est donc log-log-convexe.
\end{xdemomine}









\subsection{D�monstration bas�e sur le gradient}
\label{hmm_demo_gradient_par}
\indexfr{gradient}

Cette d�monstration est pr�sent�e dans \citeindex{Levinson1983}.


\begin{xdemo}{th�or�me}{\ref{theoreme_hmm_baum_welch_1}}


L'expression de la probabilit� d'une s�quence $O$ connaissant le mod�le $M$ est :%

        $$
        \pr{  O\left|  M\right.  }  =\underset{\left(  q_{1},...,q_{T}%
        \right)  }{\overset{}{{\displaystyle\sum} }}\left[  \pi_{q_{1}}b_{q_{1}}\left(  O_{1}\right)  \left(  \underset
        {t=1}{\overset{T-1}{\prod}}a_{q_{t},q_{t+1}}b_{q_{t+1}}\left(  O_{t}\right) \right)  \theta_{q_{T}}\right]
        $$

Chaque coefficient intervient plusieurs fois dans l'expression de la probabilit�, cependant il ne peut intervenir qu'une seule fois � chaque temps $u\in\left\{  1,...T\right\}  $. C'est pourquoi on d�compose $P\left(  O\left|  M\right.  \right)  $ en~:

        \begin{eqnarray}
        \pr{   O\left|  M\right.  }   &=& \underset{u=1}{\overset{T-1}{\sum} }
                \left[  \underset{\left(  i,j\right)  }{\overset{}{
            {\displaystyle\sum}}}a_{ij}b_{j}\left(  O_{t}\right)  \underset{=
                        \pr{  q_{u}=i,\,q_{u+1} =j,O\left|  M\right.  }
            }{\underbrace{\underset{\left(  q_{1},...,q_{T}\right)  }
            {\overset{q_{u}=i,\,q_{u+1}=j}{ {\displaystyle\sum} }}\pi_{q_{1}}b_{q_{1}}\left(
            O_{1}\right)  \theta_{q_{T}}\left(\underset{t=1,t\neq u}{\overset{T-1}{\prod}}a_{q_{t},q_{t+1}}b_{q_{t+1}
            }\left(  O_{t}\right)  \right)  }}\right] \nonumber\\
        \Longleftrightarrow \pr{  O\left|  M\right.  } &=& \underset{u=1}
                    {\overset{T-1}{\sum}}\left[  \underset{\left(  i,j\right)
            }{\overset{}{{\displaystyle\sum} }}a_{ij}b_{j}\left(  O_{t}\right)  \alpha_{u}
                    \left(  i\right)  \beta _{u+1}\left(  j\right)  \right]
            \label{hmm_gradient_equation_un}\\
        \Longleftrightarrow \pr{  O\left|  M\right.  }  &=& \underset
                 {u=1}{\overset{T}{\sum}}\,\underset{i,o}{\overset{}{{\displaystyle\sum}
            }}b_{i}\left(  o\right)  \underset{=\pr{  q_{u}=i,\,O_{u}=o,O\left| 
                M\right.  }  = \pr{  q_{u}=i,\,O\left|  M\right.  }
            \,\indicatrice{O_{u}=o}}{\underbrace{\underset{\left(q_{1},...,q_{T}\right)  }
            {\overset{q_{u}=i,\,O_{u}=o}{ {\displaystyle\sum}
            }}\left[  \pi_{q_{1}}b_{q_{1}}\left(  O_{1}\right)  \left(  \underset
                 {t=1}{\overset{T-1}{\prod}}a_{q_{t},q_{t+1}}b_{q_{t+1}}\left(  O_{t}\right)
            \right)  \theta_{q_{T}}\right] \label{hmm_gradient_equation_deux} }}
        \end{eqnarray}


On en d�duit que :%

        $$
        \begin{array}
        [c]{rrcl}%
            (\ref{hmm_gradient_equation_un})\Longrightarrow & %
            \dfrac{\partial \pr{  O\left|  M\right.  }  }{\partial a_{ij} }%
            & = &%
            \underset{u=1}{\overset{T-1}{\sum}}b_{j}\left(O_{t}\right) 
                     \alpha _{u}\left(  i\right)  \beta_{u+1}\left(  j\right)
        \\
            (\ref{hmm_gradient_equation_un})\Longrightarrow & %
            \dfrac{\partial \pr{  O\left|  M\right.  }  }{\partial\pi_{i}}%
            & = &%
            \beta_{1}\left(  i\right)
        \\
            (\ref{hmm_gradient_equation_un})\Longrightarrow & %
            \dfrac{\partial \pr{  O\left|  M\right.  }  }{\partial\theta_{i}}%
            & = & %
            \alpha_{T}\left(  i\right)  b_{i}\left(  O_{T}\right)
        \\
            (\ref{hmm_gradient_equation_deux})\Longrightarrow &%
            \dfrac{\partial \pr{   O\left|  M\right.  }  }{\partial b_{i}\left( o\right) }%
            & = &%
            \underset{u=1}{\overset{T}{\sum}}\alpha_{u}\left( i\right)\beta_{u}
                \left(  i\right)  \,\mathbf{1}_{\left\{  O_{u}=o\right\}  }%
        \end{array}
        $$

De plus, dans le cas de plusieurs s�quences, si $x$ est un coefficient du mod�le, on utilise le fait que :

        $$
        \dfrac{\partial L}{\partial x}=\dfrac{\partial\left(  \underset{k=1}{\overset{K}{\prod}} \pr{
         O_{1}^{k},...,O_{T_{k}}^{k}\left|  M\right.
        }  \right)  }{\partial x}=\underset{k=1}{\overset{K}{ {\displaystyle\sum} }}\dfrac{L}
        { \pr{  O^{k}\left|  M\right.  }
        }\dfrac{\partial \pr{ O^{k}\left|  M\right.  }  }{\partial x}
        $$

Comme la fonction $\pa{A,B,\theta,\pi} \longrightarrow \pr{O|M}$ est un polyn�me � coefficients positifs, le th�or�me~\ref{hmm_theorem_baumwelch_un} nous assure de la croissance de $\pr{O|M}$ au cours des it�rations de l'algorithme d'apprentissage. Comme cette suite est major�e par $1$, elle est convergente.

\end{xdemo}




\subsection{D�monstration ant�rieure � la d�couverte de l'algorithme EM}
\label{hmm_demo_em_em}

Cette d�monstration est pr�sent�e dans \citeindex{Levinson1983}.


\begin{xdemo}{th�or�me}{\ref{theoreme_hmm_baum_welch_1}}


Soient deux mod�les $M$ et $M^{\prime}$ poss�dant le m�me nombre d'�tats. On d�finit $P_{k}\left( M\right)  = \pr{   O^{k}\left|  M\right. } $ et $P_{k}\left( M^{\prime}\right)  = \pr{  O^{k}\left|  M^{\prime}\right.  }$. Pour cette s�quence d'observations, il existe $N^{T_{k}}$ s�quences d'�tats possibles. On note $s^{i}=\left(  s_{1}^{i},...,s_{T_{k}}%
^{i}\right)  $ la s�quence d'�tat d'indice $i$.

        $$
        P_{k}\left(  M\right)  =\underset{\left(  q_{1},...,q_{T_{k}}\right)}{\overset{}{{\displaystyle\sum}}}\left[
         \pi_{q_{1}}b_{q_{1}}\left(
        O_{1}^{k}\right)  \left(  \underset {t=1}{\overset{T_{k}-1}
                {\prod}}a_{q_{t},q_{t+1}}b_{q_{t+1}}\left(  O_{t} ^{k}\right)  \right)
        \theta_{q_{T_{k}}}\right]  =\underset{i=1} {\overset{N^{T_{k}}}{ {\displaystyle\sum}}}u_{i}^{k}
        $$

De mani�re analogue :

        $$
        P_{k}\left(  M^{\prime}\right)  =\underset{\left(q_{1},...,q_{T}\right)  }
        {\overset{}{{\displaystyle\sum} }}\left[
        \pi_{q_{1}}^{\prime}b_{q_{1}}^{\prime}\left(  O_{1}^{k}\right) \left(
         \underset{t=1}{\overset{T_{k}-1}{\prod}}a_{q_{t},q_{t+1}}^{\prime
        }b_{q_{t+1}}^{\prime}\left(  O_{t}^{k}\right)  \right) 
                 \theta_{q_{T_{k}} }^{\prime}\right]  =\underset{i=1}{\overset{N^{T_{k}}}{
        {\displaystyle\sum} }}v_{i}^{k}
        $$

En appliquant le lemme ~\ref{hmm_lemme_baumwelch_1_un}, on trouve :

        $$
        \ln\left(  \dfrac{\underset{k=1}{\overset{K}{\prod}}P_{k}\left(  M^{\prime }\right) 
         }{\underset{k=1}{\overset{K}{\prod}}P_{k}\left(  M\right)
        }\right)=\underset{k=1}{\overset{K}{\sum}}\ln\left(  \frac{\underset{i=1}
        {\overset{N^{T_{k}}}{ {\displaystyle\sum}
        }}v_{i}^{k}}{\underset{i=1}{\overset{N^{T_{k}}}{ {\displaystyle\sum} }}u_{i}^{k}}\right) 
         \geqslant\underset{k=1}{\overset{K}{\sum}}\dfrac
        {\overset{N^{T_{k}}}{\underset{i=1}{\sum}}u_{i}^{k}\ln v_{i}^{k}-u_{i}^{k}\ln
        u_{i}^{k}}{\overset{N^{T_{k}}}{\underset{i=1}{\sum}}u_{i}^{k}}=\underset {k=1}
        {\overset{K}{\sum}}\left[  \dfrac{Q_{k}\left(
         M,M^{\prime}\right)
        }{P_{k}\left(  M\right)  }-\frac{Q_{k}\left(  M,M\right)  }{P_{k}\left( M\right)  }\right]
        $$

On cherche � maximiser :

        $$
        \underset{\left(  v_{1},...,v_{N^{T}}\right) }{\max}\,\underset{k=1}{\overset{K}{\sum}}
        \dfrac{Q_{k}\left(  M,M^{\prime
        }\right)  }{P_{k}\left(  M\right)  }=\underset{\left(  v_{1},...,v_{N^{T}}\right) 
         }{\max}\,\underset{k=1}{\overset{K}{\sum}}\left[  \dfrac{1}
        {P_{k}\left(  M\right)  }\overset{N^{T_{k}}}{\underset{i=1}{\sum}}u_{i}^{k}\ln v_{i}^{k}\right]
        $$

Or :
        $$
        u_{i}^{k}\ln v_{i}^{k}=u_{i}^{k}\left[  \ln\pi_{q_{s_{1}^{i}}}^{\prime }+\ln b_{s_{1}^{i}}^{\prime}
        \left(  O_{1}^{k}\right)  +\underset{t=1}
        {\overset{T_{k}-1}{\sum}}\left(  \ln a_{s_{t}^{i},s_{t+1}^{i}}^{\prime}+
        \ln b_{s_{t+1}^{i}}^{\prime}\left(  O_{t}^{k}\right) 
         \right)  +\ln\theta
        _{s_{T}^{i}}^{\prime}\right]
        $$

On cherche � �crire diff�remment la somme $\overset{N^{T_{k}}}{\underset{i=1}{\sum}}u_{i}^{k}\ln v_{i}^{k}$ sous la forme$\,$ :

        \begin{eqnarray}
        \underset{k=1}{\overset{K}{\sum}}\left[\dfrac{1}{P_{k}\left(  M\right) }
        \overset{N^{T_{k}}} {\underset{i=1}{\sum} }u_{i}^{k}\ln v_{i}^{k}\right]
        =\underset{n=1}{\overset{N}{\sum}} C_{n}\ln \pi_{n}^ {\prime} + \underset{n=1} {\overset{N}{\sum}}\underset{m=1}
        {\overset {N}{\sum}}A_{nm}\ln
        a_{nm}^{\prime}+\underset{n=1}{\overset{N}{\sum}} \underset{o}{\overset{}{\sum}}B_{n,o}\ln b_{n}^{\prime}\left(
        o\right)+\underset{n=1}{\overset{N}{\sum}}D_{n}\ln\theta_{n}^{\prime} \label{hmm_em_equation_trois}
        \end{eqnarray}

Pour cela, on note :

\begin{itemize}
\item $p\left(  s,i,j\right)  $ avec $\left(  i,j\right)  \in\left\{ E,S,1,...,N\right\}  ^{2}$ le nombre de fois o� la connexion $i\rightarrow j$ est utilis�e dans la s�quence d'�tats $s$

\item $p^{\prime}\left(  s,i,o\right)  $ avec $\left(  i,o\right)  \in\left\{ E,S,1,...,N\right\} \times\mathbf{O}$ le nombre de fois o� l'�tat $i$ �met l'observation $o$ dans la s�quence d'�tats $s$
\end{itemize}\bigskip


Avec ces notations~:

        \begin{eqnarray}
            A_{nm}%
            & = &%
            \underset{k=1}{\overset{K}{\sum}}\dfrac{1}{P_{k}\left(  M\right)}\overset{N^{T_{k}}}
            {\underset{i=1}{\sum}}u_{i}^{k}\,p\left(  s^{i} ,n,m\right)%
            = %
            \underset{k=1}{\overset{K}{\sum}}\dfrac{1}{P_{k}\left(M\right)  }
            \pr{  q_{t}=n,q_{t+1}=m,O^{k}\left|  M\right.  } \label{hmm_em_demo_eq_un}%
        \\
            B_{n}%
            &  = & %
            \underset{k=1}{\overset{K}{\sum}}\dfrac{1}{P_{k}\left(  M\right)
             }\overset{N^{T_{k}}}{\underset{i=1}{\sum}}u_{i}^{k}\,p^{\prime}\left(
            s^{i},n,o\right)%
            = %
            \underset{k=1}{\overset{K}{\sum}}\dfrac{1}{P_{k}\left(M\right)  }
            \pr{ q_{t}=n,O_{t}=o,O^{k}\left|  M\right.  } \label{hmm_em_demo_eq_deux}
        \\
            C_{n}%
            &  =&%
            \underset{k=1}{\overset{K}{\sum}}\dfrac{1}{P_{k}
            \left(  M\right)}\overset{N^{T_{k}}}{\underset{i=1}{\sum}}u_{i}^{k}\,p\left(  s^{i} ,E,k\right)%
            = %
            \underset{k=1}{\overset{K}{\sum}}\dfrac{1}{P_{k}\left(M\right)  }
            \pr{  q_{1}=n,O^{k}\left|  M\right.  } \label{hmm_em_demo_eq_trois}%
        \\
            D_{n}%
            & = &%
            \underset{k=1}{\overset{K}{\sum}}\dfrac{1}{P_{k}\left(  M\right)}
            \overset{N^{T_{k}}}{\underset{i=1}{\sum}}u_{i}^{k}\,p\left(  s^{i} ,n,S\right)%
            = %
            \underset{k=1}{\overset{K}{\sum}}\dfrac{1}{P_{k}\left( M\right)  }
            \pr{  q_{T_{k}}=n,O^{k}\left|  M\right.  }\label{hmm_em_demo_eq_quatre}%
        \end{eqnarray}

Les �quations (\ref{hmm_proba_state}) et (\ref{hmm_proba_transition}) (page~\pageref{hmm_proba_transition}) permettent de d�duire les valeurs de $A_{nm}, B_{n}, C_{n}, D_{n}$. En appliquant le lemme~\ref{hmm_lemme_baumwelch_2_deux} � l'�quation (\ref{hmm_em_equation_trois}), on d�montre que les valeurs qui maximisent $Q\left(M,M^{\prime}\right)  $ sont~:%

        $$
        \begin{array}
        [c]{ccc}%
        a_{ij}^{\prime}=\dfrac{A_{ij}}{\overset{N}{\underset{l=1}{\sum}}A_{il}} &  &
        b_{i,o}^{\prime}=\dfrac{B_{i,o}}{\overset{}{\underset{r\in\mathbf{O}}{\sum}%
        }B_{i,r}}\\
        \pi_{i}^{\prime}=\dfrac{C_{i}}{\overset{N}{\underset{l=1}{\sum}}C_{l}} &  &
        \theta_{i}^{\prime}=\dfrac{D_{i}}{\overset{N}{\underset{l=1}{\sum}}D_{l}}%
        \end{array}
        $$

On retrouve les formules de Baum-Welch. Si on note $\left(  M_{t}\right)  $ la suite de mod�les obtenus apr�s chaque it�ration, la d�monstration pr�c�dente (paragraphe~\ref{hmm_demo_gradient_par}) nous assure que la suite $\pr{  O\left| M_{t}\right.  }  $ est croissante, comme elle est major�e par un, elle est convergente. Cependant, la convergence s'effectue vers un maximum local.

\end{xdemo}





















\subsection{Algorithme EM (Expectation-Maximisation)}
\label{hmm_algo_em_sec_new}

\indexfr{EM}

\subsubsection{D�finition}

Dans le cas g�n�ral, l'algorithme permet d'estimer les param�tres d'une loi lorsque certaines donn�es sont manquantes ou cach�es. On consid�re deux variables al�atoires~:

\begin{itemize}
\item $X\in\mathcal{X}\subset \R^p$ de densit� $f\left(  x\left|  \theta\right.  \right)  $ avec $\theta\in\Theta$ ($\Theta$ est l'ensemble des param�tres) 
\item $Z\in\mathcal{Z}\subset\R^{q}$ de densit� $g\left(  z\left|  \theta\right.  \right)  $
\end{itemize}


Les variables $X$, $Z$, $\pa{X,Z}$ sont appel�es :


\begin{itemize}
\item $X$ est la variable observ�e ou incompl�te
\item $Z$ est la variable cach�e ou manquante
\item $\left( X,Z\right) $ est la variable compl�te
\end{itemize}

On note $h\left( x,z\left| \theta\right. \right)  $ la densit� de $\left( X,Z\right)$ et $k\left( z\left| x,\theta\right. \right)  $ la densit� de la variable $E\left(  Z\left|  X\right.  \right)$. D'apr�s la r�gle de Bayes~:

        \begin{eqnarray*}
        && h\left(  x,z\left|  \theta\right.  \right)   = k\left(  z\left| x,\theta\right.  \right)  
        f\left(  x\left|  \theta\right.  \right)\\
        &\Longrightarrow & f\left(  x\left|  \theta\right.  \right)  =\dfrac{h\left( x,z\left| 
                     \theta\right.  \right)  }
        {k\left(  z\left|
            x,\theta\right.    \right)  }\\
        & \Longrightarrow & \ln f\left(  x\left|  \theta\right.  \right)  =\ln h\left( x,z\left| 
                 \theta\right.  \right) 
         -\ln k\left(  z\left|
            x,\theta\right.
            \right) \\
        & \Longrightarrow &\left[  \ln f\left(  x\left|  \theta\right.  \right) \right]  
        k\left(  z\left|  x,\theta\right.  \right)  =\left[  \ln h\left(
            x,z\left|  \theta\right.  \right)  \right]  k\left(  z\left|  x,\theta\right. \right)
              -\left[  \ln k\left(  z\left|  x,\theta\right.  \right)
            \right]k\left(  z\left|  x,\theta\right.  \right) \\
        & \Longrightarrow & \int_{\mathcal{Z}}\left[  \ln f\left(  x\left| \theta\right.  \right) 
             \right]  k\left(  z\left|  x,\theta\right.
            \right) dz=\int_{\mathcal{Z}}\left[  \ln h\left(  x,z\left|  \theta\right. \right)  
            \right]  \,k\left(  z\left|  x,\theta\right.  \right)
            dz - \int _{\mathcal{Z}}\left[  \ln k\left(  z\left|  x,\theta\right.  \right) \right] 
             \,k\left(  z\left|  x,\theta\right.  \right)  dz
        \end{eqnarray*}

On d�finit :

        \begin{eqnarray*}
        Q_{\mathcal{Z}}\left(  \varphi,\theta\right)   &=& E_{\mathcal{Z}}\left[  \ln h\left( 
                 x,z\left|  \varphi\right.  \right)  \,\left|
            \,x,\theta\right. \right]  =\int_{\mathcal{Z}}\left[  \ln h\left(  x,z\left| 
            \varphi\right.  \right)  \right]  \,k\left(  z\left|
            x,\theta\right.\right)  dz\\
        H_{\mathcal{Z}}\left(  \varphi,\theta\right)   &=& E_{\mathcal{Z}}\left[ 
                 \ln h\left(  z\left|  x,\varphi\right.  \right)  \,\left|
            \,x,\theta\right. \right]  =\int_{\mathcal{Z}}\left[  \ln k\left(  z\left| 
             x,\varphi \right.  \right)  \right]  \,k\left(  z\left|
            x,\theta\right.  \right)  dz
        \end{eqnarray*}

D'o� :%

        \begin{eqnarray*}
        &  \Longrightarrow & \ln f\left(  x\left|  \theta\right.  \right)  =
                \underset {=Q_{\mathcal{Z}}\left(  \theta,\theta\right)
            }{\underbrace{E_{\mathcal{Z} }\left[  \ln h\left(  x,z\left|  \theta\right.  \right)  \,\left|
                 \,x,\theta\right.  \right]
            }}-\underset{=H_{\mathcal{Z}}\left(  \theta ,\theta\right)  }{\underbrace{E_{\mathcal{Z}}
                    \left[  \ln h\left(  z\left|
            x,\theta\right.  \right)  \,\left|  \,x,\theta\right.  \right]  }}\\
        &  \Longrightarrow & \ln f\left(  x\left|  \theta\right.  \right) =Q_{\mathcal{Z}}\left(  
                \theta,\theta\right) -H_{\mathcal{Z}}\left(
            \theta,\theta\right)
        \end{eqnarray*}

Or :
        \begin{eqnarray*}
        H_{\mathcal{Z}}\left(  \varphi,\theta\right)  -H_{\mathcal{Z}}\left( \theta,\theta\right)
              =\int_{\mathcal{Z}}\left[  \ln\dfrac{k\left(
        z\left|  x,\varphi\right.  \right)  }{k\left(  z\left|  x,\theta\right. \right)  }\right]
              k\left(  z\left|  x,\theta\right.  \right)  dz
        \end{eqnarray*}




            \begin{xtheorem}{In�galit� de Jensen}
            \label{theoreme_inegalite_jensen_1}%
            \indexfr{Jensen}%
            Soit $X\in\mathcal{X}$ une variable al�atoire de densit� $f$, soit $g:\mathcal{X}\longrightarrow\R$ 
            une fonction convexe alors~:
            
                    $$
                    E\left(  g\left(  X\right)  \right)  =\int _{\mathcal{X}}g\left(  x\right)  
                                f\left(  x\right)  dx\leqslant g\left(
                    \int_{\mathcal{X}}f\left(  x\right)  dx\right)  =g\left(  E\left( X\right)  \right)
                    $$
                    
            \end{xtheorem}

D'apr�s l'in�galit� de Jensen, on d�duit que, puisque la fonction $t\rightarrow-\ln t$ est convexe~:

        $$
        H_{\mathcal{Z}}\left(  \varphi,\theta\right)  -H_{\mathcal{Z}}
                    \left( \theta,\theta\right)  \leqslant\ln\int_{\mathcal{Z}}\left[
        \dfrac{k\left(  z\left|  x,\varphi\right.  \right)  }{k\left(  z\left| x,\theta\right.  \right)  }\right] 
         k\left(  z\left|  x,\theta\right.
        \right)  dz=\ln\int_{\mathcal{Z}}k\left(  z\left|  x,\varphi\right. \right)  dz=\ln1=0
        $$

Par cons�quent~:

        \begin{eqnarray}
        \forall\varphi\in\Theta,\; H_{\mathcal{Z}}\left(  \theta,\theta\right) \geqslant H_{\mathcal{Z}}\left(
        \varphi,\theta\right) \label{hmm_eq_em_jensen}
        \end{eqnarray}

De plus~:

        \begin{eqnarray}
        && \text{soit } \varphi\in\Theta \text { tel que } Q_{\mathcal{Z} }\left(  \varphi,\theta\right)  
                        \geqslant Q_{\mathcal{Z}}\left(  \theta ,\theta\right)
                        \nonumber\\
        & \Longrightarrow & E_{\mathcal{Z}}\left[  \ln h\left(  x,z\left|  \varphi \right.  \right)  \,\left| 
                 \,x,\theta\right.  \right]  -E_{\mathcal{Z}
            }\left[  \ln h\left(  z\left|  x,\varphi\right.  \right)  \,\left| \,x,\theta\right.  \right]  \geqslant
                 E_{\mathcal{Z}}\left[  \ln h\left(
            x,z\left|  \theta\right.  \right)  \,\left|  \,x,\theta\right.  \right] -E_{\mathcal{Z}}\left[  \ln h\left(  
                z\left|  x,\theta\right.  \right)
            \,\left|  \,x,\theta\right.  \right] \nonumber \\
        & \Longrightarrow & \ln f\left(  x\left|  \varphi\right.  \right)  \geqslant\ln f\left(  x\left|  \theta\right.  
                \right) \label{hmm_eq_em_jensen_2}
        \end{eqnarray}


L'algorithme~EM a pour objectif de trouver $\theta^{\ast}\in\Theta$ qui maximise $\ln f\left(  x\left|  \theta\right.  \right)  $, il est inspir� de ce qui pr�c�de~:

            \begin{xalgorithm}{EM}
            \label{algorithme_EM}
            \indexfr{EM}
            Les notations adopt�es sont celles des paragraphes qui pr�c�dent. L'objectif de cet algorithme est de trouver 
            les param�tres $\theta$ qui maximisent la densit� $f\pa{x \sac \theta}$~:
            
            \begin{xalgostep}{initialisation}
                    On choisit $\theta_{0}\in\Theta$ de mani�re al�atoire.
            \end{xalgostep}
            
            \begin{xalgostep}{expectation "E"}\label{hmm_em_step_e}
                    Pour $\theta_{t}$, on calcule $Q_{\mathcal{Z}}\left(  \varphi,\theta _{t}\right)  =
                    \displaystyle\int_{\mathcal{Z}}\left[  \ln h\left(  x,z\left|
                    \varphi\right.  \right)  \right]  \,k\left(  z\left|  x,\theta_t\right.  \right) dz$.
            \end{xalgostep}
            
            \begin{xalgostep}{maximisation "M"}
                    On obtient $\theta_{t+1}=\underset{\varphi\in\Theta}{\arg\max }\;
                             Q_{\mathcal{Z}}\left(  \varphi,\theta_{t}\right)$.
            \end{xalgostep}
            
            \begin{xalgostep}{terminaison}
                    On retourne � l'�tape~\ref{hmm_em_step_e} jusqu'� ce que la suite 
                    $\left(  \ln f\left(  x\left| \theta_{t}\right. \right)\right)  _{t}$ converge.
            \end{xalgostep}
            
            \end{xalgorithm}
            
            
        \begin{xtheorem}{convergence de l'algorithme EM}\label{hmm_theorem_em}
        \indexfr{EM}
        
        La suite $\left(  \ln f\left(  x\left| \theta_{t}\right. \right)\right)  _{t}$ construite par l'algorthime 
        EM (\ref{algorithme_EM})
        converge vers un minimum local de la fonction $\theta \longrightarrow f\pa{x \sac \theta}$.
        \end{xtheorem}
        
        
\begin{xdemo}{th�or�me}{\ref{hmm_theorem_em}}
Le th�or�me est d�montr�e par l'�quation (\ref{hmm_eq_em_jensen_2}), la suite $\left(  \ln f\left(  x\left| \theta_{t}\right. \right)\right)  _{t}$ est croissante et born�e, donc elle converge.
\end{xdemo}
        
        
        
        
        



\subsubsection{Exemple : la taille d'un poisson selon le sexe}
\indexfrr{exemple}{algorithme EM}
\indexfr{poisson}


Soit $X$ une variable al�atoire repr�sentant la taille d'un poisson d'une esp�ce donn�e � l'�ge adulte. La taille d�pend fortement du sexe du poisson. Soit $Z\in\left\{  0,1\right\}  $ le sexe du poisson, $X$ est la variable observ�e, $Z$ la variable manquante. On suppose que, connaissant le sexe du poisson, sa taille suit une loi normale de param�tre $\left(  \mu_{i},\sigma_{i}\right)  _{i\in\left\{ 0,1\right\} }$. Le sexe du poisson suit une loi binomiale de param�tre $p$.

Dans ce cas, $\theta=\left(  p,\mu_{0},\sigma_{0},\mu_{1},\sigma_{1}\right)$, la densit� de $X|Z$ est :%

        $$
        l\left(  x\left|  z,\theta\right.  \right)   = \dfrac{1}{\sigma_z\sqrt{2\pi} }
        e^{-\dfrac{\left(  x-\mu_{z}\right)  ^{2}}{2\sigma_{z}^{2}}}
        $$
        
et la densit� de $Z|\theta$ est~:

        $$
        \pr{Z=z\left|  \theta\right.  }   = p\,\mathbf{1}_{\left\{z=0\right\}  }+\left(  1-p\right)
        \,\mathbf{1}_{\left\{  z=1\right\}  }
        $$

D'apr�s les hypoth�ses, on en d�duit que :%

        \begin{eqnarray*}
        h\left(  x,z\left|  \theta\right.  \right)   &=& \indicatrice{z=0} \left[  \dfrac{p}{\sigma_0
                 \sqrt{2\pi}}e^{-\dfrac{\left( x-\mu
            _{0}\right)  ^{2}}{2\sigma_{0}^{2}}}\right]  + \indicatrice{z=1} \left[ 
                 \dfrac{\left(  1-p\right)  }{\sigma_1
             \sqrt{2\pi}}e^{-\dfrac
            {\left(  x-\mu_{1}\right)  ^{2}}{2\sigma_{1}^{2}}}\right] \\
        \ln h\left(  x,z\left|  \theta\right.  \right)   &=& \indicatrice{z=0}\left[ 
                 \ln\dfrac{p}{\sigma_0 \sqrt{2\pi}}-\dfrac{\left(
         x-\mu
            _{0}\right)  ^{2}}{2\sigma_{0}^{2}}\right]  +\indicatrice{z=1}\left[ 
                     \ln\dfrac{\left(  1-p\right)  }{\sigma_1
             \sqrt{2\pi}}-\dfrac{\left(
            x-\mu _{1}\right)  ^{2}}{2\sigma_{1}^{2}}\right] \\
        f\left(  x\left|  \theta\right.  \right)   &=& \dfrac{p}{\sigma_0 \sqrt{2\pi} }
                e^{-\dfrac{\left(  x-\mu_{0}\right)
            ^{2}}{2\sigma_{0}^{2}}}+\dfrac{\left(1-p\right)  }{\sigma_1 \sqrt{2\pi}}
                    e^{-\dfrac{\left(  x-\mu_{1}\right)  ^{2}}
             {2\sigma_{1}^{2}}}\\
        \pr{  Z=z\left|  x,\theta\right.  }   &=& k\left(  z\left| x,\theta\right. 
                 \right)  =\dfrac{h\left(  x,z\left| 
         \theta\right.  \right)
            }{f\left(  x\left|  \theta\right.  \right)  }
        \end{eqnarray*}

L'objectif est de trouver les v�ritables valeurs de $\left(  p,\mu _{0},\sigma_{0},\mu_{1},\sigma_{1}\right)  $ � partir d'une liste d'observation $\left(  x_{1},...,x_{n}\right)  $ donc de trouver :

        $$
        \theta^{\ast}=\underset{\theta}{\arg\max}\underset{i=1}{\overset{n}{\prod}
        }f\left(  x_{i}\left|  \theta\right.  \right)  =\underset{\theta}{\arg\max
                 }\underset{i=1}{\overset{n}{\sum}}\ln f\left( 
         x_{i}\left|
        \theta\right. \right)
        $$

Ce probl�me n'est pas soluble par maximum de vraisemblance. En effet, maximiser la vraisemblance du mod�le aboutit � la r�solution d'un syst�me d'�quations � cinq inconnues insoluble. L'algorithme EM est une alternative, dans ce cas~:

        \begin{eqnarray*}
        Q_{\mathcal{Z}}\left(  \theta,\theta_{t}\right)   &=& \overset {n}{\underset{i=1}{\sum}}\overset{1}
        {\underset{z=0}{\sum}}\left[  \ln h\left(
            x_{i},z\left|  \theta\right.  \right)  \right]  \,k\left(  z\left|x,\theta_{t}\right.  \right)\\
        Q_{\mathcal{Z}}\left(  \theta,\theta_{t}\right)   &=& \overset {n}{\underset{i=1}{\sum}}
                \left[  \ln\dfrac{p}{\sigma_0 \sqrt{2\pi}} - \dfrac{\left(  x_{i}-\mu_{0}\right) ^{2}}
                {2\sigma_{0}^{2}}\right] k\pa{0 |x_i,\theta_t}
            +   \left[  \ln\dfrac{\left(  1-p\right) }{\sigma_1 \sqrt{2\pi}}-\dfrac{\left(  x_i-\mu_{1}\right) ^{2}}
                    {2\sigma_{1}^{2} }\right] k\pa{1 |x_i,\theta_t}
        \end{eqnarray*}

Trouver $\theta_{t+1}=\underset{\theta}{\arg\max}Q_{\mathcal{Z}}\left( \theta,\theta_{t}\right)  $ est un probl�me plus simple que le pr�c�dent et soluble car cette fois, le syst�me d'�quation � cinq inconnues obtenu est soluble. Cet exemple est un cas particulier des m�langes de lois normales.

\indexfr{EM}\indexfr{SEM}\indexfr{SAEM}
\indexfr{stochastique}

Les formules de Baum-Welch sont un cas particulier de cet algorithme dont la d�courverte est post�rieure. L'algorithme EM est aussi d�clin� dans plusieurs variantes SEM, SAEM, CEM, ... (voir \citeindex{Celeux1985}, \citeindex{Celeux1995}). En particulier, comme pour les r�seaux de neurones\seeannex{rn_section_train_rn}{r�seau de neurones}, il existe une version stochastique de l'algorithme EM not�e SEM.










\subsection{D�monstration des formules de Baum-Welch avec l'algorithme EM}

\begin{xdemo}{th�or�me}{\ref{theoreme_hmm_baum_welch_1}}

Les formules de Baum-Welch (voir table~\ref{figure_formule_baumwelch-fig}, page~\pageref{figure_formule_baumwelch-fig}) se d�duisent de l'algorithme EM (algorithme ~\ref{algorithme_EM}). Soit $M\pa{\phi}$ un mod�le de Markov cach� dont les param�tres sont le vecteur $\phi = \pa{A_\phi, B_\phi, \pi_\phi, \theta_\phi}$. Soit $O=\vecteur{O_1}{O_K}$ $K$ s�quences d'observations avec $\forall k \in \intervalle{1}{K}, \; O^k = \vecteur{O_1^k}{O_{T_k}^k}$, $s = \vecteur{q_1}{q_T}$ est une s�quence d'�tats cach�s. Les densit�s $h$, $k$, $f$ de l'algorithme EM correspondent �~:

        \begin{eqnarray*}
        h\pa{O,s | M\pa{\phi}} &=& \prody{k=1}{K} \pr{\vecteurno{O_1^k}{O_{T_k}^k},
                    \vecteurno{q_1}{q_{T_k}} | M\pa{\phi}} \\
         &=& \prody{k=1}{K}  \pi_{\phi,q_1} b_{\phi,q_1}\pa{O_1} \crochet { \prody{t=2}{T_k} 
                     a_{\phi,q_{t-1} q_t} b_{\phi,q_t} \pa{O_t}
          } \theta_{\phi,q_{T_k}} \\
        f\pa{O | M\pa{\phi}} &=& \summyone{s} h\pa{O,s | M\pa{\phi}} \\
        k\pa{s | O,M\pa{\phi}} &=& \dfrac{ h\pa{O,s | M\pa{\phi}} } {f\pa{O | M\pa{\phi}}}
        \end{eqnarray*}

On note $\mathcal{S}$ l'ensemble des s�quences d'�tats cach�s, alors :

        \begin{eqnarray}
        Q_{\mathcal{S}} \pa{\psi, \phi} &=& \summyone{s \in \mathcal{S}} \ln h\pa{O,s | M\pa{\psi}} 
                        k\pa{s | O,M\pa{\phi}} \\
        &=& \summyone{s \in \mathcal{S}} k\pa{s | O,M\pa{\phi}}
                    \summy{k=1}{K}  \crochet{
                        \begin{array}{cl}
                              &  \ln \pi_{\psi,q_1} + \ln b_{\psi,q_1}\pa{O_1} \\
                            + &  \summy{t=2}{T_k} \ln a_{\psi,q_{t-1} q_t} + \ln b_{\psi,q_t} \pa{O_t} \\
                            + &  \ln \theta_{\psi,q_{T_k}}
                        \end{array} } \label{hmm_em_demo_un}
        \end{eqnarray}

$\Theta$ est l'ensemble des param�tres $\phi = \pa{A_\phi, B_\phi, \pi_\phi, \theta_\phi}$ v�rifiant les contraintes inh�rentes aux cha�nes de Markov cach�es. L'objectif est de trouver :

        $$
        \psi^* = \underset{\psi \in \Theta} {\arg \max} \; Q_{\mathcal{S}} \pa{\psi, \phi}
        $$

Pour cela, on �crit diff�remment l'�quation (\ref{hmm_em_demo_un}) :

        \begin{eqnarray}
        Q_{\mathcal{S}} \pa{\psi, \phi} = \summy{n=1}{N} C_{n}\ln \pi_{\psi,n} + \summy{n=1}{N}\summy{m=1}{N} A_{nm} 
            \ln a_{\psi,nm}+ \summy{n=1}{N}
        \summyone{o} B_{n,o} \ln b_{\psi,n} \pa{o} + \summy{n=1}{N} D_{n} \ln\theta_{\psi,n}
        \end{eqnarray}

Les matrices $C_{n}, A_{nm}, B_{n,o}, D_{n}$ ont les valeurs donn�es par les �quations (\ref{hmm_em_demo_eq_un}) � (\ref{hmm_em_demo_eq_quatre}) (page~\pageref{hmm_em_demo_eq_un}).


\end{xdemo}












\subsection{Am�lioration de l'apprentissage}

\indexfrr{coefficients}{nuls}%
\indexfr{recuit simul�}%
\indexfr{apprentissage}%
\label{hmm_apprentissage_ameliore}%

Les formules de Baum-Welch (voir table~\ref{figure_formule_baumwelch-fig}) impliquent que si un coefficient devient nul apr�s un certain nombre d'it�rations, il le restera aux it�rations suivantes. Cela ne signifie pas que la valeur optimale pour ce coefficient soit diff�rente de z�ro, cependant si ce n'est pas le cas, l'apprentissage est biais�. C'est pourquoi on pr�f�re que tous les coefficients soient non nuls. 

Afin d'�viter cet �cueil, les coefficients inf�rieurs � un certain seuil sont modifi�s al�atoirement de sorte qu'ils soient sup�rieurs � ce seuil, ce seuil $s_t$ d�cro�t avec le nombre d'it�rations~$t$~:

            $$
            s_t = \frac{s_0}{ 1 + \gamma t } \text{ avec } \gamma \in \R^+
            $$

La vraisemblance des mod�les obtenue lors des it�rations successives d�cro�t globalement mais l'al�atoire introduit entre chaque it�ration fait osciller la valeur de cette vraisemblance lorsque les coefficients sont proches d'un optimum local. Cette oscillation d�cro�t au fur et � mesure que $s_t$ d�cro�t.















%----------------------------------------------------------------------------------------------------------------------
\section{Observations continues et r�seau de neurones} \label{hmm_sec_rn_obs_cont}
%----------------------------------------------------------------------------------------------------------------------

\indexfrr{observations}{continues}%
\indexfrr{�missions}{continues}%

Jusqu'� pr�sent, les observations �taient discr�tes~: les s�quences d'observations �taient des s�quences d'entiers pris dans un ensemble fini. Lorsque les donn�es observ�es sont continues, il est possible de se ramener � ce cas-l� en construisant une partition de l'espace (avec l'algorithme des centres mobiles par exemple, voir paragraphe~\ref{emission_continue_centre_mobile}). N�anmoins, une classification traite de mani�re insatisfaisante les ambigu�t�s : les observations situ�es sur une fronti�re entre deux classes (voir figure~\ref{figure_partitionnement_ambigu-fig}). Il est alors pr�f�rable de conserver des probabilit�s d'appartenir � telle ou telle classe (voir paragraphe~\ref{hmm_classification_obs_trois}).

        \begin{figure}[ht]
    $$\frame{$\begin{array}[c|c]{c}\includegraphics[height=4cm, width=5cm] 
    {\filext{../dessin2/hmm_rn_ambigu}}\end{array}$}$$
    \caption{Ambigu�t�s d'un partitionnenement d'un espace continu.}
    \label{figure_partitionnement_ambigu-fig}
        \end{figure}







\subsection{Cha�ne de Markov cach�e incluant un r�seau de neurones}
\label{hmm_reseau_neurone}
\indexfr{MMC}
\indexfr{r�seau de neurones}

Les cha�nes de Markov cach�es incluant un r�seau de neurones sont qualifi�es de \emph{hybrides},\indexfrr{MMC}{hybride} les �missions sont en quelque sorte sous-trait�es par la cha�ne de Markov � un r�seau de neurones.

\indexfrr{MMC}{r�seau de neurones}%

\subsubsection{Initialisation}

On suppose que l'espace des observations continues a �t� partitionn� � l'aide des m�thodes pr�sent�es dans les paragraphes~\ref{hmm_classification_obs_un}, \ref{hmm_classification_obs_deux}, \ref{hmm_classification_obs_trois} (pages~\pageref{hmm_classification_obs_un} et suivantes), on dispose donc pour chaque observation $x$ des probabilit�s $\pr{  c\left| x\right.}$, elles sont retourn�es par un r�seau de neurones classifieur (voir paragraphe~\ref{classification}, page~\pageref{classification}) dont l'apprentissage est �voqu� au paragraphe~\ref{hmm_classification_obs_trois}.



\subsubsection{Des observations discr�tes aux observations continues}
\label{hmm_definition_observation_continue}

Jusqu'� pr�sent, les mod�les d'�missions ont toujours �t� discrets, les mod�les de Markov retournaient la probabilit�s de s�quences discr�tes. Les mod�les d'�missions discretes sont enti�rement d�crits par une matrice :

        $$
        \begin{array}{l}
        \left(  b_{i,o}\right)_{\substack{1\leqslant i\leqslant N\\1\leqslant o\leqslant O}}=
                \left(  \pr{ o\left|  i\right.  }  \right)
            _{\substack{1\leqslant i\leqslant N\\1\leqslant o\leqslant O}}\\ \\
        \text{avec }        \left |
                            \begin{array}{l}
                            N \text{ est le nombre d'�tats de la cha�ne de Markov} \\
                            O \text{ le nombre d'observations possibles} \\
                            \pr{  o\left|  i\right.  } \text{ est la probabilit� d'�mettre l'observation } o 
                                    \text{ connaissant l'�tat } i
                            \end{array}
                            \right.
        \end{array}
        $$

Comme les observations sont continues, il faut construire un mod�le d'�mission estimant la densit� d'une observation continue $x$ sachant l'�tat~$i$~: $f\left(  x\left| i\right. \right)$. On note $x\longrightarrow Rn\left(  x\right)  =\left(  \pr{ c\left|  x\right. }  \right) _{1\leqslant c\leqslant C}$ la fonction d�finie par le r�seau de neurones appris gr�ce � la classification (voir paragraphe~\ref{hmm_classification_obs_trois}).






            \begin{xdefinition}{Cha�ne de Markov cach�e hybride}
            \label{definition_mmc_1}
            \indexfr{hybride}
            
            Une cha�ne de Markov cach�e hybride dont les observations sont continues v�rifie les conditions 2 � 4 v�rifi�es 
            par une cha�ne de Markov cach�e dont les observations sont discr�tes 
            (voir d�finition~\ref{markov_chaine_cachee_definition},
             page~\pageref{markov_chaine_cachee_definition}), et les conditions 1 � 3 qui suivent~:
            
            \begin{enumerate}
            \item La densit� d'une observation ne d�pend que de sa classe : $f\left(  x\left|  c,i\right.  \right)  =
                        f\left( x\left| c\right.  \right)$
            \item La probabilit� que l'observation � l'instant $t$ soit dans la classe $c$ ne d�pend que 
                            de l'�tat � l'instant $t$ :
            
                $$
                \pr{  O_{t}\in classe\left(  c\right)  \,\left|  \,q_{1},...,q_{t},O_{1},...,O_{t-1}\right.  } 
                             = \pr{   O_{t}\in classe\left( c\right)
                \left|  q_{t}\right.  }  = \pr{  c\left| q_{t}\right. }
                $$
                
            \item La probabilit� que l'observation � l'instant $t$ soit dans la classe $c$ ne d�pend pas du temps :
            
                $$
                \forall t_{1},t_{2},\,\forall i,c,\; \pr{   O_{t_1}\in classe\left( c\right)  \left|  q_{t_{1}}=i\right.  
                        }  = \pr{   O_{t_2}\in
                classe\left(  c\right)  \left|  q_{t_{2}}=i\right. }
                $$
            \end{enumerate}%
            \end{xdefinition}
            

\indexfr{densit�}%


        \begin{xproperty}{probabilit� d'�mission}
        On en d�duit que la densit� $f\pa{x|i}$ d'une observation $x$ sachant l'�tat $i$ est~:
        
                $$
                f\left(  x\left|  i\right.  \right)  =\underset{c=1}{\overset{C}{\sum} }f\left(  x,c\left|  i\right.  
                        \right)  =\underset{c=1}{\overset{C}{\sum}
                }f\left(  x\left|  c,i\right.  \right)  \pr{   c\left|  i\right. } =\underset{c=1}{\overset{C}
                        {\sum}}\dfrac{ \pr{   c\left|  x\right.
                } \pr{  c\left|  i\right.  }  f\left(  x\right)  }{ \pr{   c}  }
                $$
        
        o�~:
        
                \begin{eqnarray*}
                \pr{  c\left|  x\right.  }  && \text{est estim� par le r�seau de neurones : }
                            \pr{   c\left|  x\right.  }  =Rn\left(  x\right)\\
                \pr{  c\left|  i\right.  }  && \text{est un coefficient qui sera estim� de la m�me mani�re que 
                                les probabilit�s de transition}\\
                f\left(  x\right) && \text{est la densit� des observations, elle est inconnue mais peut �tre estim�e par
                                 (\ref{hmm_rn_densite_x})}\\
                \pr{  c } && \text{est la probabilit� de la classe $c$, elle est incoonue mais peut �tre estim�e par
                             (\ref{hmm_rn_densite_p})}
                \end{eqnarray*}
        \end{xproperty}

On note $\pr{c|i}_{i,c} = \pa{c_{i,c}}_{i,c}$ la matrice des probabilit�s �missions dans le cas d'observations continues.






\subsection{R�estimation de $\pa{c_{i,c}}_{i,c}$}

On d�finit de nouveaux coefficients pour le mod�le de Markov cach� :

        $$
        \pa{c_{ci}}_{\begin{subarray}{c} 1 \infegal i \infegal N \\ 1 \infegal c \infegal C \end{subarray}} =%
        \pa{\pr{c|i}}_{\begin{subarray}{c} 1 \infegal i \infegal N \\ 1 \infegal c \infegal C \end{subarray}}
        $$
        

\label{hmm_reestimation_emission_rn}%
\indexfr{Baum-Welch}%

De la m�me mani�re que pour les formules de Baum-Welch, on cherche � estimer $\pr{  c,i,O}  $ o� $O$ est une s�quence
d'observations. $C_{t}$ d�signe la classe de l'observation $O_{t}$.%

        $$
        \pr{  c\left|  i\right.  }  =\overline{c_{i,c}}=\dfrac{\underset {k=1}{\overset{K}
                { {\displaystyle\sum} }}\dfrac{1}{P_{k}}
        \underset{t=1}{\overset{T_{k}}{ {\displaystyle\sum}}} \pr{   C_{t}=c, \, q_{t}=i,O^{k}}  }
                {\underset{k=1}{\overset{K}{ {\displaystyle\sum}
        }}\dfrac{1}{P_{k}}\underset{t=1}{\overset{T_{k}}{ {\displaystyle\sum}}} \pr{  q_{t}=i, \, O^{k}}  }
        $$

La d�monstration de la formule de r�estimation de $c_{i,c}$ pour un mod�le apprenant la s�quence d'observations $\vecteur{O_1}{O_T}$~:

        \begin{eqnarray}
        \pr{  C_{t},q_{t},O }  &=&  \pr{  O_{t+1},..,O_{T}\left| 
                 C_{t},q_{t},O_{1},...,O_{t}\right.  } \pr{    C_{t},q_{t},O_{1}
            ,...,O_{t}} \nonumber\\
        \pr{   C_{t},q_{t},O}  &=& \pr{  O_{t+1},..,O_{T}\left|q_{t}\right.  }
                    \pr{  O_{t}\left|  C_{t},q_{t},O_{1},...,O_{t-1}
            \right. }  \pr{  C_{t},q_{t},O_{1},...,O_{t-1}} \nonumber\\
        \pr{  C_{t},q_{t},O}  &=& \beta_{q_{t}}\left(  t\right)  \pr{O_{t}\left|  C_{t}\right.  }
                 \pr{  C_{t}\left|  q_{t},O_{1}
            ,...,O_{t-1}\right.  }  \pr{ q_{t},O_{1},...,O_{t-1}} \nonumber\\
        \pr{  C_{t},q_{t},O}  &=& \beta_{q_{t}}\left(  t\right)  \pr{ O_{t}\left|  C_{t}\right. }
                  \pr{  C_{t}\left|  q_{t}\right.
            }  \underset{q_{t-1}}{\overset{}{\sum}} \pr{ q_{t},q_{t-1} ,O_{1},...,O_{t-1}} \nonumber\\
        \pr{  C_{t},q_{t},O}  &=& \beta_{q_{t}}\left(  t\right)  \pr{ O_{t}\left|  C_{t}\right.  }
                 \,c_{q_{t},C_{t}}\underset{q_{t-1}
            }{\overset{}{\sum}}a_{q_{t-1},q_{t}}\,\alpha_{q_{t-1}}\left(  t\right) =\dfrac{\beta_{q_{t}}\left(  t\right)
                      \pr{ O_{t}\left|  C_{t}\right.
            }  \,c_{q_{t},C_{t}}\,\alpha_{q_{t}}\left(  t\right)  }{b_{q_{t}}\left( O_{t}\right)  } \nonumber\\
        \pr{  C_{t},q_{t},O}  &=& \dfrac{\beta_{q_{t}}\left(  t\right) \pr{  O_{t}\left|  C_{t}\right.
                 }\,c_{q_{t},C_{t}} \,
            \alpha_{q_{t}} \left(  t\right)  }{\underset{d=1}{\overset{N}{{\displaystyle\sum}}}
                    \pr{  O_{t}\left|  C_{t}=d\right.}
            \,c_{q_{t},d}} \label{hmm_equation_reestimation}\\
        \text{Rappel :} \pr{  q_{t},O}  &=& \alpha_{q_{t}}\left(  t\right)  \beta_{q_{t} }\left(  t\right) \nonumber
        \end{eqnarray}

Si le mod�le apprend plusieurs s�quences $\vecteur{O^1}{O^K}$ de longueurs respectives $\vecteur{T_1}{T_K}$, alors la formule de la table~\ref{figure_formule_baumwelch-fig_2} vient s'ajouter � celles de la table~\ref{figure_formule_baumwelch-fig}.%

                \begin{table}[t]
                \[
                \fbox{$\begin{array}[c]{c}%
                \overline{c_{i,c}}= \pr{  c\left|  i,O\right.  }  =\dfrac{\underset{k=1}
                        {\overset{K}{ {\displaystyle\sum} }}\dfrac{1}{P_{k}}
                \underset{t=1}{\overset{T_{k}}{ {\displaystyle\sum} }}\dfrac{\beta_{i}^{k}
                        \left(  t\right)  \pr{  O_{t}^k\left|  c\right. }
                c_{i,c}\alpha_{i}^{k}\left(  t\right)  }{\underset{d=1}{\overset {N}{\sum}}
                        \pr{ O_{t}^k\left|  c\right.  }  c_{i,d}}}{\underset
                {k=1}{\overset{K}{ {\displaystyle\sum} }}\dfrac{1}{P_{k}}\underset{t=1}
                        {\overset{T_{k}}{ {\displaystyle\sum} }}\alpha_{i}^{k} \left(  t\right)
                \beta_{i}^{k}\left(  t\right)  }\end{array}$}
                \]
                \caption{Formules de r�estimation de Baum-Welch, mod�le hybride}
                \label{figure_formule_baumwelch-fig_2}
                \indexfr{Baum-Welch}
                \indexfr{r�estimation}
                \indexfr{hybride}
                \end{table}






\subsection{R�estimation des $\pr{c |o }$}

\indexfrr{MMC}{annotation RN par MMC}%
\label{hmm_reestimation_rn_classification}%
\indexfr{r�estimation}

Ces probabilit�s sont fournies par le r�seau de neurones dont l'apprentissage peut �tre mis en parall�le avec celui du mod�le de Markov cach� ou �tre diff�r�. Dans cette seconde solution, il faut estimer les probabilit�s $\left( \pr{ c\left| x\right. } \right) _{1\leqslant c\leqslant C}$ qui diminueront la vraisemblance des observations. De la m�me mani�re que pr�c�demment, on estime la probabilit� $\pr{C_{t}\left| O_{t}^{k}\right. }  $ pour la s�quence $O^{k}$. 

$C_{t}$ d�signe toujours la classe de l'observation $O_{t}$, la d�monstration des formules sera faite pour une s�quence, pour abr�ger les notations, $O=O^{k}$~:

        \begin{eqnarray*}
        \pr{C_t|O_t} &=& \pr{C_t|O} = \frac{\pr{C_t,O}}{\pr{O}} = \frac{1}{\pr{O}} \summyone{q_t} \pr{C_t,q_t,O}\\
        &=& \frac{1}{\pr{O}} \summyone{q_t} \dfrac{\beta_{q_{t}}\left(  t\right) \pr{ O_{t}\left|  
                    C_{t}\right. }\,c_{q_{t},C_{t}} \,
            \alpha_{q_{t}} \left(  t\right)  }{\underset{d=1}{\overset{N}{{\displaystyle\sum}}}\pr{ O_{t}\left| 
                     C_{t}=d\right. }
            \,c_{q_{t},d}} \quad \text{ d'apr�s (\ref{hmm_equation_reestimation})}
        \end{eqnarray*}

Par cons�quent, dans un premier temps, la base d'apprentissage du r�seau de neurones est la base $\left(  X,Y\right)  $ d�finies par la table~\ref{figure_formule_baumwelch-fig_3}.%

                \begin{table}[t]
                \[
                \fbox{$%
                \begin{array}{l}%
                i {{}^\circ} \text{ ligne de }X\text{ : }X_{i}=O_{t}^k\\
                k {{}^\circ} \text{ ligne de }Y\text{ : }Y_{k}=\left(  \dfrac{1}{\pr{O^k}
                                } \bigsummyone{q_t} \dfrac{\beta_{q_{t}^k}\left(  t\right) \pr{
                    O_{t}^k\left| c\right. }\,c_{q_{t},c} \, \alpha_{q_{t}^k} \left(  t\right) 
                             }{\underset{d=1}{\overset{C}{{\displaystyle\sum}}} \pr{ 
                    O_{t}^k\left|  d\right. } \,c_{q_{t},d}}
                    \right)  _{1\leqslant c\leqslant C} %
                \end{array}
                $}%
                \]
                \caption{Formules de r�estimation de Baum-Welch, mod�le hybride, partie r�seau de neurones.
                                 On passe d'une ligne � la suivante en incr�mentant~$t$ ou lorsque~$t$ correspond
                                 � la derni�re observations de la s�quence~$O^k$, en incr�mentant~$k$. Les 
                                 matrices $X$ et $Y$ constituent la base d'apprentissage du r�seau de neurones, $X$ 
                                 contient les entr�es, $Y$ les sorties d�sir�es.    }
                \label{figure_formule_baumwelch-fig_3}
                \indexfr{Baum-Welch}
                \indexfr{r�estimation}
                \indexfr{hybride}
                \indexfr{r�seau de neurones}
                \end{table}

Toutefois la formule d�crite dans cette table~\ref{figure_formule_baumwelch-fig_3} ne donne pas le vecteur de probabilit� $Y$ qui maximise la vraisemblance des observations mais celui-ci peut �tre obtenu en adaptant l'algorithme EM\indexfr{EM} � ce cas-l�. On note $Y_{ct} = \pr{ O_j \sac C_c }$. $O_t$ d�signe la $t^\text{�me}$ observations de la s�quence $O = \vecteur{O_1}{O_T}$ et $C_i$ la $c^\text{�me}$ classe. Par cons�quent $Y_{tc}$ est la sortie $c^\text{�me}$ d�sir�e du r�seau de neurones lorsqu'il a pour entr�e le vecteur $O_t$. Comme les coefficients $c_{i,c}$ (voir table~\ref{figure_formule_baumwelch-fig_2}), les nombres $Y_{tc}$ sont mis � jour selon la formules de la table~\ref{figure_formule_baumwelch-fig_3prime}. 


                \begin{table}[t]
                $$\begin{array}{|l|}\hline
                \overline{Y_{tc}^k} = \dfrac{1}{ \pr{O^k} } \pa { 
                                    \summyone{q_t} \; 
                                            \dfrac{  \beta_{q_t}^k\pa{t} \, Y_{tc}^k  \, c_{q_t,c} \, \alpha_{q_t}^k \pa{t} }
                                                    {  \summy{d=1}{C} \, Y_{td}^k  \,  c_{q_t,d} }
                                                    }
                \\ \hline
                \end{array}$$
                \caption{    Formules de r�estimation de Baum-Welch, mod�le hybride, partie r�seau de neurones.
                                    Cette formule de r�estimation vient en compl�ment de la
                                    table~\ref{figure_formule_baumwelch-fig_3} o� le terme $Y_i$ est remplac� par le 
                                    vecteur $\vecteur{ \overline{Y_{t1}^k} }{ \overline{Y_{tC}^k} } $ obtenu apr�s convergence
                                    de la probabilit� $\pr{ O_t \sac M}$ et en utilisant la formule 
                                    de r�estimation ci-dessus. La premi�re valeur pour $Y_{tC}^k$ correspond � la sortie
                                    du r�seau de neurones avant r�apprentissage. }
                \label{figure_formule_baumwelch-fig_3prime}
                \indexfr{Baum-Welch}
                \indexfr{r�estimation}
                \indexfr{hybride}
                \indexfr{r�seau de neurones}
                \end{table}

Il faut d'ajouter que l'utilisation de telles formules de convergence m�nent souvent � des sorties d�sir�es pour le r�seau de neurones qui sont soient nulles, soient �gales � un. La remarque~\ref{nn_remark_classification_output_alpha}\seeannex{nn_remark_classification_output_alpha}{r�seau de neurones} sugg�re de ne pas utiliser ces sorties telles quelles afin de faciliter l'apprentissage.


            \begin{xalgorithm}{apprentissage altern� du mod�le hybride complet}
            \label{algorithme_apprentissge_modelel_complet_1}%
            \indexfrr{apprentissage}{MMC + RN}%
            \indexfr{r�seau de neurones}
            L'apprentissage propos� alterne l'apprentissage de la cha�ne de Markov cach�e de celui du r�seau de neurones, 
            il est constitu� de trois �tapes~:
            
            \begin{xalgostep}{initialisation}
                    Initialisation du r�seau de neurones � l'aide des m�thodes propos�es dans les paragraphes :
                            \ref{hmm_classification_obs_un}         (page~\pageref{hmm_classification_obs_un}),
                            \ref{hmm_classification_obs_deux}       (page~\pageref{hmm_classification_obs_deux}),
                            \ref{hmm_classification_obs_trois}      (page~\pageref{hmm_classification_obs_trois})
            \end{xalgostep}
            
            \begin{xalgostep}{apprentissage MMC}\label{hmm_rn_step_algo_mmc}
                    Apprentissage Baum-Welch des probabilit�s de transitions et d'�missions, voir les paragraphes~:
                            \ref{formule_baumwelch}                 (page~\pageref{formule_baumwelch}),
                            \ref{hmm_reestimation_emission_rn}      (page~\pageref{hmm_reestimation_emission_rn}),
            \end{xalgostep}
            
            \begin{xalgostep}{apprentissage RN}
                    R�apprentissage du r�seau de neurones, voir ce paragraphe
                            \ref{hmm_reestimation_rn_classification} (page~\pageref{hmm_reestimation_rn_classification}) 
                            ainsi que les tables~\ref{figure_formule_baumwelch-fig_3}
                            et~\ref{figure_formule_baumwelch-fig_3prime}. \\
                    Retour � l'�tape~\ref{hmm_rn_step_algo_mmc} jusqu'� convergence.
            \end{xalgostep}
            
            \end{xalgorithm}
            





\begin{xremark}{convergence non monotone}
Il est conseill� de conserver les versions des mod�les � chaque it�ration car la convergence est rarement monotone.
\indexfr{monotone}
\end{xremark}










\subsection{Emissions continues mod�lis�es par une loi normale multidimensionnelle}
\label{hmm_loi_normale_emission_section}
\indexfrr{�missions}{continues}%
\indexfrr{loi}{normale multidimensionnelle}%

Les probabilit�s d'�mission peuvent �tre mod�lis�es par des lois normales, soit $\vecteur{O_1}{O_T}$ une s�quence d'observations et $\vecteur{q_1}{q_T}$ une s�quence d'�tats du mod�le $M$. On suppose que la variable~:

        $$
        O_t | q_t = i \sim \loinormale{\mu_i}{V_i}
        $$
        
Par cons�quent~:

        $$
        b_i\pa{O_t} = f\pa{O_t | q_t = i,M} = \dfrac{1}{\pa{2\pi}^{\frac{n}{2}} \sqrt{ \det \pa{ V_i}} }
                                \; e ^{ - \frac{1}{2} \pa{O_t - \mu_i}' \,  V_i^{-1} \pa{O_t - \mu_i}             }
        $$

Les formules de r�estimation (voir \citeindex{Bottou1991}) � utiliser lors de l'algorithme de Baum-Welch sont les suivantes pour les s�quences d'observations $\vecteur{O^k_1}{O^k_{T_k}}_{1 \infegal k \infegal K}$, on note $P_k = f\pa{O^k|M}$ o� $f$ est la densit� des s�quences d'observations~:%

\indexfrr{MMC}{Baum-Welch}%

        \begin{eqnarray}
        \overline {\mu_{i}} &=& \dfrac      {   \summy{k=1}{K} \; \dfrac{1}{P_k} \,  
                                                                                        \summy{t=1}{T_k}  \alpha_t^k\pa{i} \beta_t^k\pa{i} O_t^k }
                                            {   \summy{k=1}{K} \; \dfrac{1}{P_k} \,  
                                                    \summy{t=1}{T_k}   \alpha_t^k\pa{i} \beta_t^k\pa{i}  } \\
        && \nonumber\\
        \overline {V_{i}} &=& \dfrac        {   \summy{k=1}{K} \; \dfrac{1}{P_k} \,  
                                                                                        \summy{t=1}{T_k}   \alpha_t^k\pa{i} \beta_t^k\pa{i} O_t^k {O_t^k}' }
                                            {   \summy{k=1}{K} \; \dfrac{1}{P_k} \,  
                                                    \summy{t=1}{T_k}   \alpha_t^k\pa{i} \beta_t^k\pa{i}  }
                            - \mu_i \mu'_i
        \end{eqnarray}

L'inconv�nient de ces mod�les est le calcul de la densit� qui implique un produit matrice en $O\pa{d^3}$ o� $d$ est la dimension de l'espace des observations. Etant donn� la taille consid�rable de cette matrice, elles sont soit r�duites � leur diagonale, soit factoris�es entre les �tats. Pour cette derni�re solution, le mod�le hybride r�sultant est agenc� de mani�re semblable � celui regroupant un mod�le de Markov cach� et un r�seau de neurones. Le r�seau de neurones agit comme un classifieur commun � tous les �tats, dans l'autre cas, c'est un m�lange de lois normales qui mod�lisent la distribution des observations. \indexfrr{loi}{m�lange}


\begin{xremark}{calcul pratique de probabilit�s~: utlisation de co�ts}
L'utilisation de lois normales \index{co�t} peut poser des probl�mes informatiques de mise en \oe uvre. En effet, les probabilit�s sont alors souvent tr�s faibles pour des espaces de grandes dimensions, quelques dizaines comme pour la reconnaissance de l'�criture manuscrite. Il arrive fr�quemment que l'estimation de tels mod�les n�cessite le calcul de probabilit�s parfois inf�rieures � $10^{-300}$ qui est la limite d'un r�el cod� informatique sur huit octets. Il est alors pr�f�rable d'utiliser des co�ts ou logarithme de probabilit�s lors des calculs.
\end{xremark}










%----------------------------------------------------------------------------------------------------------------------
\section{Cha�nes de Markov d'ordres sup�rieurs}
%----------------------------------------------------------------------------------------------------------------------

\label{par_chaine_ordre_superieur}

Jusqu'� pr�sent, seules les cha�nes de Markov cach�es d'ordre un ont �t� utilis�es, ceci signifie que l'�tat � l'instant $t$ ne d�pend que de l'�tat � l'instant $t-1$, un ordre sup�rieur signifie que l'�tat � l'instat $t$ d�pend de plusieurs des �tats pr�c�dents.

\subsection{D�finition d'une cha�ne de Markov d'ordre $n$}

La d�finition suivante concerne une cha�ne de Markov et non une cha�ne de Markov cach�e : les �missions ne sont pas prises en compte.

        \begin{xdefinition}{Cha�ne de Markov d'ordre $n$}
        \label{definition_mmc_ordre_n}
        \indexfr{ordre}
        
        Soit $N\in\N^{\ast}$, on appelle une cha�ne de Markov � $N$ �tats d'ordre $n$ une cha�ne de Markov 
        qui v�rifie les conditions suivantes~:
        
                \begin{enumerate}
                \item l'�tat � l'instant $t$ ne d�pend que des �tats aux instants $\left(  t-1,...,t-n\right)$. 
                            Par cons�quent~:
                    $$
                    \forall t>n, \; \pr{  q_{t}\left|  q_{t-1},...,q_{1},M\right. }  = \pr{   q_{t}\left| 
                     q_{t-1},...,q_{t-n},M\right. }
                    $$
                    
                \item les probabilit�s de transition ne d�pendent pas du temps, par cons�quent :
                
                    $$
                    \begin{array}{l} \forall t_{1},t_{2}>1,\,\forall\left(i_{0},i_{1},...,i_{d}\right),\\
                    \pr{  q_{t_{1}}=i_{0}\left|q_{t_{1}-1}=i_{1},...,
                    q_{t_{1}-d}=i_{d},M\right.  }  = \pr{  q_{t_{2}}=i_{0}\left|  
                            q_{t_{2}-1}=i_{1},...,q_{t_{2}-d}=i_{d},M\right.  }
                    \end{array}
                    $$
                    
                \end{enumerate}
        \end{xdefinition}
        

On note $\mathcal{M}_{n}$ l'ensemble des cha�ne de Markov d'ordre $n$.




\subsection{Descente d'ordre}
\indexfr{descente d'ordre}%
\indexfrr{ordre}{descente}

Tout d'abord, on d�finit la fonction suivante $f$ :

        \begin{eqnarray}
        \begin{array}{l}
        g:\left\{  1,...,N\right\}  ^{n}\longrightarrow\left\{  1,...,N^{n}\right\}\\
        g\left(  i_{1},...,i_{n}\right)  =\underset{k=1}{\overset{n}{\sum}}\pa{i_{k}-1}N^{k-1}+1
        \end{array}
        \label{markov_ordre_homomorphisme_un}
        \end{eqnarray}

        \begin{xproperty}{homomorphisme}
        \label{propriete_chaine_ordre_n_1}%
        Si $g$ est la fonction d�finie en (\ref{markov_ordre_homomorphisme_un}), alors $g$ est bijective.
        \end{xproperty}


Par cons�quent, $g^{-1}$ existe et, on notera $\left[g^{-1}\left(l\right)\right]  _{k}$ la $k{{}^\circ}$ coordonn�es de $g^{-1}\left(l\right)$. Cette fonction est tout simplement l'�criture des entiers en base $N$.

Dans toute la suite, les �tat de sorties et d'entr�es ne seront plus distincts des autres �tats, ceci permettra de ne pas traiter les probabilit�s de transition, les probabilit�s d'entr�e et les probabilit�s de sortie de mani�re s�par�e.


Soit une cha�ne de Markov $M$ d'ordre $n$ contenant $N$ �tats repr�sent�s par l'ensemble $\vecteur{1}{N}$. Cette cha�ne est enti�rement d�finie par une hyper-matrice carr�e $A_{M}\in\mathcal{M}_{N}^{n+1}\left(\R\right)  $ contenant les $\left( N\right)^{n+1}$ probabilit�s de transition de la cha�ne de Markov $M\in\mathcal{M}_{n}$~:

        $$
        A_{M}\left(i_{1},...,i_{n},i_{n+1}\right)  =\pr{  q_{t}=i_{n+1}\left| 
         q_{t-1}=i_{n},...,q_{t-n}=i_{1},M\right.  }
        $$

Si $e$ est l'�tat d'entr�e du mod�le, on pose comme convention :

        \begin{eqnarray}
        A_M \vecteur{i_1}{i_{n+1}} &=& \left \{
        \begin{array}{l}
        0 \text{ si } i_{n+1} = e \\
        0 \text{ si } \exists k \infegal n \text{ tel que } i_k \neq e \text{ et } i_{k+1} = e \\
        1 \text{ si } \exists k \text{ tel que }  3 \infegal k \infegal n \text{ et } \forall k' < k, \; i_{k'} =
                 e \text { et } \forall k' \supegal k, \; i_{k'} \neq e \\
        \pr{q_t = i_{n+1} \, | \, \vecteurno{q_{t-1} = i_n}{q_{t-n} = i_1}} \text{ sinon}
        \end{array}
        \right. \label{hmm_equation_convention_ordre}
        \end{eqnarray}

On construit la cha�ne de Markov $M^{\prime}$ d'ordre un contenant $N^{n}$ �tats repr�sent�s par l'ensemble $\vecteur{1}{N^n}$. Cette cha�ne est enti�rement d�finie par sa matrice carr�e $A_{M^{\prime}}^{\prime }\in \mathcal{M}_{N^{n}}^{2}\left( \R\right) $ contenant les $\pa{N^n}^2$ probabilit�s de transition de la cha�ne $M^{\prime}\in\mathcal{M}_1$~:

        $$
        A_{M^{\prime}}^{\prime}\left(  k,l\right)=\pr{ q_{t}=l\left| q_{t-1}=k,M^{\prime}\right.  }
        $$

La matrice des transitions $A_{M^{\prime}}^{\prime }$ est d�finie � partir de l'hyper-matrice $A_M$~:

        \begin{eqnarray}
        A_{M^{\prime}}^{\prime}\left(  k,l\right) &=&\left\{
        \begin{array}[c]{l}%
        A_{M}\left(  \left[  g^{-1}\left(  k\right)  \right]  _{1},g^{-1}\left( l\right)  \right) 
                 \text{ si }\forall i\in\left\{  1,...,n-1\right\}
        ,\,\left[  g^{-1}\left(  l\right)  \right]  _{i}=\left[  g^{-1}\left(
        k\right)  \right]  _{i+1}\\
        0\text{ sinon}%
        \end{array}
        \right. \label{markov_ordre_homomorphisme_deux}\\
        && \text{avec $g$ la fonction d�finie en (\ref{markov_ordre_homomorphisme_un})} \nonumber
        \end{eqnarray}

Enfin on d�finit la fonction $h$~:%

        \begin{eqnarray}
        \begin{array}[c]{l}
        h:\mathcal{M}_{n}\longrightarrow\mathcal{M}_{1}\\
        h\left(  M\right)  =M^{\prime} \text{ avec $M'$ construite comme en (\ref{markov_ordre_homomorphisme_deux})}%
        \end{array}
        \label{markov_ordre_homomorphisme_trois}
        \end{eqnarray}

On doit d'abord d�finir l'�quivalence entre deux cha�nes de Markov~:


        \begin{xdefinition}{�quivalence entre deux cha�nes de Markov}
        \label{definition_mm_equivalence}%
        \indexfr{�quivalence}
        Soient $M_1$ et $M_2$ deux cha�nes de Markov, on note $S$ l'ensemble des s�quences d'�tats, alors~:
                $$
                \pa{M_1 \Longleftrightarrow M_2} \Longleftrightarrow \pa{\forall s \in S, \; \pr{s|M_1} = \pr{s|M_2}}
                $$
        \end{xdefinition}
        

On peut maintenant �noncer le th�or�me suivant~:


        \begin{xtheorem}{homomorphisme}
        \label{markov_ordre_homomorphisme_trois_th}%
        Avec ces notations, la fonction $h$ (\ref{markov_ordre_homomorphisme_trois}) d�finit un homomorphisme de $\left(\mathcal{M}_{n} ,
        \Longleftrightarrow \right)$ dans $\left( \mathcal{M}_{1},\Longleftrightarrow\right)  $ o� $\Longleftrightarrow$ 
        est la relation d'�quivalence    entre deux cha�nes de Markov.
        \end{xtheorem}




\para{Rappel :}


        \begin{xdefinition}{homomorphisme}
        \label{definition_mmc_homomorphisme}%
        Soit $\left(  E,\perp\right)  $ et $\left(  F,\perp\right)  $ deux espaces munis chacun 
        d'une relation d'�quivalence.\newline%
        Soit $h:\left( E,\perp\right) \longrightarrow\left(  F,\perp\right)  $ une fonction, $h$ est un homomorphisme 
        si et seulement si :
                $$
                \forall\left(  x,y\right)  \in E^{2},\; x\perp y\Longrightarrow h\left(  x\right)  \perp h\left(y\right)
                $$
        \end{xdefinition}
        


\begin{xdemo}{theoreme}{\ref{markov_ordre_homomorphisme_trois_th}}

\textbf{Rappel :} L'�tat 0 correspond � l'�tat d'entr�e.\newline%


Soit $s=\vecteur{s_1}{s_T}$ une s�quence d'�tats du mod�le $M$.\newline%
On d�finit la s�quence d'�tats $u=k\left(  s\right)  $ comme suit~:

        $$
        u=k\pa{s}=\left(  u_{1},...,u_{T}\right)  =\left(  \left(
        \begin{array}[c]{c}%
        u_{11}\\
        \vdots\\
        u_{1n}%
        \end{array}
        \right),....,\left(
        \begin{array}[c]{c}%
        u_{T1}\\
        \vdots\\
        u_{Tn}%
        \end{array}
        \right)  \right)  \in\left[  \left\{  1,...,N\right\}  ^{n}\right]  ^{T}
        $$
avec :
        $$
        \forall t\in \intervalle{1}{T}, \; \forall l\in \intervalle{1}{n}, \; u_{tl} =
            \left\{
            \begin{array}[c]{l}%
            s_{t+l-n} \text { si } t+l-n > 0\\
            e \text { si } l+t-n\leqslant0 \text{ o� } e \text{ est l'�tat d'entr�e de } M
            \end{array}
            \right.
        $$

Cette s�quence v�rifie :

        $$
        \begin{array}{rrcl}
        \forall t \in \intervalle{2}{T}, \; \forall l\in \intervalle{1}{n-1}, & u_{t-1,l+1}&=&u_{tl} \\
        \forall t \in \intervalle{1}{T-1}, & u_{tn} &=& u_{t+1,1}
        \end{array}
        $$

La convention choisie en (\ref{hmm_equation_convention_ordre}) implique que :

        $$
        \pr{  s\left|  M\right.  } = \pr{ u\left|M^{\prime}\right.  }  = \pr{ h\left( s\right) \left|
         M^{\prime}\right.  }
        $$

Donc, soit $\left(  M,N\right)  \in\left(  \mathcal{M}_{n}\right)  ^{2},$

        $$
        \biggcro{M \Longleftrightarrow N } \Longrightarrow  \biggcro{ \forall s \in S ,\; 
                _pr{  s\left| M\right.  }
        = \pr{   s\left| N\right.
        } \Longrightarrow \forall s,\, \pr{   k\left(  s\right)  \left| h\left( M\right) \right. } 
        = \pr{  k\left(  s\right) \left|
        g\left( N\right)  \right. }}
        $$

De plus, d'apr�s (\ref{markov_ordre_homomorphisme_deux}), on d�duit que :

        $$
        \forall u,\; \biggcro{  \nexists s \in S \text{ tel que }k\left(  s\right)  =u } \Longrightarrow \pr{
         u\left|  g\left(  M\right) \right.
        } = \pr{  u\left|  g\left(  N\right)  \right.  }  =0
        $$

Donc :

        $$
        \biggcro { M\Longleftrightarrow N }  \Longrightarrow \biggcro{ g\left( M\right) 
         \Longleftrightarrow g\left(  N\right)  }
        $$

\end{xdemo}









\subsection{D�finition d'une cha�ne de Markov cach�e d'ordre $n$}

Le paragraphe pr�c�dent a montr� comment transformer une cha�ne de Markov d'ordre $n$ en une cha�ne de Markov d'ordre un. Ce r�sultat peut �tre �tendu aux cha�nes de Markov cach�es~:

        \begin{xdefinition}{cha�ne de Markov cach�e d'ordre $n$}
        \label{hmm_markov_ordre_n_def}%
        \indexfr{ordre}
        
        Soit $N\in\N^{\ast}$, soit une cha�ne de Markov cach�e � $N$ �tats d'ordre $n$ dont les �missions sont discr�tes 
        et appartiennent � l'ensemble $\vecteur{1}{D}$, cette cha�ne v�rifie les hypoth�ses suivantes~:
        
        \begin{enumerate}
        \item L'�tat � l'instant $t$ ne d�pend que des �tats aux instants $\left(  t-1,...,t-n\right)$. Par cons�quent :
                $$
                \forall t>n,\quad \pr{q_{t}\left|  q_{t-1},...,q_{1},M\right. }  = \pr{  q_{t}\left| 
                 q_{t-1},...,q_{t-n},M\right. }
                $$
        
        \item Les probabilit�s de transition ne d�pendent pas du temps, par cons�quent :
                $$
                \begin{array}{l}
                \forall t_{1},t_{2}>1,\,\forall\left(i_{0},i_{1},...,i_{n}\right)  ,\\
                \pr{  q_{t_{1}}=i_{0}\left|q_{t_{1}-1}=i_{1},...,q_{t_{1}-n}=i_{n},M\right.  }  
                = \pr{  q_{t_{2}}=i_{0}\left|  q_{t_{2}-1}=i_{1},
                ...,q_{t_{2}-n}=i_{n},M\right. }
                \end{array}
                $$
        
        \item Les probabilit�s d'�mission ne d�pendent que des �tats aux instants $\left(  t,...,t-n+1\right)$ :
        
                $$
                \forall t\geqslant 1,\, \pr{ O_{t}\left|q_{1},...,q_{t},O_{1},...,O_{t-1},M\right.  } =
                    \pr{  O_{t}\left| 
                 \vecteur{q_{t}}{q_{t-n+1}},M\right.}
                $$
        
        \item Les probabilit�s d'�mission ne d�pendent pas du temps :
        
                $$
                \begin{array}{l}
                \forall t_{1},t_{2}>1,\;\forall\left(i_{1},...,i_{n}\right), \; \forall o, \\
                \pr{  O_{t_{1}}=o\left|q_{t_{1}}=i_{1},...,q_{t_{1}-n+1}=i_{n},M\right.  }  =
                \pr{ O_{t_{2}}=o\left| 
                 q_{t_{2}}=i_{1},
                ...,q_{t_{2}-n+1}=i_{n},M\right.  }
                \end{array}
                $$
        
        \end{enumerate}
        
        \end{xdefinition}
        
\begin{xremark}{autres types d'�mission}
Cette d�finition peut �tre d�clin�e pour des observations d'un type diff�rent (r�seau de neurones, normales...).
\end{xremark}




On note $\mathcal{C}_{n}$ l'ensemble des cha�nes de Markov cach�es d'ordre $n$, en appliquant les r�sultats du paragraphe pr�c�dent, il est possible de construire une fonction $h^{\prime}$ :%

        \begin{eqnarray}%
        \begin{array}{l}
        h^{\prime}:\mathcal{C}_{n}\longrightarrow\mathcal{C}_{1}\\
        h'\left(  C\right)  =C^{\prime} \text{ avec } M_{C'} = h\pa{M_C} \text{ o� } \\
        \quad\quad\quad\quad\quad\quad M_C \text { est la cha�ne de Markov cach�e dans } C \\
        \quad\quad\quad\quad\quad\quad M_{C'} \text { est la cha�ne de Markov cach�e dans } C'%
        \end{array}
        \label{markov_ordre_homomorphisme_quatre}
        \end{eqnarray}


$h\pa{C}$ v�rifie~:

        \begin{eqnarray*}
        \pr{  q_{t}=l\left|  q_{t-1}=k,M^{\prime}\right.  }  &=& \left\{%
        \begin{array}[c]{l}%
        \pr{  q_{t}=\left[  g^{-1}\left(  l\right)  \right]  _{n}\left| 
             \vecteurno{q_{t-1}=\crochet{g^{-1}\pa{k}}_{n}} {q_{t-n}=
        \crochet{g^{-1}\pa{k}}_{1}} \right.
            ,M} \medskip\\
        \quad\quad\quad \text{ si }\forall i\in\left\{  1,...,n-1\right\}  ,\,\left[  g^{-1}\left(
            l\right)  \right]  _{i}=\left[  g^{-1}\left(  k\right)  \right]  _{i+1}\\
        e\text{ sinon (} e \text{ est l'�tat d'entr�e de la cha�ne de Markov)}%
        \end{array}
        \right. \\
        \pr{ O_{t}=o\left|  q_{t}=l,M^{\prime}\right.  }  &=& \pr{ O_{t}=o\left| 
         \vecteurno{q_{t}=\crochet{g^{-1}\pa{l}}_{n}} {q_{t-n+1}=
        \crochet{g^{-1}\pa{l}}_{1}} ,M\right. }
        \end{eqnarray*}

On doit d'abord d�finir l'�quivalence entre deux cha�nes de Markov cach�es :


        \begin{xdefinition}{�quivalence entre deux cha�nes de Markov cach�es}
        \label{definition_hmm_equivalence}%
        Soient $C_1$ et $C_2$ deux cha�nes de Markov cach�e, on note $\mathcal{O}$ l'ensemble des s�quences 
        d'observations, alors :
                $$
                \biggcro{C_1 \Longleftrightarrow C_2} \Longleftrightarrow \biggcro{\forall O
                \in \mathcal{O}, \; \pr{O|C_1} = \pr{O|C_2}}
                $$
        \end{xdefinition}




On peut maintenant �noncer le th�or�me suivant :


        \begin{xtheorem}{homomorphisme}
        \label{theoreme_equivalence_cachee}%
        \indexfr{homomorphisme}
        Avec ces notations, la fonction $h'$ (\ref{markov_ordre_homomorphisme_quatre}) 
        d�finit un homomorphisme de $\left(\mathcal{C}_{n} ,
         \Longleftrightarrow \right)$ dans $\left( \mathcal{C}_{1},\Longleftrightarrow\right)  $ o� 
         $\Longleftrightarrow$ est la relation
          d'�quivalence entre deux cha�nes de Markov. De plus, $\forall C\in \mathcal{C}_n, \; h\pa{C} 
          \Longleftrightarrow C$.
        \end{xtheorem}


\begin{xdemo}{th�or�me}{\ref{theoreme_equivalence_cachee}}
Ce th�or�me est un corollaire du th�or�me~\ref{markov_ordre_homomorphisme_trois_th} (page~\pageref{markov_ordre_homomorphisme_trois_th}).
\end{xdemo}











\subsection{D�finition d'une cha�ne de Markov cach�e d'ordre $\pa{p,q}$}


Ces mod�les sont ceux dont les hypoth�ses sont les moins contraignantes.


        \begin{xdefinition}{cha�ne de Markov cach�e d'ordre $\pa{p,q}$}%
        \label{hmm_markov_ordre_pq_def}%
        \indexfr{ordre}
        Soit $N\in\N^{\ast}$, soit une cha�ne de Markov cach�e � $N$ �tats d'ordre $p>0$ dont les �missions 
        sont discr�tes et appartiennent � l'ensemble $\vecteur{1}{D}$, cette cha�ne v�rifie les hypoth�ses suivantes~:
        
        \begin{enumerate}
        \item L'�tat � l'instant $t$ ne d�pend que des �tats aux instants $\left(  t-1,...,t-p\right)$ et 
        des observations aux instants
                $\vecteur{O_{t-1}}{O_{t-q}}$ :
                $$
                \forall t>p,\; \pr{ q_{t}\left|  \overline{q_{t-1}}, \overline{O_{t-1}},M\right. }
                =   \pr{  q_{t}\left|  q_{t-1},...,q_{t-p},O_{t-1},...,O_{t-q},M\right. }
                $$
        
        \item Les probabilit�s de transition ne d�pendent pas du temps, Par cons�quent :
                $$
                \begin{array}{l}
                \forall t_{1},t_{2}>1,\;\forall\left(i_{0},...,i_{p}\right), \; \forall\left(x_{1},...,x_{q}\right), \; \\
                \pr{   q_{t_{0}}=i_0\left|q_{t_{1}}=i_{1},...,q_{t_{1}-p+1}=i_{n}, 
                        O_{t_{1}}=x_{1},...,O_{t_{1}-q}=x_{n},M\right.  }  \\
                \quad\quad= \pr{   q_{t_{2}}=i_0\left| 
                 q_{t_{2}}=i_{1},...,q_{t_{2}-n+1}=i_{n},O_{t_{2}}=x_{1},...,O_{t_{2}-q}=x_{n},M\right.  }
                \end{array}
                $$
        
        \item Les probabilit�s d'�mission ne d�pendent que des �tats aux instants $\left(  t,...,t-p+1\right)$ 
                    et des observations aux instants $\vecteur{O_{t-1}}{O_{t-Q}}$~:
                    
                $$
                \forall t\geqslant 1,\, \pr{ O_{t}\left|q_{1},...,q_{t},O_{1},...,O_{t-1},M\right.  } =
                \pr{   O_{t}\left|  \vecteur{q_{t}}{q_{t-p+1}},\vecteur{O_{t-1}}{O_{t-q}},M\right.    }
                $$
        
        \item Les probabilit�s d'�mission ne d�pendent pas du temps~:
        
                $$
                \begin{array}{l}
                \forall t_{1},t_{2}>1,\;\forall\left(i_{1},...,i_{p}\right), \; 
                            \forall\left(x_{1},...,x_{q}\right), \; \forall o, \\
                \pr{ O_{t_{1}}=o\left|q_{t_{1}}=i_{1},...,q_{t_{1}-p+1}=i_{n},O_{t_{1}} =
                            x_{1},...,O_{t_{1}-q}=x_{n},M\right.  }  \\
                \quad\quad= \pr{  O_{t_{2}}=o\left| 
                     q_{t_{2}}=i_{1},...,q_{t_{2}-n+1}=i_{n},O_{t_{2}}=x_{1},...,O_{t_{2}-q}=x_{n},M\right.  }
                \end{array}
                $$
                
        \end{enumerate}
        \end{xdefinition}
        


Gr�ce � une d�monstration similaire, les paragraphes pr�c�dents nous permettent d'�noncer le th�or�me suivant~:

        \begin{xtheorem}{homomorphisme}%
        \label{theoreme_hmm_homomorphisme_1}%
        Soit $\mathcal{C}_{p,q} \pa{\mathcal{X}}$ l'ensemble des cha�nes de Markov cach�es d'ordre $\pa{p,q}$ 
        dont les observations
             appartiennent � l'ensemble $\mathcal{X}$. Alors il existe un homomorphisme de $\pa{\mathcal{C}_{p,q}
              \pa{\mathcal{X}},\Longleftrightarrow}$ dans $\pa{\mathcal{C}_{1,1} \pa{\mathcal{X}^q},\Longleftrightarrow}$
        \end{xtheorem}

\begin{xdemo}{th�or�me}{\ref{theoreme_hmm_homomorphisme_1}}
La d�monstration est similaire � celle du th�or�me~\ref{markov_ordre_homomorphisme_trois_th} (page~\pageref{markov_ordre_homomorphisme_trois_th}).
\end{xdemo}






        \begin{xcorollary}{homomorphisme}
        \label{corollaire_chaine_markov_cachee_1}%
        Si $\mathcal{X}$ est un ensemble fini, il existe un homomorphisme de 
        $\pa{\mathcal{C}_{p,q} \pa{\mathcal{X}},\Longleftrightarrow}$ dans
        $\pa{\mathcal{C}_{1,0} \pa{\mathcal{X}^q},\Longleftrightarrow}$
        \end{xcorollary}









\subsection{Conclusion}


Cette annexe a pr�sent� les mod�les de Markov cach�s, leur utilisation pour la mod�lisation de s�quences discr�tes ou continues et leur estimation. Pour des raisons calculatoires, les cha�nes de Markov cach�es d'ordre $\pa{p,q}$ avec $q>0$ aux �missions continues sont peu utilis�es. Il est alors possible de n'envisager que des mod�les de cha�nes de Markov cach�es d'ordre $\pa{1,0}$ puisque toute cha�ne d'ordre $\pa{p>1,0}$ a son �quivalent d'ordre $\pa{1,0}$. Les calculs avec ces mod�les sont simples et leur repr�sentation peut �tre r�duite � un simple graphe, ce dernier point facilite leur r�alisation informatique.



\subsection{Extension}

\indexfrr{loi}{normale}

L'article \citeindex{Bicego2003} d�montre aussi l'�quivalence entre un mod�le de Markov cach� dont les �missions associ�s aux �tats sont des m�langes de lois normales avec un mod�le de Markov cach� dont les �missions sont des lois gaussiennes. Le second mod�le comporte bien �videmment plus d'�tats.




\firstpassagedo{
    \begin{thebibliography}{99}
    \input{hmm_bibliographie.tex}
    \end{thebibliography}
}


\input{../../common/livre_table_end.tex}
\input{../../common/livre_end.tex}
